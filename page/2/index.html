<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sk-xinye.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.yml"};
  </script>

  <meta name="description" content="愿所有努力都不被辜负">
<meta property="og:type" content="website">
<meta property="og:title" content="sk-xinyeの博客">
<meta property="og:url" content="https://sk-xinye.github.io/page/2/index.html">
<meta property="og:site_name" content="sk-xinyeの博客">
<meta property="og:description" content="愿所有努力都不被辜负">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sk-xinye">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://sk-xinye.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>sk-xinyeの博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">sk-xinyeの博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习的脚步</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">13</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">96</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/26/7-%E6%B7%B1%E5%85%A5%E5%AE%A2%E6%88%B7%E7%AB%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/26/7-%E6%B7%B1%E5%85%A5%E5%AE%A2%E6%88%B7%E7%AB%AF/" class="post-title-link" itemprop="url">7.深入客户端</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-26 09:38:04" itemprop="dateCreated datePublished" datetime="2021-06-26T09:38:04+08:00">2021-06-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-27 21:44:56" itemprop="dateModified" datetime="2021-06-27T21:44:56+08:00">2021-06-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h2><ul>
<li>Kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略。</li>
<li>默认情况下，此参数的值为 org.apache.kafka.clients.consumer.RangeAssignor，即采用RangeAssignor分配策略。</li>
<li>除此之外，Kafka还提供了另外两种分配策略：RoundRobinAssignor 和 StickyAssignor。</li>
<li>消费者客户端参数 partition.assignment.strategy可以配置多个分配策略，彼此之间以逗号分隔。</li>
</ul>
<h3 id="RangeAssignor分配策略"><a href="#RangeAssignor分配策略" class="headerlink" title="RangeAssignor分配策略"></a>RangeAssignor分配策略</h3><p>假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。</p>
<p>假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有4个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t0p3、t1p0、t1p1、t1p2、t1p3。最终的分配结果为：</p>
<ul>
<li>消费者c0:t0p0、t0p1、t1p0、t1p1</li>
<li>消费者c1:t0p2、t0p3、t1p2、t1p3</li>
</ul>
<p>假设上面例子中2个主题都只有3个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：</p>
<ul>
<li>消费者c0:t0p0、t0p1、t1p0、t1p1</li>
<li>消费者c1:t0p2、t1p2</li>
</ul>
<p>可以明显地看到这样的分配并不均匀，如果将类似的情形扩大，则有可能出现部分消费者过载的情况。</p>
<h3 id="RoundRobinAssignor分配策略"><a href="#RoundRobinAssignor分配策略" class="headerlink" title="RoundRobinAssignor分配策略"></a>RoundRobinAssignor分配策略</h3><ul>
<li>RoundRobinAssignor分配策略的原理是将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区依次分配给每个消费者。</li>
<li>RoundRobinAssignor分配策略对应的 partition.assignment.strategy 参数值为 org.apache.kafka.clients.consumer.RoundRobinAssignor。</li>
</ul>
<p>假设消费组中有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：</p>
<ul>
<li>消费者c0:t0p0、t0p2、t1p1</li>
<li>消费者c1:t0p1、t1p0、t1p2</li>
</ul>
<p>当也会有缺点：假设消费组内有3个消费者（C0、C1和C2），它们共订阅了3个主题（t0、t1、t2），这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2</p>
<ul>
<li>消费者c0:t0p0</li>
<li>消费者c1:t1p0</li>
<li>消费者c0:t1p1,t2p0,t2p1,t2p2</li>
<li>可以看到RoundRobinAssignor策略也不是十分完美，这样分配其实并不是最优解，因为完全可以将分区t1p1分配给消费者C1。</li>
</ul>
<h3 id="StickyAssignor分配策略"><a href="#StickyAssignor分配策略" class="headerlink" title="StickyAssignor分配策略"></a>StickyAssignor分配策略</h3><p>“sticky”这个单词可以翻译为“黏性的”，Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的</p>
<ul>
<li>分区的分配要尽可能均匀。</li>
<li>分区的分配尽可能与上次分配的保持相同。</li>
<li>当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor分配策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂得多。我们举例来看一下StickyAssignor分配策略的实际效果。</li>
</ul>
<p>假设消费组内有3个消费者（C0、C1和C2），它们都订阅了4个主题（t0、t1、t2、t3），并且每个主题有2个分区。也就是说，整个消费组订阅了t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区。最终的分配结果如下：</p>
<ul>
<li>消费者c0:t0p0,t1p1,t3p0</li>
<li>消费者c1:t0p1,t2p0,t3p1</li>
<li>消费者c2:t1p0,t2p1</li>
</ul>
<p>这样初看上去似乎与采用RoundRobinAssignor分配策略所分配的结果相同，但事实是否真的如此呢？再假设此时消费者 C1 脱离了消费组，那么消费组就会执行再均衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor分配策略，那么此时的分配结果如下:</p>
<ul>
<li>消费者c0:t0p0,t1p0,t2p0,t3p0</li>
<li>消费者c2:t0p1,t1p1,t2p1,t3p1</li>
</ul>
<p>如分配结果所示，RoundRobinAssignor分配策略会按照消费者C0和C2进行重新轮询分配。如果此时使用的是StickyAssignor分配策略，那么分配结果为：</p>
<ul>
<li>消费者c0:t0p0,t1p1,t3p0,t3p0</li>
<li>消费者c2:t1p0,t2p1,t0p1,t3p1</li>
</ul>
<p>使用StickyAssignor分配策略的一个优点就是可以使分区重分配具备“黏性”，减少不必要的分区移动（即一个分区剥离之前的消费者，转而分配给另一个新的消费者）。</p>
<h3 id="自定义分区分配策略"><a href="#自定义分区分配策略" class="headerlink" title="自定义分区分配策略"></a>自定义分区分配策略</h3><h2 id="消费者协调器和组协调器"><a href="#消费者协调器和组协调器" class="headerlink" title="消费者协调器和组协调器"></a>消费者协调器和组协调器</h2><p>多个消费者之间的分区分配是需要协同的，那么这个协同的过程又是怎样的呢？这一切都是交由消费者协调器（ConsumerCoordinator）和组协调器（GroupCoordinator）来完成的，它们之间使用一套组协调协议进行交互。</p>
<h3 id="再均衡的原理"><a href="#再均衡的原理" class="headerlink" title="再均衡的原理"></a>再均衡的原理</h3><p>新版的消费者客户端对此进行了重新设计，将全部消费组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理，GroupCoordinator是Kafka服务端中用于管理消费组的组件。而消费者客户端中的ConsumerCoordinator组件负责与GroupCoordinator进行交互。</p>
<p>ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者再均衡的操作，包括前面提及的分区分配的工作也是在再均衡期间完成的。就目前而言，一共有如下几种情形会触发再均衡的操作</p>
<ul>
<li>有新的消费者加入消费组</li>
<li>有消费者宕机下线。消费者并不一定需要真正下线，例如遇到长时间的 GC、网络延迟导致消费者长时间未向GroupCoordinator发送心跳等情况时，GroupCoordinator会认为消费者已经下线。</li>
<li>有消费者主动退出消费组（发送 LeaveGroupRequest 请求）。比如客户端调用了unsubscrible（）方法取消对某些主题的订阅。</li>
<li>消费组所对应的GroupCoorinator节点发生了变更。</li>
<li>消费组内所订阅的任一主题或者主题的分区数量发生变化。</li>
</ul>
<p>当有消费者加入消费组时，消费者、消费组及组协调器之间会经历一下几个阶段。</p>
<ul>
<li>第一阶段（FIND_COORDINATOR）<ul>
<li>消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接。</li>
<li>如果消费者已经保存了与消费组对应的 GroupCoordinator 节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。</li>
<li>否则，就需要向集群中的某个节点发送FindCoordinatorRequest请求来查找对应的GroupCoordinator，这里的“某个节点”并非是集群中的任意节点，而是负载最小的节点，即2.2.2节中的leastLoadedNode。</li>
<li>Kafka 在收到 FindCoordinatorRequest 请求之后，会根据 coordinator_key（也就是groupId）查找对应的GroupCoordinator节点，如果找到对应的GroupCoordinator则会返回其相对应的node_id、host和port信息。</li>
<li>具体查找GroupCoordinator的方式是先根据消费组groupId的哈希值计算__consumer_offsets中的分区编号</li>
<li>中 groupId.hashCode 就是使用 Java 中 String 类的 hashCode（）方法获得的，groupMetadataTopicPartitionCount 为主题__consumer_offsets 的分区个数，这个可以通过broker端参数offsets.topic.num.partitions来配置，默认值为50。</li>
<li>找到对应的__consumer_offsets中的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为这个groupId所对应的GroupCoordinator节点。</li>
<li>消费者groupId最终的分区分配方案及组内消费者所提交的消费位移信息都会发送给此分区leader副本所在的broker节点，让此broker节点既扮演GroupCoordinator的角色，又扮演保存分区分配方案和组内消费者位移的角色，这样可以省去很多不必要的中间轮转所带来的开销。</li>
</ul>
</li>
<li>第二阶段（JOIN_GROUP）<ul>
<li>在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段，在此阶段的消费者会向GroupCoordinator发送JoinGroupRequest请求，并处理响应。</li>
<li>如果是原有的消费者重新加入消费组，那么在真正发送JoinGroupRequest 请求之前还要执行一些准备工作<ul>
<li>如果消费端参数enable.auto.commit设置为true（默认值也为true），即开启自动提交位移功能，那么在请求加入消费组之前需要向 GroupCoordinator 提交消费位移。这个过程是阻塞执行的，要么成功提交消费位移，要么超时。</li>
<li>如果消费者添加了自定义的再均衡监听器（ConsumerRebalanceListener），那么此时会调用onPartitionsRevoked（）方法在重新加入消费组之前实施自定义的规则逻辑，比如清除一些状态，或者提交消费位移等。</li>
<li>因为是重新加入消费组，之前与GroupCoordinator节点之间的心跳检测也就不需要了，所以在成功地重新加入消费组之前需要禁止心跳检测的运作。</li>
</ul>
</li>
<li>选举消费组的leader<ul>
<li>GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader，这个选举的算法也很简单，分两种情况分析。如果消费组内还没有 leader，那么第一个加入消费组的消费者即为消费组的 leader。很随机</li>
</ul>
</li>
<li>选举分区分配策略<ul>
<li>收集各个消费者支持的所有分配策略，组成候选集candidates。</li>
<li>每个消费者从候选集candidates中找出第一个自身支持的策略，为这个策略投上一票。</li>
<li>计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略。</li>
</ul>
</li>
<li>在此之后，Kafka服务端就要发送JoinGroupResponse响应给各个消费者，leader消费者和其他普通消费者收到的响应内容并不相同，</li>
<li><img src="/2021/06/26/7-%E6%B7%B1%E5%85%A5%E5%AE%A2%E6%88%B7%E7%AB%AF/%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E9%80%81%E5%8A%A0%E5%85%A5%E7%BB%84%E8%AF%B7%E6%B1%82.png" class=""></li>
<li></li>
</ul>
</li>
<li>第三阶段（SYNC_GROUP）<ul>
<li>leader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，此时leader消费者并不是直接和其余的普通消费者同步分配方案，而是通过 GroupCoordinator 这个“中间人”来负责转发同步分配方案的。</li>
<li><img src="/2021/06/26/7-%E6%B7%B1%E5%85%A5%E5%AE%A2%E6%88%B7%E7%AB%AF/%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D.png" class=""></li>
<li>服务端在收到消费者发送的SyncGroupRequest请求之后会交由GroupCoordinator来负责具体的逻辑处理。</li>
<li>GroupCoordinator同样会先对SyncGroupRequest请求做合法性校验，在此之后会将从 leader 消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入Kafka的__consumer_offsets主题中，最后发送响应给各个消费者以提供给各个消费者各自所属的分配方案。</li>
<li>当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment（）方法。随后再调用ConsumerRebalanceListener中的OnPartitionAssigned（）方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartbeatRequest来确定彼此在线。</li>
<li>消费组元数据信息</li>
</ul>
</li>
<li>第四阶段（HEARTBEAT）<ul>
<li>进入这个阶段之后，消费组中的所有消费者就会处于正常工作状态。</li>
<li>由参数heartbeat.interval.ms指定，默认值为3000，即3秒，</li>
</ul>
</li>
</ul>
<h2 id="consumer-offsets剖析"><a href="#consumer-offsets剖析" class="headerlink" title="__consumer_offsets剖析"></a>__consumer_offsets剖析</h2><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>At Least Once + 幂等性 = Exactly Once，但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以幂等性无法保证跨分区跨会话的 Exactly Once。<br>事务</p>
<p>事务可以保证 Kafka 在 Exactly Once 语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<ul>
<li>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的TransactionID 获得原来的 PID。</li>
<li>为了管理 Transaction，Kafka 引入了一个新的组件 Transaction Coordinator。Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。TransactionCoordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</li>
</ul>
<h3 id="消息传输保障"><a href="#消息传输保障" class="headerlink" title="消息传输保障"></a>消息传输保障</h3><p>一般而言，消息中间件的消息传输保障有3个层级，分别如下。</p>
<ol>
<li>at most once：至多一次。消息可能会丢失，但绝对不会重复传输。</li>
<li>at least once：最少一次。消息绝不会丢失，但可能会重复传输。</li>
<li>exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次。</li>
</ol>
<p>生产者提供的消息保证是最少一次，对消费者而言，消费者处理消息和提交消费位移的顺序在很大程度上决定了消费者提供哪一种消息传输保障。</p>
<ul>
<li>如果消费者在拉取完消息之后，应用逻辑先处理消息后提交消费位移，那么在消息处理之后且在位移提交之前消费者宕机了，待它重新上线之后会从上一次位移提交的位置拉取，这样就出现了重复消费，</li>
<li>如果消费者在拉完消息之后，应用逻辑先提交消费位移后进行消息处理，那么在位移提交之后且在消息处理完成之前消费者宕机了，待它重新上线之后，会从已经提交的位移处开始重新消费，但之前尚有部分消息未进行消费，如此就会发生消息丢失，此时就对应at most once。</li>
</ul>
<p>Kafka从0.11.0.0版本开始引入了<strong>幂等和事务</strong>这两个特性，以此来实现EOS（exactly once semantics，精确一次处理语义）。</p>
<h3 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h3><ul>
<li>所谓的幂等，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。</li>
<li>开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数enable.idempotence设置为true即可</li>
<li>不过如果要确保幂等性功能正常，还需要确保生产者客户端的 retries、acks、max.in.flight.requests.per.connection这几个参数不被配置错。实际上在使用幂等性功能的时候，用户完全可以不用配置（也不建议配置）这几个参数。<ul>
<li>如果用户显式地指定了 retries 参数，那么这个参数的值必须大于 0，否则会报出ConfigException：</li>
<li>如果用户没有显式地指定 retries 参数，那么 KafkaProducer 会将它置为 Integer.MAX_VALUE。</li>
<li>同时还需要保证max.in.flight.requests.per.connection参数的值不能大于5（这个参数的值默认为5，在2.2.1节中有相关的介绍），否则也会报出ConfigException</li>
<li>如果用户还显式地指定了 acks 参数，那么还需要保证这个参数的值为-1（all），如果不为-1（这个参数的值默认为1，2.3节中有相关的介绍），那么也会报出ConfigException：</li>
</ul>
</li>
<li>为了实现生产者的幂等性，Kafka为此引入了producer id（以下简称PID）和序列号（sequence number）这两个概念</li>
<li>对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将＜PID，分区＞对应的序列号的值加1</li>
<li>broker端会在内存中为每一对＜PID，分区＞维护一个序列号。对于收到的每一条消息，只有当它的序列号的值（SN_new）比broker端中维护的对应的序列号的值（SN_old）大1（即SN_new=SN_old+1）时，broker才会接收它。如果SN_new＜SN_old+1，那么说明消息被重复写入，broker可以直接将其丢弃。如果SN_new＞SN_old+1，那么说明中间有数据尚未写入，出现了乱序，暗示可能有消息丢失，对应的生产者会抛出OutOfOrderSequenceException，这个异常是一个严重的异常，后续的诸如 send（）、beginTransaction（）、commitTransaction（）等方法的调用都会抛出IllegalStateException的异常。</li>
<li>引入序列号来实现幂等也只是针对每一对＜PID，分区＞而言的，也就是说，Kafka的幂等只能保证单个生产者会话（session）中单分区的幂等。</li>
</ul>
<h3 id="事务——"><a href="#事务——" class="headerlink" title="事务——"></a>事务——</h3><p>幂等性并不能跨多个分区运作，而事务[1]可以弥补这个缺陷。事务可以保证对多个分区写入操作的原子性。</p>
<ul>
<li>对流式应用（Stream Processing Applications）而言，一个典型的应用模式为“consume-transform-produce”。在这种模式下消费和生产并存，</li>
<li>Kafka 中的事务可以使应用程序将消费消息、生产消息、提交消费位移当作原子操作来处理，同时成功或失败，即使该生产或消费会跨多个分区。</li>
<li>为了实现事务，应用程序必须提供唯一的 transactionalId，这个 transactionalId通过客户端参数transactional.id来显式设置</li>
<li>事务要求生产者开启幂等特性，因此通过将transactional.id参数设置为非空从而开启事务特性的同时需要将 enable.idempotence 设置为 true</li>
<li>transactionalId与PID一一对应，两者之间所不同的是transactionalId由用户显式设置，而PID是由Kafka内部分配的。</li>
<li>为了保证新的生产者启动后具有相同transactionalId的旧生产者能够立即失效，每个生产者通过transactionalId获取PID的同时，还会获取一个单调递增的producer epoch</li>
<li>如果使用同一个transactionalId开启两个生产者，那么前一个开启的生产者会报出如下的错误</li>
</ul>
<p>从生产者的角度分析，通过事务，Kafka 可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复。</p>
<ul>
<li>前者表示具有相同 transactionalId 的新生产者实例被创建且工作的时候，旧的且拥有相同transactionalId的生产者实例将不再工作。</li>
<li>后者指当某个生产者实例宕机后，新的生产者实例可以保证任何未完成的旧事务要么被提交（Commit），要么被中止（Abort），如此可以使新的生产者实例从一个正常的状态开始工作。</li>
</ul>
<p>而从消费者的角度分析，事务能保证的语义相对偏弱。出于以下原因，Kafka 并不能保证已提交的事务中的所有消息都能够被消费：</p>
<ul>
<li>对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理（相同key的消息，后写入的消息会覆盖前面写入的消息）</li>
<li>事务中消息可能分布在同一个分区的多个日志分段（LogSegment）中，当老的日志分段被删除时，对应的消息可能会丢失。</li>
<li>消费者可以通过seek（）方法访问任意offset的消息，从而可能遗漏事务中的部分消息。</li>
<li>消费者在消费时可能没有分配到事务内的所有分区，如此它也就不能读取事务中的所有消息。</li>
</ul>
<img src="/2021/06/26/7-%E6%B7%B1%E5%85%A5%E5%AE%A2%E6%88%B7%E7%AB%AF/%E4%BA%8B%E5%8A%A1%E7%9B%B8%E5%85%B3.png" class="">

<ul>
<li>initTransactions（）方法用来初始化事务，这个方法能够执行的前提是配置了transactionalId</li>
<li>beginTransaction（）方法用来开启事务；</li>
<li>sendOffsetsToTransaction（）方法为消费者提供在事务内的位移提交的操作；</li>
<li>commitTransaction（）方法用来提交事务；</li>
<li>abortTransaction（）方法用来中止事务，类似于事务回滚。</li>
</ul>
<p>在消费端有一个参数isolation.level，与事务有着莫大的关联，这个参数的默认值为“read_uncommitted”</p>
<ul>
<li>设置为“read_committed”的消费端应用是消费不到这些消息的，不过在KafkaConsumer内部会缓存这些消息，直到生产者执行 commitTransaction（）方法之后它才能将这些消息推送给消费端应用。反之，如果生产者执行了 abortTransaction（）方法，那么 KafkaConsumer 会将这些缓存的消息丢弃而不推送给消费端应用。</li>
</ul>
<p>日志文件中除了普通的消息，还有一种消息专门用来标志一个事务的结束，它就是控制消息（ControlBatch）。</p>
<ul>
<li>控制消息一共有两种类型：COMMIT和ABORT，分别用来表征事务已经成功提交或已经被成功中止。</li>
<li>KafkaConsumer 可以通过这个控制消息来判断对应的事务是被提交了还是被中止了，然后结合参数isolation.level配置的隔离级别来决定是否将相应的消息返回给消费端应用，</li>
</ul>
<img src="/2021/06/26/7-%E6%B7%B1%E5%85%A5%E5%AE%A2%E6%88%B7%E7%AB%AF/%E6%B6%88%E8%B4%B9%E7%94%9F%E4%BA%A7.png" class="">

<ul>
<li>查找TransactionCoordinator<ul>
<li>TransactionCoordinator负责分配PID和管理事务，因此生产者要做的第一件事情就是找出对应的TransactionCoordinator所在的broker节点。</li>
<li>与查找GroupCoordinator节点一样，也是通过FindCoordinatorRequest请求来实现的，只不过FindCoordinatorRequest中的coordinator_type就由原来的0变成了1，由此来表示与事务相关联</li>
<li>Kafka 在收到 FindCoorinatorRequest 请求之后，会根据 coordinator_key （也就是transactionalId）查找对应的TransactionCoordinator节点。</li>
<li>如果找到，则会返回其相对应的node_id、host和port信息。</li>
<li>具体查找TransactionCoordinator的方式是根据transactionalId的哈希值计算主题__transaction_state中的分区编号，</li>
<li>找到对应的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为这个transactionalId对应的TransactionCoordinator节点。</li>
</ul>
</li>
<li>获取PID<ul>
<li>在找到TransactionCoordinator节点之后，就需要为当前生产者分配一个PID了。凡是开启了幂等性功能的生产者都必须执行这个操作，不需要考虑该生产者是否还开启了事务。</li>
<li>生产者获取PID的操作是通过InitProducerIdRequest请求来实现的</li>
<li>生产者的InitProducerIdRequest请求会被发送给TransactionCoordinator。</li>
<li>如果未开启事务特性而只开启幂等特性，那么 InitProducerIdRequest 请求可以发送给任意的 broker。</li>
<li>当TransactionCoordinator第一次收到包含该transactionalId的InitProducerIdRequest请求时，它会把transactionalId和对应的PID以消息（我们习惯性地把这类消息称为“事务日志消息”）的形式保存到主题__transaction_state中</li>
<li>与InitProducerIdRequest对应的InitProducerIdResponse响应体结构如图7-24所示，除了返回PID，InitProducerIdRequest还会触发执行以下任务<ul>
<li>增加该 PID 对应的 producer_epoch。具有相同 PID 但 producer_epoch 小于该producer_epoch的其他生产者新开启的事务将被拒绝。</li>
<li>恢复（Commit）或中止（Abort）之前的生产者未完成的事务</li>
</ul>
</li>
</ul>
</li>
<li>开启事务<ul>
<li>通过KafkaProducer的beginTransaction（）方法可以开启一个事务，调用该方法后，生产者本地会标记已经开启了一个新的事务，只有在生产者发送第一条消息之后 TransactionCoordinator才会认为该事务已经开启。</li>
</ul>
</li>
<li>Consume-Transform-Produce<ul>
<li>AddPartitionsToTxnRequest<ul>
<li>当生产者给一个新的分区（TopicPartition）发送数据前，它需要先向TransactionCoordinator发送AddPartitionsToTxnRequest请求（AddPartitionsToTxnRequest请求体结构如图7-25所示），这个请求会让 TransactionCoordinator 将＜transactionId，TopicPartition＞的对应关系存储在主题__transaction_state中</li>
</ul>
</li>
<li>ProduceRequest<ul>
<li>这一步骤很容易理解，生产者通过ProduceRequest 请求发送消息（ProducerBatch）到用户自定义主题中，这一点和发送普通消息时相同，</li>
</ul>
</li>
<li>AddOffsetsToTxnRequest<ul>
<li>通过KafkaProducer的sendOffsetsToTransaction（）方法可以在一个事务批次里处理消息的消费和发送，方法中包含2个参数：Map＜TopicPartition，OffsetAndMetadata＞ offsets和groupId。</li>
</ul>
</li>
<li>TxnOffsetCommitRequest<ul>
<li>这个请求也是sendOffsetsToTransaction（）方法中的一部分，在处理完AddOffsetsToTxnRequest之后，生产者还会发送 TxnOffsetCommitRequest 请求给 GroupCoordinator，从而将本次事务中包含的消费位移信息offsets存储到主题__consumer_offsets中</li>
</ul>
</li>
</ul>
</li>
<li>提交或者中止事务<ul>
<li>一旦数据被写入成功，我们就可以调用 KafkaProducer 的 commitTransaction（）方法或abortTransaction（）方法来结束当前的事务。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/" class="post-title-link" itemprop="url">6.深入服务端</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-25 13:57:01" itemprop="dateCreated datePublished" datetime="2021-06-25T13:57:01+08:00">2021-06-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-12 22:02:41" itemprop="dateModified" datetime="2021-07-12T22:02:41+08:00">2021-07-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本章涉及协议设计、时间轮、延迟操作、控制器及参数解密，尤其是协议设计和控制器的介绍，这些是深入了解Kafka的必备知识点。</p>
<h2 id="协议设计"><a href="#协议设计" class="headerlink" title="协议设计"></a>协议设计</h2><p>Kafka自定义了一组基于TCP的二进制协议，只要遵守这组协议的格式，就可以向Kafka发送消息，也可以从Kafka中拉取消息，或者做一些其他的事情，比如提交消费位移等。</p>
<p>一共包含了 43 种协议类型</p>
<ul>
<li>每种类型的Request都包含相同结构的协议请求头（RequestHeader）和不同结构的协议请求体（RequestBody）<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E5%8D%8F%E8%AE%AE%E8%AF%B7%E6%B1%82%E5%A4%B4.png" class=""><img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E8%AF%B7%E6%B1%82%E5%A4%B4%E8%A7%A3%E9%87%8A.png" class=""></li>
<li>每种类型的Response也包含相同结构的协议响应头（ResponseHeader）和不同结构的响应体（ResponseBody）<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E5%93%8D%E5%BA%94%E8%AF%B7%E6%B1%82%E5%A4%B4.png" class=""><img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" class=""><img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/request%E7%BB%93%E6%9E%84.png" class=""></li>
</ul>
<p>消息累加器 RecordAccumulator 中的消息是以＜分区，Deque＜ProducerBatch＞＞的形式进行缓存的，之后由Sender线程转变成＜Node，List＜ProducerBatch＞＞的形式，针对每个Node，Sender线程在发送消息前会将对应的List＜ProducerBatch＞形式的内容转变成 ProduceRequest 的具体结构。List＜ProducerBatch＞中的内容首先会按照主题名称进行分类（对应ProduceRequest中的域topic），然后按照分区编号进行分类（对应ProduceRequest中的域partition），分类之后的ProducerBatch集合就对应ProduceRequest中的域record_set。</p>
<h2 id="时间轮"><a href="#时间轮" class="headerlink" title="时间轮"></a>时间轮</h2><p>Kafka中存在大量的延时操作，比如延时生产、延时拉取和延时删除等。Kafka并没有使用JDK自带的Timer或DelayQueue（O(nlogn)）来实现延时的功能，而是基于时间轮的概念自定义实现了一个用于延时功能的定时器,而基于时间轮可以将插入和删除操作的时间复杂度都降为O（1）（SystemTimer）</p>
<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%97%B6%E9%97%B4%E8%BD%AE.png" class="">

<ul>
<li>Kafka中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）</li>
<li>TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务（TimerTask）。</li>
<li>时间轮由多个时间格组成，每个时间格代表当前时间轮的基本时间跨度（tickMs）。时间轮的时间格个数是固定的，可用wheelSize来表示，</li>
<li>那么整个时间轮的总体时间跨度（interval）可以通过公式 tickMs×wheelSize计算得出。</li>
<li>时间轮还有一个表盘指针（currentTime），用来表示时间轮当前所处的时间，currentTime是tickMs的整数倍</li>
<li>currentTime可以将整个时间轮划分为到期部分和未到期部分，currentTime当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的TimerTaskList中的所有任务。</li>
</ul>
<p>工作流程：</p>
<ul>
<li>若时间轮的tickMs为1ms且wheelSize等于20，那么可以计算得出总体时间跨度interval为20ms。</li>
<li>初始情况下表盘指针currentTime指向时间格0，此时有一个定时为2ms的任务插进来会存放到时间格为2的TimerTaskList中。</li>
<li>随着时间的不断推移，指针currentTime不断向前推进，过了2ms之后，当到达时间格2时，就需要将时间格2对应的TimeTaskList中的任务进行相应的到期操作。</li>
<li>此时若又有一个定时为 8ms 的任务插进来，则会存放到时间格 10 中，currentTime再过8ms后会指向时间格10。</li>
<li>如果同时有一个定时为19ms的任务插进来怎么办？新来的TimerTaskEntry会复用原来的TimerTaskList，所以它会插入原本已经到期的时间格1。</li>
<li>总之，整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间。</li>
<li>Kafka中不乏几万甚至几十万毫秒的定时任务，这个wheelSize的扩充没有底线，就算将所有的定时任务的到期时间都设定一个上限，比如100万毫秒，那么这个wheelSize为100万毫秒的时间轮不仅占用很大的内存空间，而且也会拉低效率。</li>
<li>Kafka 为此引入了<strong>层级时间轮的概念</strong>，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E5%B1%82%E7%BA%A7%E6%97%B6%E9%97%B4%E8%BD%AE.png" class=""></li>
<li>第一层的时间轮tickMs=1ms、wheelSize=20、interval=20ms。</li>
<li>第二层的时间轮的tickMs为第一层时间轮的interval，即20ms。每一层时间轮的wheelSize是固定的，都是20，那么第二层的时间轮的总体时间跨度interval为400ms。</li>
<li>以此类推，这个400ms也是第三层的tickMs的大小，第三层的时间轮的总体时间跨度为8000ms。</li>
<li>同理，也会有降级操作</li>
</ul>
<p>TimingWheel时还有一些小细节</p>
<ul>
<li>TimingWheel中的每个双向环形链表TimerTaskList都会有一个哨兵节点（sentinel），引入哨兵节点可以简化边界条件。哨兵节点也称为哑元节点（dummy node），它是一个附加的链表节点，该节点作为第一个节点，</li>
<li>Kafka 中的定时器只需持有 TimingWheel 的第一层时间轮的引用，并不会直接持有其他高层的时间轮，但每一层时间轮都会有一个引用（overflowWheel）指向更高一层的应用，以此层级调用可以实现定时器间接持有各个层级时间轮的引用。</li>
<li>并且会配合DelayQueue 完成工作，其中用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作</li>
<li>会有线程专门拿取DelayQueue中的到期的任务列表，推进时间轮，降级时间轮，处理操作</li>
</ul>
<h2 id="延时操作"><a href="#延时操作" class="headerlink" title="延时操作"></a>延时操作</h2><p>如果在使用生产者客户端发送消息的时候将 acks 参数设置为-1，那么就意味着需要等待ISR集合中的所有副本都确认收到消息之后才能正确地收到响应的结果，或者捕获超时异常。</p>
<p>在Kafka中有多种延时操作，比如前面提及的延时生产，还有延时拉取（DelayedFetch）、延时数据删除（DelayedDeleteRecords）等。</p>
<ul>
<li>延时操作创建之后会被加入延时操作管理器（DelayedOperationPurgatory）来做专门的处理。延时操作有可能会超时，每个延时操作管理器都会配备一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现的</li>
<li>时间轮的轮转是靠“收割机”线程ExpiredOperationReaper来驱动的，这里的“收割机”线程就是由延时操作管理器启动的。</li>
<li>定时器、“收割机”线程和延时操作管理器都是一一对应的。</li>
<li>延时操作需要支持外部事件的触发，所以还要配备一个监听池来负责监听每个分区的外部事件—查看是否有分区的HW发生了增长。另外需要补充的是，ExpiredOperationReaper不仅可以推进时间轮，还会定期清理监听池中已完成的延时操作。<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E5%BB%B6%E6%97%B6%E7%94%9F%E4%BA%A7%E7%BB%86%E8%8A%82.png" class=""></li>
</ul>
<p>延时拉取</p>
<p>Kafka在处理拉取请求时，会先读取一次日志文件，如果收集不到足够多（fetchMinBytes，由参数fetch.min.bytes配置，默认值为1）的消息，那么就会创建一个延时拉取操作（DelayedFetch）以等待拉取到足够数量的消息。当延时拉取操作执行时，会再读取一次日志文件，然后将拉取结果返回给 follower 副本。延时拉取操作也会有一个专门的延时操作管理器负责管理，大体的脉络与延时生产操作相同，不再赘述。如果拉取进度一直没有追赶上leader副本，那么在拉取leader副本的消息时一般拉取的消息大小都会不小于fetchMinBytes，这样Kafka也就不会创建相应的延时拉取操作，而是立即返回拉取结果。如果是follower副本的延时拉取，它的外部事件就是消息追加到了leader副本的本地日志文件中；如果是消费者客户端的延时拉取，它的外部事件可以简单地理解为HW的增长。</p>
<p>目前版本的Kafka还引入了事务的概念，对于消费者或follower副本而言，其默认的事务隔离级别为“read_uncommitted”。不过消费者可以通过客户端参数isolation.level将事务隔离级别设置为“read_committed”（注意：follower副本不可以将事务隔离级别修改为这个值），这样消费者拉取不到生产者已经写入却尚未提交的消息。对应的消费者的延时拉取，它的外部事件实际上会切换为由LSO<br>（LastStableOffset）的增长来触发。LSO是HW之前除去未提交的事务消息的最大偏移量，LSO≤HW，有关事务和LSO的内容可以分别参考7.4节和10.2节。</p>
<h2 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h2><ul>
<li>在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态。</li>
<li>当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。</li>
<li>当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。</li>
<li>当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。</li>
</ul>
<h3 id="控制器的选举及异常恢复"><a href="#控制器的选举及异常恢复" class="headerlink" title="控制器的选举及异常恢复"></a>控制器的选举及异常恢复</h3><p>Kafka中的控制器选举工作依赖于ZooKeeper，成功竞选为控制器的broker会在ZooKeeper中创建/controller这个临时（EPHEMERAL）节点，此临时节点的内容参考如下：</p>
<ul>
<li>在任意时刻，集群中有且仅有一个控制器。每个 broker 启动的时候会去尝试读取/controller节点的brokerid的值，如果读取到brokerid的值不为-1，则表示已经有其他 broker 节点成功竞选为控制器，所以当前 broker 就会放弃竞选</li>
<li>如果 ZooKeeper 中不存在/controller节点，或者这个节点中的数据异常，那么就会尝试去创建/controller节点。</li>
<li>当前broker去创建节点的时候，也有可能其他broker同时去尝试创建这个节点，只有创建成功的那个broker才会成为控制器，而创建失败的broker竞选失败</li>
<li>每个broker都会在内存中保存当前控制器的brokerid值，这个值可以标识为activeControllerId。</li>
<li>ZooKeeper 中还有一个与控制器有关的/controller_epoch 节点，这个节点是持久（PERSISTENT）节点，节点中存放的是一个整型的controller_epoch值。controller_epoch用于记录控制器发生变更的次数，即记录当前的控制器是第几代控制器，我们也可以称之为“控制器的纪元”。</li>
<li>由此可见，Kafka 通过 controller_epoch 来保证控制器的唯一性，进而保证相关操作的一致性。</li>
</ul>
<p>具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下</p>
<ul>
<li>监听分区相关的变化。为ZooKeeper中的/admin/reassign_partitions 节点注册 PartitionReassignmentHandler，用来处理分区重分配的动作。为 ZooKeeper 中的/isr_change_notification节点注册IsrChangeNotificetionHandler，用来处理ISR集合变更的动作。为ZooKeeper中的/admin/preferred-replica-election节点添加PreferredReplicaElectionHandler，用来处理优先副本的选举动作。</li>
<li>监听主题相关的变化。为 ZooKeeper 中的/brokers/topics 节点添加TopicChangeHandler，用来处理主题增减的变化；为 ZooKeeper 中的/admin/delete_topics节点添加TopicDeletionHandler，用来处理删除主题的动作。</li>
<li>监听broker相关的变化。为ZooKeeper中的/brokers/ids节点添加BrokerChangeHandler，用来处理broker增减的变化。</li>
<li>从ZooKeeper中读取获取当前所有与主题、分区及broker有关的信息并进行相应的管理。对所有主题对应的 ZooKeeper 中的/brokers/topics/＜topic＞节点添加PartitionModificationsHandler，用来监听主题中的分区分配变化。</li>
<li>启动并管理分区状态机和副本状态机。</li>
<li>更新集群的元数据信息。</li>
<li>如果参数 auto.leader.rebalance.enable 设置为 true，则还会开启一个名为“auto-leader-rebalance-task”的定时任务来负责维护分区的优先副本的均衡。<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%8E%A7%E5%88%B6%E5%99%A8.png" class=""></li>
<li>在目前的新版本的设计中，只有Kafka Controller在ZooKeeper上注册相应的监听器，其他的broker极少需要再监听ZooKeeper中的数据变化，这样省去了很多不必要的麻烦。不过每个broker还是会对/controller节点添加监听器，以此来监听此节点的数据变化（ControllerChangeHandler）。</li>
<li>当/controller 节点的数据发生变化时，每个 broker 都会更新自身内存中保存的activeControllerId。如果broker 在数据变更前是控制器，在数据变更后自身的 brokerid 值与新的 activeControllerId 值不一致，那么就需要“退位”，关闭相应的资源，比如关闭状态机、注销相应的监听器等。</li>
<li>当/controller节点被删除时，每个broker都会进行选举，如果broker在节点被删除前是控制器，那么在选举前还需要有一个“退位”的动作。如果有特殊需要，则可以手动删除/controller 节点来触发新一轮的选举。当然关闭控制器所对应的 broker，以及手动向/controller节点写入新的brokerid的所对应的数据，同样可以触发新一轮的选举。</li>
</ul>
<h3 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h3><ol>
<li>获取Kafka的服务进程号PIDS。可以使用Java中的jps命令或使用Linux系统中的ps命令来查看。</li>
<li>使用 kill-s TERM $PIDS 或 kill-15 $PIDS 的方式来关闭进程，注意千万不要使用kill-9的方式。<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E5%85%B3%E9%97%AD.png" class=""></li>
</ol>
<h3 id="分区leader的选举"><a href="#分区leader的选举" class="headerlink" title="分区leader的选举"></a>分区leader的选举</h3><p>分区leader副本的选举由控制器负责具体实施。当创建分区（创建主题或增加分区都有创建分区的动作）或分区上线（比如分区中原先的leader副本下线，此时分区需要选举一个新的leader 上线来对外提供服务）的时候都需要执行 leader 的选举动作，对应的选举策略为OfflinePartitionLeaderElectionStrategy。</p>
<ul>
<li>这种策略的基本思路是按照 AR 集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。</li>
<li>一个分区的AR集合在分配的时候就被指定，并且只要不发生重分配的情况，集合内部副本的顺序是保持不变的，而分区的ISR集合中副本的顺序可能会改变。</li>
<li>注意这里是根据AR的顺序而不是ISR的顺序进行选举的。</li>
<li>如果ISR集合中没有可用的副本，那么此时还要再检查一下所配置的unclean.leader.election.enable参数（默认值为false）。如果这个参数配置为true，那么表示允许从非ISR列表中的选举leader，从AR列表中找到第一个存活的副本即为leader。</li>
</ul>
<p>当分区进行重分配（可以先回顾一下4.3.2节的内容）的时候也需要执行leader的选举动作，对应的选举策略为 ReassignPartitionLeaderElectionStrategy。</p>
<ul>
<li>从重分配的AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中。</li>
<li>当发生优先副本（可以先回顾一下4.3.1节的内容）的选举时，直接将优先副本设置为leader即可，AR集合中的第一个副本即为优先副本（PreferredReplicaPartitionLeaderElectionStrategy）。</li>
</ul>
<p>还有一种情况会发生 leader 的选举，当某节点被优雅地关闭（也就是执行ControlledShutdown）时，位于这个节点上的leader副本都会下线，所以与此对应的分区需要执行leader的选举。</p>
<ul>
<li>从AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中，与此同时还要确保这个副本不处于正在被关闭的节点上。</li>
</ul>
<h2 id="参数解密"><a href="#参数解密" class="headerlink" title="参数解密"></a>参数解密</h2><h3 id="broker-id"><a href="#broker-id" class="headerlink" title="broker.id"></a>broker.id</h3><ul>
<li>broker.id是broker在启动之前必须设定的参数之一，在Kafka集群中，每个broker都有唯一的 id（也可以记作 brokerId）值用来区分彼此。</li>
<li>broker 在启动时会在 ZooKeeper 中的/brokers/ids路径下创建一个以当前brokerId为名称的虚节点，broker的健康状态检查就依赖于此虚节点。</li>
<li>当 broker 下线时，该虚节点会自动删除，其他 broker 节点或客户端通过判断/brokers/ids路径下是否有此broker的brokerId节点来确定该broker的健康状态。</li>
<li>config/server.properties 里的 broker.id 参数来配置brokerId，默认情况下broker.id值为-1。</li>
<li>在Kafka中，brokerId值必须大于等于0才有可能正常启动，但这里并不是只能通过配置文件config/server.properties来设定这个值，还可以通过meta.properties文件或自动生成功能来实现。</li>
</ul>
<p>meta.properties文件与broker.id的关联如下</p>
<ul>
<li>如果 log.dir 或 log.dirs 中配置了多个日志根目录，这些日志根目录中的meta.properties文件所配置的broker.id不一致则会抛出InconsistentBrokerIdException的异常。</li>
<li>如果config/server.properties配置文件里配置的broker.id的值和meta.properties文件里的broker.id值不一致，那么同样会抛出InconsistentBrokerIdException的异常。</li>
<li>如果 config/server.properties 配置文件中并未配置 broker.id 的值，那么就以meta.properties文件中的broker.id值为准。</li>
<li>如果没有meta.properties文件，那么在获取合适的broker.id值之后会创建一个新的meta.properties文件并将broker.id值存入其中。</li>
<li>如果两个文件中都没有broker.id，Kafka 还提供了另外两个 broker 端参数：broker.id.generation.enable 和reserved.broker.max.id来配合生成新的brokerId。<ul>
<li>broker.id.generation.enable参数用来配置是否开启自动生成 brokerId 的功能，默认情况下为 true，即开启此功能。</li>
<li>自动生成的 brokerId 有一个基准值，即自动生成的 brokerId 必须超过这个基准值，这个基准值通过reserverd.broker.max.id参数配置，默认值为1000。也就是说，默认情况下自动生成的brokerId从1001开始。</li>
<li>自动生成的brokerId的原理是先往ZooKeeper中的/brokers/seqid节点中写入一个空字符 串，然 后 获 取 返 回 的 Stat 信 息 中 的 version 值，进 而 将 version 的 值 和reserved.broker.max.id参数配置的值相加。先往节点中写入数据再获取Stat信息，这样可以确保返回的 version 值大于 0，进而就可以确保生成的 brokerId 值大于reserved.broker.max.id 参数配置的值，符合非自动生成的 broker.id 的值在[0，reserved.broker.max.id]区间设定。</li>
</ul>
</li>
</ul>
<h3 id="bootstrap-servers"><a href="#bootstrap-servers" class="headerlink" title="bootstrap.servers"></a>bootstrap.servers</h3><ul>
<li>我们一般可以简单地认为 bootstrap.servers 这个参数所要指定的就是将要连接的Kafka集群的broker地址列表。</li>
<li>不过从深层次的意义上来讲，这个参数配置的是用来发现Kafka集群元数据信息的服务地址。<img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/bootstrap%E5%8E%9F%E7%90%86.png" class=""></li>
</ul>
<p>客户端KafkaProducer1与Kafka Cluster直连，这是客户端给我们的既定印象，而事实上客户端连接Kafka集群要经历以下3个过程</p>
<ul>
<li>客户端KafkaProducer2与bootstrap.servers参数所指定的Server连接，并发送MetadataRequest请求来获取集群的元数据信息。</li>
<li>Server在收到MetadataRequest请求之后，返回MetadataResponse给KafkaProducer2，在MetadataResponse中包含了集群的元数据信息。</li>
<li>客户端KafkaProducer2收到的MetadataResponse之后解析出其中包含的集群元数据信息，然后与集群中的各个节点建立连接，之后就可以发送消息了。</li>
</ul>
<p>在绝大多数情况下，Kafka 本身就扮演着第一步和第二步中的 Server 角色，我们完全可以将这个Server的角色从Kafka中剥离出来。我们可以在这个Server的角色上大做文章，比如添加一些路由的功能、负载均衡的功能。</p>
<p>bootstrap.servers、metadata.broker.list、zookeeper.connect 参数往往不是很清楚。这一现象还存在Kafka所提供的诸多脚本之中，在这些脚本中连接Kafka采用的选项参数有–bootstrap-server、–broker-list和–zookeeper</p>
<ul>
<li>bootstrap-server是broker-list 的替代品，但是kafka-console-producer.sh 还在使用</li>
<li>zookeeper 命令是kafka-topics.sh脚本实际上操纵的就是ZooKeeper中的节点，而不是Kafka本身，它并没有被替代的必要。</li>
</ul>
<h3 id="服务端参数列表"><a href="#服务端参数列表" class="headerlink" title="服务端参数列表"></a>服务端参数列表</h3>  <img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%82%E6%95%B01.png" class="">  <img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%82%E6%95%B02.png" class="">  <img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%82%E6%95%B03.png" class="">  <img src="/2021/06/25/6-%E6%B7%B1%E5%85%A5%E6%9C%8D%E5%8A%A1%E7%AB%AF/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%82%E6%95%B04.png" class="">

<h2 id="元数据更新"><a href="#元数据更新" class="headerlink" title="元数据更新"></a>元数据更新</h2><p>broker是有状态的服务：每台broker在内存中都维护了集群上所有节点和topic分区的状态信息——Kafka称这部分状态信息为元数据缓存(metadata cache)。本文就将讨论一下这个metadata cache的设计与实现。</p>
<h3 id="cache里面存了什么"><a href="#cache里面存了什么" class="headerlink" title="cache里面存了什么"></a>cache里面存了什么</h3><p>首先，我们来看下cache里面都存了什么，我们以Kafka 1.0.0版本作为分析对象。Metadata cache中保存的信息十分丰富，几乎囊括了Kafka集群的各个方面，它包含了：</p>
<ul>
<li>controller所在的broker ID，即保存了当前集群中controller是哪台broker</li>
<li>集群中所有broker的信息：比如每台broker的ID、机架信息以及配置的若干组连接信息(比如配置了PLAINTEXT和SASL监听器就有两套连接信息，分别使用不同的安全协议和端口，甚至主机名都可能不同)</li>
<li>集群中所有节点的信息：严格来说，它和上一个有些重复，不过此项是按照broker ID和监听器类型进行分组的。对于超大集群来说，使用这一项缓存可以快速地定位和查找给定节点信息，而无需遍历上一项中的内容，算是一个优化吧</li>
<li>集群中所有分区的信息：所谓分区信息指的是分区的leader、ISR和AR信息以及当前处于offline状态的副本集合。这部分数据按照topic和分区ID进行分组，可以快速地查找到每个分区的当前状态。（注：AR表示assigned replicas，即创建topic时为该分区分配的副本集合）</li>
</ul>
<h3 id="每台broker都保存相同的cache吗？"><a href="#每台broker都保存相同的cache吗？" class="headerlink" title="每台broker都保存相同的cache吗？"></a>每台broker都保存相同的cache吗？</h3><p>　　是的，至少Kafka在设计时的确是这样的愿景：每台Kafka broker都要维护相同的缓存，这样客户端程序(clients)随意地给任何一个broker发送请求都能够获取相同的数据，这也是为什么任何一个broker都能处理clients发来的Metadata请求的原因：因为每个broker上都有这些数据！要知道目前Kafka共有38种请求类型，能做到这一点的可谓少之又少。每个broker都能处理的能力可以缩短请求被处理的延时从而提高整体clients端的吞吐，因此用空间去换一些时间的做法是值得的。</p>
<h3 id="cache是怎么更新的？"><a href="#cache是怎么更新的？" class="headerlink" title="cache是怎么更新的？"></a>cache是怎么更新的？</h3><p>　　如前所述，用空间去换时间，好处是降低了延时，提升了吞吐，但劣势就在于你需要处理cache的更新并且维护一致性。目前Kafka是怎么更新cache的？简单来说，就是通过发送异步更新请求(UpdateMetadata request)来维护一致性的。既然是异步的，那么在某一个时间点集群上所有broker的cache信息就未必是严格相同的。只不过在实际使用场景中，这种弱一致性似乎并没有太大的问题。原因如下：</p>
<ol>
<li>clients并不是时刻都需要去请求元数据的，且会缓存到本地；</li>
<li>即使获取的元数据无效或者过期了，clients通常都有重试机制，可以去其他broker上再次获取元数据;</li>
<li>cache更新是很轻量级的，仅仅是更新一些内存中的数据结构，不会有太大的成本。因此我们还是可以安全地认为每台broker上都有相同的cache信息。</li>
</ol>
<p>　　具体的更新操作实际上是由controller来完成的。controller会在一定场景下向特定broker发送UpdateMetadata请求令这些broker去更新它们各自的cache，这些broker一旦接收到请求便开始全量更新——即清空当前所有cache信息，使用UpdateMetadata请求中的数据来重新填充cache。</p>
<h3 id="cache什么时候更新？"><a href="#cache什么时候更新？" class="headerlink" title="cache什么时候更新？"></a>cache什么时候更新？</h3><p>　　实际上这个问题等同于：controller何时向特定broker发送UpdateMetadata请求？ 如果从源码开始分析，那么涉及到的场景太多了，比如controller启动时、新broker启动时、更新broker时、副本重分配时等等。我们只需要记住：<strong>只要集群中有broker或分区数据发生了变更就需要更新这些cache</strong></p>
<p>　　举个经常有人问的例子：集群中新增加的broker是如何获取这些cache，并且其他broker是如何知晓它的？当有新broker启动时，它会在Zookeeper中进行注册，此时监听Zookeeper的controller就会立即感知这台新broker的加入，此时controller会更新它自己的缓存（注意：这是controller自己的缓存，不是本文讨论的metadata cache）把这台broker加入到当前broker列表中，之后它会发送UpdateMetadata请求给集群中所有的broker(也包括那台新加入的broker)让它们去更新metadata cache。一旦这些broker更新cache完成，它们就知道了这台新broker的存在，同时由于新broker也更新了cache，故现在它也有了集群所有的状态信息。</p>
<h3 id="目前的问题？"><a href="#目前的问题？" class="headerlink" title="目前的问题？"></a>目前的问题？</h3><p>　　前面说过了，现在更新cache完全由controller来驱动，故controller所在broker的负载会极大地影响这部分操作（实际上，它会影响所有的controller操作）。根据目前的设计，controller所在broker依然作为一个普通broker执行其他的clients请求处理逻辑，所以如果controller broker一旦忙于各种clients请求(比如生产消息或消费消息)，那么这种更新操作的请求就会积压起来(backlog)，造成了更新操作的延缓甚至是被取消。究其根本原因在于当前controller对待数据类请求和控制类请求并无任何优先级化处理——controller一视同仁地对待这些请求，而实际上我们更希望controller能否赋予控制类请求更高的优先级。社区目前已经开始着手改造当前的设计，相信在未来的版本中此问题可以得到解决。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/" class="post-title-link" itemprop="url">5.日志存储</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-25 10:04:59 / 修改时间：20:42:44" itemprop="dateCreated datePublished" datetime="2021-06-25T10:04:59+08:00">2021-06-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="文件目录布局"><a href="#文件目录布局" class="headerlink" title="文件目录布局"></a>文件目录布局</h2><ul>
<li>主题，分区是逻辑上的概念，物理上没有对应的东西</li>
<li>log或者说副本在物理存储上对应了目录，例如topic-log-0 ，其是＜topic＞-＜partition＞的文件夹</li>
<li>每个log中有多个logsegment 概念，多个分段，其实就是数据的拆分</li>
<li>每个分段又包含了.log .index .timeindex 等文件，还可能包含“.deleted”“.cleaned”“.swap”等临时文件，以及可能的“.snapshot”“.txnindex”“leader-epoch-checkpoint”等文件。<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8.png" class="">
<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/%E5%B8%83%E5%B1%80.png" class=""></li>
</ul>
<h2 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h2><p>其实和redis 类似，减少了一些元数据信息,并增加了其他可变数据类型</p>
<h2 id="消息格式v2版本"><a href="#消息格式v2版本" class="headerlink" title="消息格式v2版本"></a>消息格式v2版本</h2><ul>
<li>v2版本中消息集称为Record Batch，而不是先前的Message Set，其内部也包含了一条或多条消息，</li>
<li>生产者客户端中的ProducerBatch对应这里的RecordBatch，而ProducerRecord对应这里的Record。<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/v2.png" class="">
详细见深入理解kafka</li>
</ul>
<h2 id="日志索引"><a href="#日志索引" class="headerlink" title="日志索引"></a>日志索引</h2><ul>
<li>Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。</li>
<li>稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。</li>
<li>使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。</li>
</ul>
<p>日志切分</p>
<ol>
<li>当前日志分段文件的大小超过了 broker 端参数 log.segment.bytes 配置的值。log.segment.bytes参数的默认值为1073741824，即1GB。</li>
<li>当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天。</li>
<li>偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。log.index.size.max.bytes的默认值为10485760，即10MB。</li>
<li>追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量（offset-baseOffset＞Integer.MAX_VALUE）。</li>
</ol>
<p>位置索引和时间索引都是为了加速查找</p>
<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/%E6%97%B6%E9%97%B4%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95.png" class="">

<h2 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h2><ol>
<li>日志删除（Log Retention）：按照一定的保留策略直接删除不符合条件的日志分段。、<ul>
<li>基于时间，log.retention.hours参数，其值为168，故默认情况下日志分段文件的保留时间为7天。</li>
<li>基于日志大小。retentionSize可以通过broker端参数log.retention.bytes来配置，默认值为-1，表示无穷大。</li>
<li>基于日志起始偏移量。</li>
</ul>
</li>
<li>日志压缩（Log Compaction）：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。</li>
</ol>
<h2 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a>磁盘存储</h2><p>Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作，所以就算 Kafka使用磁盘作为存储介质，它所能承载的吞吐量也不容小觑。</p>
<h3 id="页缓存"><a href="#页缓存" class="headerlink" title="页缓存"></a>页缓存</h3><ul>
<li>当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页（page）是否在页缓存（pagecache）中，如果存在（命中）则直接返回数据，从而避免了对物理磁盘的 I/O 操作；</li>
<li>如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。</li>
<li>如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性。</li>
<li>Linux操作系统中的vm.dirty_background_ratio参数用来指定当脏页数量达到系统内存的百分之多少之后就会触发 pdflush/flush/kdmflush 等后台回写进程的运行来处理脏页，一般设置为小于10的值即可</li>
<li>在Kafka中同样提供了同步刷盘及间断性强制刷盘（fsync）的功能，这些功能可以通过 log.flush.interval.messages、log.flush.interval.ms 等参数来控制。</li>
<li>最好关闭swap vm.swappiness 建议将这个参数的值设置为 1（1-100），这样保留了swap的机制而又最大限度地限制了它对Kafka性能的影响</li>
</ul>
<h3 id="磁盘I-O流程"><a href="#磁盘I-O流程" class="headerlink" title="磁盘I/O流程"></a>磁盘I/O流程</h3><p>从编程角度而言，一般磁盘I/O的场景有以下四种</p>
<ul>
<li>用户调用标准C库进行I/O操作，数据流为：应用程序buffer→C库标准IObuffer→文件系统页缓存→通过具体文件系统到磁盘。</li>
<li>用户调用文件 I/O，数据流为：应用程序buffer→文件系统页缓存→通过具体文件系统到磁盘。</li>
<li>用户打开文件时使用O_DIRECT，绕过页缓存直接读写磁盘。</li>
<li>用户使用类似dd工具，并使用direct参数，绕过系统cache与文件系统直接写磁盘。</li>
</ul>
<ol>
<li>写操作：<ul>
<li>用户调用fwrite把数据写入C库标准IObuffer后就返回，即写操作通常是异步操作；</li>
<li>数据写入C库标准IObuffer后，不会立即刷新到磁盘，会将多次小数据量相邻写操作先缓存起来合并，最终调用write函数一次性写入（或者将大块数据分解多次write 调用）页缓存；</li>
<li>数据到达页缓存后也不会立即刷新到磁盘，内核有 pdflush 线程在不停地检测脏页，判断是否要写回到磁盘，如果是则发起磁盘I/O请求。</li>
</ul>
</li>
<li>读操作：<ul>
<li>用户调用fread到C库标准IObuffer中读取数据，如果成功则返回，否则继续；</li>
<li>到页缓存中读取数据，如果成功则返回，否则继续；</li>
<li>发起 I/O 请求，读取数据后缓存buffer和C库标准IObuffer并返回。可以看出，读操作是同步请求。</li>
</ul>
</li>
<li>I/O请求处理：<ul>
<li>通用块层根据I/O请求构造一个或多个bio结构并提交给调度层；</li>
<li>调度器将 bio 结构进行排序和合并组织成队列且确保读写操作尽可能理想：将一个或多个进程的读操作合并到一起读，将一个或多个进程的写操作合并到一起写，尽可能变随机为顺序（因为随机读写比顺序读写要慢），读必须优先满足，而写也不能等太久。<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/io.png" class=""></li>
</ul>
</li>
</ol>
<p>针对不同的应用场景，I/O调度策略也会影响I/O的读写性能，目前Linux系统中的I/O调度策略有4种，分别为NOOP、CFQ、DEADLINE和ANTICIPATORY，默认为CFQ。</p>
<ul>
<li>NOOP NOOP算法的全写为No Operation。该算法实现了最简单的FIFO队列，所有I/O请求大致按照先来后到的顺序进行操作。之所以说“大致”，原因是NOOP在FIFO的基础上还做了相邻I/O请求的合并，并不是完全按照先进先出的规则满足I/O请求。</li>
<li>CFQ CFQ算法的全写为Completely Fair Queuing。该算法的特点是按照I/O请求的地址进行排序，而不是按照先来后到的顺序进行响应。相比于NOOP的缺点是，先来的I/O请求并不一定能被满足，可能会出现“饿死”的情况。</li>
<li>DEADLINE DEADLINE在CFQ的基础上，解决了I/O请求“饿死”的极端情况。除了CFQ本身具有的I/O排序队列，DEADLINE额外分别为读I/O和写I/O提供了FIFO队列。读FIFO队列的最大等待时间为500ms，写FIFO队列的最大等待时间为5s。FIFO队列内的I/O请求优先级要比CFQ队列中的高，而读FIFO队列的优先级又比写FIFO队列的优先级高。</li>
<li>ANTICIPATORY ANTICIPATORY在DEADLINE的基础上，为每个读I/O都设置了6ms的等待时间窗口。如果在6ms内OS收到了相邻位置的读I/O请求，就可以立即满足</li>
</ul>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>将文件传出出去时，文件A经历了4次复制的过程：</p>
<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/%E9%9D%9E%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" class="">

<ul>
<li>调用read（）时，文件A中的内容被复制到了内核模式下的Read Buffer中。</li>
<li>CPU控制将内核模式数据复制到用户模式下。</li>
<li>调用write（）时，将用户模式下的内容复制到内核模式下的Socket Buffer中。</li>
<li>将内核模式下的Socket Buffer的数据复制到网卡设备中传送。</li>
</ul>
<p>从上面的过程可以看出，数据平白无故地从内核模式到用户模式“走了一圈”，浪费了 2次复制过程：第一次是从内核模式复制到用户模式；第二次是从用户模式再复制回内核模式，即上面4次过程中的第2步和第3步。而且在上面的过程中，内核和用户模式的上下文的切换也是4次。</p>
<img src="/2021/06/25/5-%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" class="">

<ul>
<li>零拷贝技术通过DMA（Direct Memory Access）技术将文件内容复制到内核模式下的Read Buffer 中。不过没有数据被复制到 Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到Socket Buffer</li>
<li>DMA引擎直接将数据从内核模式中传递到网卡设备（协议引擎）。这里数据只经历了2次复制就从磁盘中传送出去了，并且上下文切换也变成了2次。零拷贝是针对内核模式而言的，数据在内核模式下实现了零拷贝。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/24/4-%E4%B8%BB%E9%A2%98%E4%B8%8E%E5%88%86%E5%8C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/24/4-%E4%B8%BB%E9%A2%98%E4%B8%8E%E5%88%86%E5%8C%BA/" class="post-title-link" itemprop="url">4.主题与分区</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-24 18:54:23" itemprop="dateCreated datePublished" datetime="2021-06-24T18:54:23+08:00">2021-06-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-25 20:42:44" itemprop="dateModified" datetime="2021-06-25T20:42:44+08:00">2021-06-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>主题作为消息的归类，可以再细分为一个或多个分区，分区也可以看作对消息的二次归类。从Kafka的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。</p>
<p>主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是Log层面才有实际物理上的存在。</p>
<h2 id="主题管理"><a href="#主题管理" class="headerlink" title="主题管理"></a>主题管理</h2><ul>
<li>可以通过 Kafka提供的 kafka-topics.sh 脚本来执行这些操作<ul>
<li>其实质上是调用了kafka.admin.TopicCommand类来执行主题管理的操作。</li>
</ul>
</li>
<li>还可以通过KafkaAdminClient 的方式实现</li>
<li>直接操纵日志文件和ZooKeeper节点来实现。</li>
</ul>
<h3 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h3><ul>
<li>auto.create.topics.enable设置为true</li>
<li>那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为num.partitions （默认值为1）、副本因子为default.replication.factor（默认值为1）的主题。</li>
<li>当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会按照配置参数num.partitions和default.replication.factor的值来创建一个相应的主题。</li>
<li>不建议将auto.create.topics.enable参数设置为true</li>
<li>通过zookeeper /brokers/topics  可以查看主题分区情况</li>
<li>kafka-topics.sh脚本在创建主题时还会检测是否包含“.”或“_”字符。为什么要检测这两个字符呢？因为在Kafka的内部做埋点时会根据主题的名称来命名metrics的名称，并且会将点号“.”改成下画线“_”。假设遇到一个名称为“topic.1_2”的主题，还有一个名称为“topic_1.2”的主题，那么最后的metrics的名称都会为“topic_1_2”，这样就发生了名称冲突。</li>
</ul>
<h3 id="分区副本的分配"><a href="#分区副本的分配" class="headerlink" title="分区副本的分配"></a>分区副本的分配</h3><ul>
<li>生产者的分区分配是指为每条消息指定其所要发往的分区，</li>
<li>消费者中的分区分配是指为消费者指定其可以消费消息的分区</li>
<li>在创建主题时，如果使用了replica-assignment参数，那么就按照指定的方案来进行分区副本的创建</li>
</ul>
<h3 id="查看主题"><a href="#查看主题" class="headerlink" title="查看主题"></a>查看主题</h3><p>create list describe alter delete</p>
<h3 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h3><p>通过kafka-topics.sh 脚本中alter 指令提供</p>
<h2 id="分区管理"><a href="#分区管理" class="headerlink" title="分区管理"></a>分区管理</h2><h3 id="优先副本的选举"><a href="#优先副本的选举" class="headerlink" title="优先副本的选举"></a>优先副本的选举</h3><ul>
<li>分区使用多副本机制来提升可靠性，但只有leader副本对外提供读写服务，而follower副本只负责在内部进行消息的同步。</li>
<li>如果一个分区的leader副本不可用，那么就意味着整个分区变得不可用，此时就需要Kafka从剩余的follower副本中挑选一个新的leader副本来继续对外提供服务。</li>
<li>leader 副本个数的多少决定了这个节点负载的高低。</li>
<li>针对同一个分区而言，同一个broker节点中不可能出现它的多个副本，即Kafka集群的一个broker中最多只能有它的一个副本</li>
<li>我们可以将leader副本所在的broker节点叫作分区的leader节点，而follower副本所在的broker节点叫作分区的follower节点。</li>
<li>当原来的leader节点恢复之后重新加入集群时，它只能成为一个新的follower节点而不再对外提供服务。</li>
</ul>
<p>Kafka引入了优先副本（preferred replica）的概念。所谓的优先副本是指在 AR 集合列表中的第一个副本。</p>
<p>在 Kafka 中可以提供分区自动平衡的功能，与此对应的 broker 端参数是 auto.leader.rebalance.enable，此参数的默认值为true，即默认情况下此功能是开启的。</p>
<ul>
<li>如果开启分区自动平衡的功能，则 Kafka 的控制器会启动一个定时任务，这个定时任务会轮询所有的 broker节点，计算每个broker节点的分区不平衡率（broker中的不平衡率=非优先副本的leader个数/分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认值为 10%，如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡。</li>
<li>执行周期由参数leader.imbalance.check.interval.seconds控制，默认值为300秒，即5分钟。</li>
</ul>
<h3 id="分区重分配"><a href="#分区重分配" class="headerlink" title="分区重分配"></a>分区重分配</h3><p>当集群中加入节点或者减少节点时，需要重新分配分区，以达到负载均衡的目的</p>
<p>Kafka提供了 kafka-reassign-partitions.sh 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。</p>
<ul>
<li>首先创建需要一个包含主题清单的JSON 文件，</li>
<li>其次根据主题清单和 broker 节点清单生成一份重分配方案，</li>
<li>最后根据这份方案执行具体的重分配动作。</li>
<li>分区重分配的基本原理是先通过<strong>控制器</strong>为每个分区添加新副本（增加副本因子），</li>
<li>新的副本将从分区的leader副本那里复制所有的数据。</li>
<li>根据分区的大小不同，复制过程可能需要花一些时间，因为数据是通过网络复制到新副本上的。</li>
<li>在复制完成之后，控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）。</li>
<li>注意在重分配的过程中要确保有足够的空间。</li>
</ul>
<h3 id="复制限流"><a href="#复制限流" class="headerlink" title="复制限流"></a>复制限流</h3><p>kafka-config.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数：follower.replication.throttled.rate和leader.replication.throttled.rate，前者用于设置follower副本复制的速度，后者用于设置leader副本传输的速度，它们的单位都是B/s。</p>
<h3 id="修改副本因子"><a href="#修改副本因子" class="headerlink" title="修改副本因子"></a>修改副本因子</h3><p>创建主题之后我们还可以修改分区的个数，同样可以修改副本因子（副本数）。</p>
<h2 id="如何选择合适的分区数"><a href="#如何选择合适的分区数" class="headerlink" title="如何选择合适的分区数"></a>如何选择合适的分区数</h2><h3 id="性能测试工具"><a href="#性能测试工具" class="headerlink" title="性能测试工具"></a>性能测试工具</h3><p>Kafka 本身提供的用于生产者性能测试的 kafka-producer-perf-test.sh和用于消费者性能测试的kafka-consumer-perf-test.sh。</p>
<h3 id="分区数越多吞吐量就越高吗"><a href="#分区数越多吞吐量就越高吗" class="headerlink" title="分区数越多吞吐量就越高吗"></a>分区数越多吞吐量就越高吗</h3><p>分区是Kafka 中最小的并行操作单元，对生产者而言，每一个分区的数据写入是完全可以并行化的；对消费者而言，Kafka 只允许单个分区中的消息被一个消费者线程消费，一个消费组的消费并行度完全依赖于所消费的分区数。</p>
<p>本次案例中使用的测试环境为一个由3台普通云主机组成的3节点的Kafka集群，每台云主机的内存大小为8GB、磁盘大小为40GB、4核CPU的主频为2600MHz。JVM版本为1.8.0_112，Linux系统版本为2.6.32-504.23.4.el6.x86_64。</p>
<h3 id="分区数上限"><a href="#分区数上限" class="headerlink" title="分区数上限"></a>分区数上限</h3><p>由于文件描述符限制 ulimit -n，不能超过该值，会报错</p>
<h3 id="考量因素"><a href="#考量因素" class="headerlink" title="考量因素"></a>考量因素</h3><p>一个“恰如其分”的答案就是视具体情况而定。Kafka本身、业务应用、硬件资源、环境配置等多方面的考量而做出的选择。在设定完分区数，或者更确切地说是创建主题之后，还要对其追踪、监控、调优以求更好地利用它。</p>
<p>如果一定要给一个准则，则建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/" class="post-title-link" itemprop="url">3.消费者</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-22 17:11:12" itemprop="dateCreated datePublished" datetime="2021-06-22T17:11:12+08:00">2021-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-24 21:03:12" itemprop="dateModified" datetime="2021-06-24T21:03:12+08:00">2021-06-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="消费者与消费组"><a href="#消费者与消费组" class="headerlink" title="消费者与消费组"></a>消费者与消费组</h2><p>消费者（Consumer）负责订阅Kafka中的主题（Topic），并且从订阅的主题上拉取消息。<strong>与其他一些消息中间件不同的是：在Kafka的消费理念中还有一层消费组（Consumer Group）的概念</strong>，每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。</p>
<ul>
<li>每一个分区只能被一个消费组中的一个消费者所消费。</li>
<li>但是一味增加消费者个数，并不一定会增加消费能力，对于分区数固定的主题，当消费者个数大于分区数，就会有消费者不能分配到任何分区的情况</li>
<li>默认分区分配策略partition.assignment.strategy</li>
<li>消费组是一个逻辑上的概念，它将旗下的消费者归为一类，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串。</li>
<li>消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个线程，也可以是一个进程。同一个消费组内的消费者既可以部署在同一台机器上，也可以部署在不同的机器上。<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84.png" class=""></li>
</ul>
<h3 id="消息投递模式"><a href="#消息投递模式" class="headerlink" title="消息投递模式"></a>消息投递模式</h3><p>对于消息中间件而言，一般有两种消息投递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。kafka都支持，得益于消费者组</p>
<ul>
<li>如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。</li>
<li>如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。</li>
</ul>
<h2 id="客户端开发"><a href="#客户端开发" class="headerlink" title="客户端开发"></a>客户端开发</h2><h3 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h3><ul>
<li>配置消费者客户端参数及创建相应的消费者实例。</li>
<li>订阅主题。</li>
<li>拉取消息并消费。</li>
<li>提交消费位移。</li>
<li>关闭消费者实例。</li>
</ul>
<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E6%B6%88%E8%B4%B9%E8%80%85%E4%BB%A3%E7%A0%81.png" class=""> <img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E6%B6%88%E8%B4%B9%E8%80%85%E4%BB%A3%E7%A0%812.png" class="">

<h3 id="必要的参数配置"><a href="#必要的参数配置" class="headerlink" title="必要的参数配置"></a>必要的参数配置</h3><ul>
<li>在initConfig（）方法，在Kafka消费者客户端KafkaConsumer中有4个参数是必填的。<ul>
<li>bootstrap.servers：该参数的释义和生产者客户端 KafkaProducer 中的相同，用来 指 定 连 接 Kafka 集 群 所 需 的 broker 地 址 清 单，具 体 内 容 形 式 为host1：port1，host2：post，</li>
<li>group.id：消费者隶属的消费组的名称，默认值为“”。如果设置为空，则会报出异常：Exception in thread “main” org.apache.kafka.common.errors.InvalidGroupIdException：The configured groupId is invalid。一般而言，这个参数需要设置成具有一定的业务意义的名称。</li>
<li>key.deserializer 和 value.deserializer：与生产者客户端 KafkaProducer中的key.serializer和value.serializer参数对应。</li>
</ul>
</li>
</ul>
<h3 id="订阅主题与分区"><a href="#订阅主题与分区" class="headerlink" title="订阅主题与分区"></a>订阅主题与分区</h3><ul>
<li>订阅主题既可以以集合方式，也可以以正则表达式方式订阅（consumer.subscribe(Pattern.compile(“topic-.*”))），如图的构造函数<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E8%AE%A2%E9%98%85%E4%B8%BB%E9%A2%98.png" class=""></li>
<li>如果前后两次订阅了不同的主题，那么消费者以最后一次的为准。</li>
<li>其中一个构造参数ConsumerRebalance-Listener，这个是用来设置相应的再均衡监听器的</li>
<li>消费者不仅可以通过KafkaConsumer.subscribe（）方法订阅主题，还可以直接订阅某些主题的特定分区，在KafkaConsumer中还提供了一个assign（）方法来实现这些功能<ul>
<li>public void assign(Collection&lt; TopicPartition &gt; partitions)</li>
<li>这个方法只接受一个参数partitions，用来指定需要订阅的分区集合。这里补充说明一下TopicPartition类，在Kafka的客户端中，它用来表示分区</li>
<li><img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/topicpatition.png" class=""></li>
<li>TopicPartition类只有2个属性：topic和partition，分别代表分区所属的主题和自身的分区编号，这个类可以和我们通常所说的主题—分区的概念映射起来。</li>
<li>可以将subscribe 替换为assign consumer.assign(Arrays.asList(new TopicPrtition(“topic-demo”,0)))</li>
</ul>
</li>
<li>KafkaConsumer 中的partitionsFor（）方法可以用来查询指定主题的元数据信息<ul>
<li>public List&lt; PartitionInfo &gt; partitionsFor(String topic)</li>
<li><img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/partitionfor.png" class=""></li>
<li>PartitionInfo类中的属性topic表示主题名称，partition代表分区编号，leader代表分区的leader副本所在的位置，replicas代表分区的AR集合，inSyncReplicas代表分区的ISR集合，offlineReplicas代表分区的OSR集合。</li>
</ul>
</li>
<li>既然有订阅，那么就有取消订阅，可以使用 KafkaConsumer 中的 unsubscribe（）方法来取消主题的订阅。</li>
</ul>
<h3 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h3><ul>
<li>Kafka所提供的反序列化器有ByteBufferDeserializer、ByteArrayDeserializer、BytesDeserializer、DoubleDeserializer、FloatDeserializer、IntegerDeserializer、LongDeserializer、ShortDeserializer、StringDeserializer，它们分别用于ByteBuffer、ByteArray、Bytes、Double、Float、Integer、Long、Short 及String类型的反序列化，这些序列化器也都实现了 Deserializer 接口</li>
<li>与KafkaProducer中提及的Serializer接口一样，Deserializer接口也有三个方法<ul>
<li>public void configure（Map＜String，？＞ configs，boolean isKey）：用来配置当前类。</li>
<li>public byte[] serialize（String topic，T data）：用来执行反序列化。如果data为null，那么处理的时候直接返回null而不是抛出一个异常。</li>
<li>public void close（）：用来关闭当前序列化器。</li>
</ul>
</li>
</ul>
<h3 id="消息消费"><a href="#消息消费" class="headerlink" title="消息消费"></a>消息消费</h3><ul>
<li>Kafka中的消费是基于拉模式的。</li>
<li>Kafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复地调用poll（）方法，而poll（）方法返回的是所订阅的主题（分区）上的一组消息。</li>
<li>public ConsumerRecords&lt; k,v &gt; poll(final Duration timeout)</li>
<li>线程不安全的 <a target="_blank" rel="noopener" href="https://www.pianshen.com/article/88711219115/">https://www.pianshen.com/article/88711219115/</a></li>
</ul>
<h4 id="ConsumerRecords"><a href="#ConsumerRecords" class="headerlink" title="ConsumerRecords"></a>ConsumerRecords</h4><img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/consumerrecords.png" class="">

<ul>
<li>ConsumerRecords类提供了一个records（TopicPartition）方法来获取消息集中指定分区的消息</li>
<li>ConsumerRecords 类中并没提供与 partitions（）类似的 topics（）方法来查看拉取的消息集中所包含的主题列表，如果要按照主题维度来进行消费，那么只能根据消费者订阅主题时的列表来进行逻辑处理了。下面的示例演示了如何使用ConsumerRecords中的record（String topic）方法：</li>
</ul>
<h3 id="位移提交"><a href="#位移提交" class="headerlink" title="位移提交"></a>位移提交</h3><ul>
<li><p>对于消息在分区中的位置，我们将offset称为“偏移量”；对于消费者消费到的位置，将 offset 称为“位移”，有时候也会更明确地称之为“消费位移”</p>
<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E6%B6%88%E8%B4%B9%E4%BD%8D%E7%A7%BB.png" class=""></li>
<li><p>在 Kafka 中默认的消费位移的提交方式是自动提交 enable.auto.commit 配置，默认值为 true</p>
</li>
<li><p>当然这个默认的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数auto.commit.interval.ms配置，默认值为5秒，此参数生效的前提是enable.auto.commit参数为true。</p>
</li>
<li><p>自动提交缺点：</p>
<ul>
<li>自动位移提交的方式在正常情况下不会发生消息丢失或重复消费的现象，但是在编程的世界里异常无可避免，与此同时，自动位移提交也无法做到精确的位移管理。</li>
</ul>
</li>
<li><p>手动提交</p>
<ul>
<li>enable.auto.commit配置为false</li>
<li>手动提交可以细分为同步提交和异步提交，对应于 KafkaConsumer 中的 commitSync（）和commitAsync（）两种类型的方法</li>
<li>commitSync（）commitAsync（） 有重复消费问题</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(isRunning.get()):</span><br><span class="line">  ConsumerRecords&lt;String,String&gt; records = consumer.poll(<span class="number">1000</span>)；</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String,String&gt; record: records)&#123;</span><br><span class="line">    <span class="comment">//do some  logical processing</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="控制或关闭消费"><a href="#控制或关闭消费" class="headerlink" title="控制或关闭消费"></a>控制或关闭消费</h3><ul>
<li>KafkaConsumer中使用pause（）和resume（）方法来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作</li>
</ul>
<h3 id="指定位移消费"><a href="#指定位移消费" class="headerlink" title="指定位移消费"></a>指定位移消费</h3><ul>
<li>如果将auto.offset.reset参数配置为“earliest”，那么消费者会从起始处，也就是0开始消费</li>
</ul>
<h3 id="再均衡"><a href="#再均衡" class="headerlink" title="再均衡"></a>再均衡</h3><ul>
<li>再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。</li>
<li>不过在再均衡发生期间，消费组内的消费者是无法读取消息的。也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。</li>
</ul>
<h3 id="消费者拦截器"><a href="#消费者拦截器" class="headerlink" title="消费者拦截器"></a>消费者拦截器</h3><h3 id="多线程实现"><a href="#多线程实现" class="headerlink" title="多线程实现"></a>多线程实现</h3><ul>
<li>为了加速消费者的消费能力，我们可以通过多线程的方式实现消息消费。</li>
<li>KafkaProducer是线程安全的，然而KafkaConsumer却是非线程安全的。</li>
</ul>
<h4 id="第一种也是最常见的方式：线程封闭，即为每个线程实例化一个KafkaConsumer对象"><a href="#第一种也是最常见的方式：线程封闭，即为每个线程实例化一个KafkaConsumer对象" class="headerlink" title="第一种也是最常见的方式：线程封闭，即为每个线程实例化一个KafkaConsumer对象"></a>第一种也是最常见的方式：线程封闭，即为每个线程实例化一个KafkaConsumer对象</h4><img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E5%A4%9A%E7%BA%BF%E7%A8%8B1.png" class="">

<ul>
<li>一个线程对应一个KafkaConsumer实例，我们可以称之为消费线程。</li>
<li>一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。</li>
<li>这种实现方式的并发度受限于分区的实际个数当消费线程的个数大于分区数时，就有部分消费线程一直处于空闲的状态。</li>
<li>上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别，它的优点是每个线程可以按顺序消费各个分区中的消息。</li>
<li>缺点也很明显，每个消费线程都要维护一个独立的TCP连接，如果分区数和consumerThreadNum的值都很大，那么会造成不小的系统开销。</li>
</ul>
<h4 id="第二种方式是多个消费线程同时消费同一个分区"><a href="#第二种方式是多个消费线程同时消费同一个分区" class="headerlink" title="第二种方式是多个消费线程同时消费同一个分区"></a>第二种方式是多个消费线程同时消费同一个分区</h4><ul>
<li>通过 assign（）、seek（）等方法实现,这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力。</li>
<li>不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，实际应用中使用得极少，笔者也并不推荐。</li>
<li>一般而言，分区是消费线程的最小划分单位。</li>
</ul>
<h4 id="第三种实现方式，将处理消息模块改成多线程的实现方式"><a href="#第三种实现方式，将处理消息模块改成多线程的实现方式" class="headerlink" title="第三种实现方式，将处理消息模块改成多线程的实现方式"></a>第三种实现方式，将处理消息模块改成多线程的实现方式</h4><p>一般而言，poll（）拉取消息的速度是相当快的，而整体消费的瓶颈也正是在处理消息这一块，如果我们通过一定的方式来改进这一部分，那么我们就能带动整体消费性能的提升。</p>
<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E5%A4%9A%E7%BA%BF%E7%A8%8B3.png" class="">

<ul>
<li>KafkaConsumerThread类对应的是一个消费线程，里面通过线程池的方式来调用 RecordHandler 处理一批批的消息。</li>
<li>第三种实现方式还可以横向扩展，通过开启多个 KafkaConsumerThread 实例来进一步提升整体的消费能力。</li>
<li>第三种实现方式相比第一种实现方式而言，除了横向扩展的能力，还可以减少TCP连接对系统资源的消耗，不过缺点就是对于消息的顺序处理就比较困难了。</li>
</ul>
<p>对于消费位移的处理可以通过滑动窗口来解决</p>
<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.png" class="">

<ul>
<li>每一个方格代表一个批次的消息，一个滑动窗口包含若干方格，startOffset标注的是当前滑动窗口的起始位置，endOffset标注的是末尾位置。</li>
<li>每当startOffset指向的方格中的消息被消费完成，就可以提交这部分的位移，与此同时，窗口向前滑动一格，删除原来startOffset所指方格中对应的消息，并且拉取新的消息进入窗口。</li>
<li>滑动窗口的大小固定，所对应的用来暂存消息的缓存大小也就固定了，这部分内存开销可控。</li>
<li>方格大小和滑动窗口的大小同时决定了消费线程的并发数：一个方格对应一个消费线程，对于窗口大小固定的情况，方格越小并行度越高；</li>
<li>对于方格大小固定的情况，窗口越大并行度越高。</li>
<li>不过，若窗口设置得过大，不仅会增大内存的开销，而且在发生异常（比如Crash）的情况下也会引起大量的重复消费，同时还考虑线程切换的开销，建议根据实际情况设置一个合理的值，不管是对于方格还是窗口而言，过大或过小都不合适。</li>
<li>如果一个方格内的消息无法被标记为消费完成，重试失败就转入重试队列，如果还不奏效就转入死信队列</li>
</ul>
<h2 id="重要的消费者参数"><a href="#重要的消费者参数" class="headerlink" title="重要的消费者参数"></a>重要的消费者参数</h2><ol>
<li>fetch.min.bytes<ul>
<li>该参数用来配置Consumer在一次拉取请求（调用poll（）方法）中能从Kafka中拉取的最小数据量，默认值为1（B）。Kafka在收到Consumer的拉取请求时，如果返回给Consumer的数据量小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小。可以适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟（latency），对于延迟敏感的应用可能就不可取了。</li>
</ul>
</li>
<li>fetch.max.bytes<ul>
<li>该参数与fetch.max.bytes参数对应，它用来配置Consumer在一次拉取请求中从Kafka中拉取的最大数据量，默认值为 52428800（B），也就是 50MB。</li>
<li>与此相关的，Kafka中所能接收的最大消息的大小通过服务端参数message.max.bytes（对应于主题端参数max.message.bytes）来设置。</li>
</ul>
</li>
<li>fetch.max.wait.ms<ul>
<li>fetch.max.wait.ms参数用于指定Kafka的等待时间，默认值为500（ms）。</li>
<li>如果Kafka中没有足够多的消息而满足不了fetch.min.bytes参数的要求，那么最终会等待500ms。</li>
<li>这个参数的设定和Consumer与Kafka之间的延迟也有关系，如果业务应用对延迟敏感，那么可以适当调小这个参数。</li>
</ul>
</li>
<li>max.partition.fetch.bytes<ul>
<li>这个参数用来配置从每个分区里返回给Consumer的最大数据量，默认值为1048576（B），即1MB。</li>
<li>这个参数与 fetch.max.bytes 参数相似，只不过前者用来限制一次拉取中每个分区的消息大小，而后者用来限制一次拉取中整体消息的大小。</li>
<li>同样，如果这个参数设定的值比消息的大小要小，那么也不会造成无法消费，Kafka 为了保持消费逻辑的正常运转不会对此做强硬的限制。</li>
</ul>
</li>
<li>max.poll.records<ul>
<li>这个参数用来配置Consumer在一次拉取请求中拉取的最大消息数，默认值为500（条）。如果消息的大小都比较小，则可以适当调大这个参数值来提升一定的消费速度。</li>
</ul>
</li>
<li>connections.max.idle.ms<ul>
<li>这个参数用来指定在多久之后关闭限制的连接，默认值是540000（ms），即9分钟</li>
</ul>
</li>
<li>exclude.internal.topics<ul>
<li>Kafka中有两个内部的主题：__consumer_offsets和__transaction_state</li>
<li>exclude.internal.topics用来指定Kafka中的内部主题是否可以向消费者公开，默认值为true。</li>
<li>如果设置为true，那么只能使用subscribe（Collection）的方式而不能使用subscribe（Pattern）的方式来订阅内部主题，设置为false则没有这个限制。</li>
</ul>
</li>
<li>receive.buffer.bytes<ul>
<li>这个参数用来设置Socket接收消息缓冲区（SO_RECBUF）的大小，默认值为65536（B），即64KB。</li>
<li>如果设置为-1，则使用操作系统的默认值。</li>
<li>如果Consumer与Kafka处于不同的机房，则可以适当调大这个参数值。</li>
</ul>
</li>
<li>send.buffer.bytes<ul>
<li>这个参数用来设置Socket发送消息缓冲区（SO_SNDBUF）的大小，默认值为131072（B），即128KB。</li>
<li>与receive.buffer.bytes参数一样，如果设置为-1，则使用操作系统的默认值。</li>
</ul>
</li>
<li>request.timeout.ms<ul>
<li>这个参数用来配置Consumer等待请求响应的最长时间，默认值为30000（ms）。</li>
</ul>
</li>
<li>metadata.max.age.ms<ul>
<li>这个参数用来配置元数据的过期时间，默认值为300000（ms），即5分钟。</li>
<li>如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新的broker加入。</li>
</ul>
</li>
<li>reconnect.backoff.ms<ul>
<li>这个参数用来配置尝试重新连接指定主机之前的等待时间（也称为退避时间），避免频繁地连接主机，默认值为50（ms）。</li>
<li>这种机制适用于消费者向broker发送的所有请求。</li>
</ul>
</li>
<li>retry.backoff.ms<ul>
<li>个参数用来配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避）时间，避免在某些故障情况下频繁地重复发送，默认值为100（ms）。</li>
</ul>
</li>
<li>isolation.level<ul>
<li>这个参数用来配置消费者的事务隔离级别。</li>
<li>字符串类型，有效值为“read_uncommitted”和“read_committed”，表示消费者所消费到的位置，如果设置为“read_committed”，那么消费者就会忽略事务未提交的消息，即只能消费到 LSO（LastStableOffset）的位置，默认情况下为“read_uncommitted”，即可以消费到HW（High Watermark）处的位置。</li>
</ul>
</li>
</ol>
<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E5%85%B6%E4%BB%96%E5%8F%82%E6%95%B01.png" class="">
<img src="/2021/06/22/3-%E6%B6%88%E8%B4%B9%E8%80%85/%E5%85%B6%E4%BB%96%E5%8F%82%E6%95%B02.png" class="">

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/22/2-%E7%94%9F%E4%BA%A7%E8%80%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/22/2-%E7%94%9F%E4%BA%A7%E8%80%85/" class="post-title-link" itemprop="url">2.生产者</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-22 11:34:09" itemprop="dateCreated datePublished" datetime="2021-06-22T11:34:09+08:00">2021-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-23 07:13:18" itemprop="dateModified" datetime="2021-06-23T07:13:18+08:00">2021-06-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="客户端开发"><a href="#客户端开发" class="headerlink" title="客户端开发"></a>客户端开发</h2><ul>
<li>配置生产者客户端参数及创建相应的生产者实例。</li>
<li>构建待发送的消息。</li>
<li>发送消息。</li>
<li>关闭生产者实例。<img src="/2021/06/22/2-%E7%94%9F%E4%BA%A7%E8%80%85/%E7%94%9F%E4%BA%A7%E8%80%85%E4%BB%A3%E7%A0%81.png" class=""></li>
</ul>
<h3 id="ProducerRecord"><a href="#ProducerRecord" class="headerlink" title="ProducerRecord"></a>ProducerRecord</h3><img src="/2021/06/22/2-%E7%94%9F%E4%BA%A7%E8%80%85/ProducerRecord.png" class="">

<ul>
<li><strong>topic</strong> 主题必填</li>
<li>key 用来分区使用，二次分类（主题分为一次分类），相同key 放到相同分区，而且拥有key的值还支持压缩功能。</li>
<li><strong>value</strong> 为消息体，必填，一般不为空，如果为空则表示特定的消息–墓碑消息</li>
<li>timestamp 是指消息的时间戳，它有CreateTime和LogAppendTime两种类型，前者表示消息创建的时间，后者表示消息追加到日志文件的时间</li>
</ul>
<h3 id="必要的参数配置"><a href="#必要的参数配置" class="headerlink" title="必要的参数配置"></a>必要的参数配置</h3><h4 id="initConfig（）方法"><a href="#initConfig（）方法" class="headerlink" title="initConfig（）方法"></a>initConfig（）方法</h4><ul>
<li>bootstrap.servers：该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单</li>
<li>key.serializer 和 value.serializer：broker 端接收的消息必须以字节数组（byte[]）的形式存在</li>
<li>client.id：这个参数用来设定KafkaProducer对应的客户端id，默认值为“”。如果客户端不设置，则KafkaProducer会自动生成一个非空字符串，内容形式如“producer-1”“producer-2”</li>
</ul>
<h3 id="KafkaProducer"><a href="#KafkaProducer" class="headerlink" title="KafkaProducer"></a>KafkaProducer</h3><ul>
<li>线程安全的，可以在多个线程中共享单个KafkaProducer实例，也可以将其进行池化供其他线程调用</li>
<li>其内部原理和无序列化器的构造方法一样，不过就实际应用而言，一般都选用 public KafkaProducer（Properties properties）这个构造方法来创建KafkaProducer实例。</li>
</ul>
<h4 id="异常类型"><a href="#异常类型" class="headerlink" title="异常类型"></a>异常类型</h4><ul>
<li>可重试异常：NetworkException、LeaderNotAvailableException、UnknownTopicOrPartitionException、NotEnoughReplicasException、NotCoordinatorException等<ul>
<li>props.put(ProducerConfig.RETRIES_CONFIG,10) 出现异常后重试10次，在不行就抛出异常</li>
</ul>
</li>
<li>不可重试异常：RecordTooLargeException异常等</li>
</ul>
<h3 id="send-在KafkaProducer中"><a href="#send-在KafkaProducer中" class="headerlink" title="send (在KafkaProducer中)"></a>send (在KafkaProducer中)</h3><ul>
<li>发后即忘（fire-and-forget）</li>
<li>同步（sync）</li>
<li>异步（async）</li>
<li>send 方法可以通过返回Future &lt; RecordMetadata &gt;对象，调用 get 来阻塞kafka的相应，直到消息发送成功，当然也提供了超时阻塞的方法</li>
</ul>
<p>回调函数也是保证顺序性的</p>
<p>经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）</p>
<h4 id="序列化器"><a href="#序列化器" class="headerlink" title="序列化器"></a>序列化器</h4><p>生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给Kafka。而在对侧，消费者需要用反序列化器（Deserializer）把从 Kafka 中收到的字节数组转换成相应的对象。</p>
<h4 id="分区器"><a href="#分区器" class="headerlink" title="分区器"></a>分区器</h4><p>拦截器（下一章会详细介绍）一般不是必需的，而序列化器是必需的。消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。</p>
<p>其中包含两个方法</p>
<ul>
<li>Kafka中提供的默认分区器是org.apache.kafka.clients.producer.internals.DefaultPartitioner，它实现了org.apache.kafka.clients.producer.Partitioner接口</li>
<li>其中partition（）方法用来计算分区号，返回值为int类型。partition（）方法中的参数分别表示主题、键、序列化后的键、值、序列化后的值，以及集群的元数据信息，通过这些信息可以实现功能丰富的分区器。close（）方法在关闭分区器的时候用来回收一些资源。</li>
<li>分区方式：<ul>
<li>key 不为null,通过key计算哈希值，（采用MurmurHash2算法，具备高运算性能及低碰撞率）</li>
<li>如果key为null，那么消息将会以轮询的方式发往主题内的各个可用分区。</li>
</ul>
</li>
</ul>
<h4 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h4><p>在序列化器和分区器之前调用拦截器的onSend()方法</p>
<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>有可能需要经历拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）等一系列的作用</p>
<img src="/2021/06/22/2-%E7%94%9F%E4%BA%A7%E8%80%85/%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png" class="">

<ul>
<li>整体分为2个线程，主线程和sender线程</li>
<li>在主线程中由KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（RecordAccumulator，也称为消息收集器）中。Sender 线程负责从RecordAccumulator中获取消息并将其发送到Kafka中。</li>
<li>RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。<ul>
<li>RecordAccumulator 缓存的大小可以通过生产者客户端参数buffer.memory 配置，默认值为 33554432B，即 32MB</li>
<li>在 RecordAccumulator 的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch</li>
<li>消息写入缓存时，追加到双端队列的尾部；Sender读取消息时，从双端队列的头部读取。</li>
<li>注意ProducerBatch不是ProducerRecord，ProducerBatch中可以包含一至多个 ProducerRecord。</li>
<li>ProducerBatch的大小和batch.size参数也有着密切的关系</li>
<li>当一条消息（ProducerRecord）流入RecordAccumulator时，会先寻找与消息分区所对应的双端队列（如果没有则新建），再从这个双端队列的尾部获取一个 ProducerBatch（如果没有则新建），查看 ProducerBatch 中是否还可以写入这个 ProducerRecord，如果可以则写入，如果不可以则需要创建一个新的ProducerBatch。在新建ProducerBatch时评估这条消息的大小是否超过batch.size参数的大小，如果不超过，那么就以 batch.size 参数的大小来创建 ProducerBatch，这样在使用完这段内存区域之后，可以通过BufferPool 的管理来进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，这段内存区域不会被复用。</li>
</ul>
</li>
<li>Sender<ul>
<li>Sender 从 RecordAccumulator 中获取缓存的消息之后，会进一步将原本＜分区，Deque＜ProducerBatch＞＞的保存形式转变成＜Node，List＜ ProducerBatch＞的形式，其中Node表示Kafka集群的broker节点。</li>
<li>在转换成＜Node，List＜ProducerBatch＞＞的形式之后，Sender 还会进一步封装成＜Node，Request＞的形式</li>
<li>请求在从Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体形式为 Map＜NodeId，Deque＜Request＞＞，它的主要作用是缓存了已经发出去但还没有收到响应的请求（NodeId 是一个 String 类型，表示节点的 id 编号）。</li>
<li>InFlightRequests还可以获得leastLoadedNode，即负载最小的node</li>
</ul>
</li>
<li>发送之前要获取元数据信息<a target="_blank" rel="noopener" href="https://blog.csdn.net/yuanshangshenghuo/article/details/112625489">https://blog.csdn.net/yuanshangshenghuo/article/details/112625489</a><ul>
<li>KafkaProducer要将此消息追加到指定主题的某个分区所对应的leader副本之前，首先需要知道主题的分区数量，然后经过计算得出（或者直接指定）目标分区，之后KafkaProducer需要知道目标分区的leader副本所在的broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka，在这一过程中所需要的信息都属于元数据信息。</li>
<li>这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪个节点上，follower副本分配在哪些节点上，哪些副本在AR、ISR等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。</li>
<li>时机<ol>
<li>一个是业务线程获取topic分区信息元数据的时候发现没有，就会立马唤醒sender线程去拉取元数据</li>
<li>sender线程检查已经准备好的batch的时候，发现没有partition 没有leader副本的信息</li>
<li>一个是距离上次更新元数据已经过了5分钟了，这个时候就会去更新下，这个参数配置metadata.max.age.ms，默认是5分钟</li>
<li>broker 响应发送消息结果里面带着异常，InvalidMetadataException，就是元数据异常。</li>
</ol>
</li>
<li>业务线程等待元数据<ol>
<li>long waitedOnMetadataMs = waitOnMetadata(record.topic(), this.maxBlockTimeMs);</li>
<li>这行代码就是检查消息对应topic 的partition元数据信息是不是存在，如果不存在的话，就会不断尝试获取并且 “通知”sender线程去更新这个元数据信息。</li>
</ol>
</li>
<li>sender线程拉取元数据</li>
</ul>
</li>
</ul>
<h2 id="重要的生产者参数"><a href="#重要的生产者参数" class="headerlink" title="重要的生产者参数"></a>重要的生产者参数</h2><ol>
<li>acks<ul>
<li>acks=1。默认值即为1。生产者发送消息之后，只要分区的leader副本成功写入消息，那么它就会收到来自服务端的成功响应。</li>
<li>acks=0。生产者发送消息之后不需要等待任何服务端的响应。</li>
<li>acks=-1或acks=all。生产者在消息发送之后，需要等待ISR中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。<ul>
<li>不一定可靠，因为isr中可能只有leader副本，需要配合参数min.insync.replicas</li>
</ul>
</li>
</ul>
</li>
<li>max.request.size<ul>
<li>这个参数用来限制生产者客户端能发送的消息的最大值，默认值为 1048576B，即 1MB。、</li>
<li>不建议设置过大，因为这个参数还涉及一些其他参数的联动，比如broker端的message.max.bytes参数</li>
</ul>
</li>
<li>retries和retry.backoff.ms<ul>
<li>retries参数用来配置生产者重试的次数，默认值为0，即在发生异常的时候不进行任何重试动作。</li>
<li>重试还和另一个参数retry.backoff.ms有关，这个参数的默认值为100，它用来设定两次重试之间的时间间隔，避免无效的频繁重试。</li>
<li>顺序保证：max.in.flight.requests.per.connection配置为1，而不是把acks配置为0，不过这样也会影响整体的吞吐。</li>
</ul>
</li>
<li>compression.type<ul>
<li>这个参数用来指定消息的压缩方式，默认值为“none”，即默认情况下，消息不会被压缩。该参数还可以配置为“gzip”“snappy”和“lz4”。</li>
<li>消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。</li>
</ul>
</li>
<li>connections.max.idle.ms<ul>
<li>这个参数用来指定在多久之后关闭限制的连接，默认值是540000（ms），即9分钟。</li>
</ul>
</li>
<li>linger.ms<ul>
<li>这个参数用来指定生产者发送 ProducerBatch 之前等待更多消息（ProducerRecord）加入ProducerBatch 的时间，默认值为 0。</li>
<li>增加会提升系统的吞吐，但是会有时延</li>
</ul>
</li>
<li>receive.buffer.bytes<ul>
<li>这个参数用来设置Socket接收消息缓冲区（SO_RECBUF）的大小，默认值为32768（B），即32KB。如果设置为-1，则使用操作系统的默认值。如果Producer与Kafka处于不同的机房，则可以适地调大这个参数值。</li>
</ul>
</li>
<li>send.buffer.bytes<ul>
<li>这个参数用来设置Socket发送消息缓冲区（SO_SNDBUF）的大小，默认值为131072（B），即128KB。与receive.buffer.bytes参数一样，如果设置为-1，则使用操作系统的默认值。</li>
</ul>
</li>
<li>request.timeout.ms<ul>
<li>这个参数用来配置Producer等待请求响应的最长时间，默认值为30000（ms）。请求超时之后可以选择进行重试。注意这个参数需要比broker端参数replica.lag.time.max.ms的值要大，这样可以减少因客户端重试而引起的消息重复的概率。<img src="/2021/06/22/2-%E7%94%9F%E4%BA%A7%E8%80%85/%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0.png" class=""></li>
</ul>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>本章主要讲述了生产者客户端的具体用法及其整体架构，主要内容包括配置参数的详解、消息的发送方式、序列化器、分区器、拦截器等。</li>
<li>在实际应用中，一套封装良好的且灵活易用的客户端可以避免开发人员重复劳动，也提高了开发效率，还可以提高程序的健壮性和可靠性，而Kafka的客户端正好包含了这些特质。</li>
<li>对于KafkaProducer而言，它是线程安全的，我们可以在多线程的环境中复用它，</li>
<li>而对于下一章的消费者客户端KafkaConsumer而言，它是非线程安全的，因为它具备了状态，具体怎么使用我们不妨继续来了解下一章的内容。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/22/%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/22/%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">常见命令总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-22 10:59:01" itemprop="dateCreated datePublished" datetime="2021-06-22T10:59:01+08:00">2021-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-27 21:44:56" itemprop="dateModified" datetime="2021-06-27T21:44:56+08:00">2021-06-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>启动kafka程序</p>
<ul>
<li>bin/kafka-server-start.sh config/server.properties</li>
<li>Bin/kafka_server_start.sh -daemon config/server.properties  后台启动</li>
</ul>
<ol>
<li><p>创建主题</p>
<ul>
<li>bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 24 –topic sensor_input_demo</li>
<li>bin/kafka-topics.sh –create –zookeeper 192.168.10.233:2181 –replication-factor 2 –partitions 24 –topic sensor_input_test</li>
</ul>
</li>
<li><p>生产者发送消息</p>
<ul>
<li>bin/kafka-console-producer.sh –broker-list 172.18.31.161:9092 –topic sensor_input</li>
<li>bin/kafka-console-producer.sh –broker-list 172.18.30.24:9092 –topic monitor</li>
<li>bin/kafka-console-producer.sh –broker-list 172.18.30.24:9092,172.18.30.48:9092,172.18.30.16:9092 –topic feifei</li>
</ul>
</li>
<li><p>消费者发送消息</p>
<ul>
<li>Jxf |grep FILEPARSE_RULE_CHANGED</li>
<li>bin/kafka-console-consumer.sh –bootstrap-server 172.18.31.19:9092 –from-beginning –topic sensor_input &gt; /opt/kafka/config/2222.txt</li>
<li>bin/kafka-console-consumer.sh –bootstrap-server 172.18.30.24:9092,172.18.30.48:9092,172.18.30.16:9092 –from-beginning –topic feifei &gt; /opt/kafka/config/2222.txt</li>
<li>bin/kafka-console-consumer.sh –bootstrap-server 192.168.10.232:9092,192.168.10.233:9092 –from-beginning –topic sensor_input_test</li>
</ul>
</li>
<li><p>查看主题</p>
<ul>
<li>bin/kafka-topics.sh –zookeeper localhost:2181 –list  查看所有主题</li>
<li>bin/kafka-topics.sh –zookeeper 192.168.10.226:2181 –list</li>
</ul>
</li>
<li><p>删除创建的主题(注意这里一定要写ip，千万不要写localhost)磁盘</p>
<ul>
<li><p>bin/kafka-topics.sh –delete –zookeeper 192.168.10.226:2181 –topic sensor_input</p>
</li>
<li><p>bin/kafka-topics.sh –delete –zookeeper 192.168.10.226:2181 –topic sensor_input_three</p>
</li>
<li><p>bin/kafka-topics.sh –delete –zookeeper 192.168.9.191:2181 –topic sensor_input_three</p>
</li>
<li><p>1)登录zookeeper客户端的命令：zookeeper/bin/zkCli.sh</p>
</li>
<li><p>2)找到topic所在的目录：ls /brokers/topics</p>
</li>
<li><p>3)找到要删除的topic，执行如下命令即可，此时topic被彻底删除：rmr /brokers/topics/topic名称</p>
</li>
</ul>
</li>
<li><p>查看kafka消费情况</p>
<ul>
<li>#查看某一个消费者组的消费情况<ul>
<li>bin/kafka-consumer-groups.sh –bootstrap-server 172.18.31.49:9092 –describe –group sensor-es</li>
<li>bin/kafka-consumer-groups.sh –bootstrap-server 192.168.10.232:9092,192.168.10.233:9092 –describe –group sensor-es</li>
</ul>
</li>
<li>#查看有哪些消费者组<ul>
<li>bin/kafka-consumer-groups.sh –bootstrap-server localhost:9092 –list</li>
</ul>
</li>
<li>#删除消费者组<ul>
<li>bin/kafka-consumer-groups.sh –bootstrap-server localhost:9092 –delete –group sensor-stream333</li>
</ul>
</li>
</ul>
</li>
<li><p>查看topic各个分区的消息的信息</p>
<ul>
<li>bin/kafka-run-class.sh kafka.tools.GetOffsetShell –broker-list localhost:9092 –topic sensor_input_update –time -1</li>
<li>bin/kafka-run-class.sh kafka.tools.GetOffsetShell –broker-list 192.168.10.226:9092 –topic xy_test –time -1</li>
<li>bin/kafka-run-class.sh kafka.tools.GetOffsetShell –broker-list localhost:9092 –topic sensor_input</li>
</ul>
</li>
<li><p>修改kafka分区的数量</p>
<ul>
<li>bin/kafka-topics.sh –zookeeper localhost:2181 –alter –topic sensor_input –partitions 24</li>
</ul>
</li>
<li><p>查看consumer组的状态</p>
<ul>
<li>bin/kafka-consumer-groups.sh –bootstrap-server 192.168.10.226:9092 –group sensor-stream –describe –state</li>
</ul>
</li>
<li><p>重新消费</p>
<ul>
<li>bin/kafka-consumer-groups.sh  –bootstrap-server 192.168.10.226:9092 –reset-offsets –execute –group sensor_stream_zhangjian –all-topics –to-earliest</li>
</ul>
</li>
<li><p>统计数量</p>
<ul>
<li>bin/kafka-run-class.sh kafka.tools.GetOffsetShell –topic sensor_input –broker-list 192.168.10.226:9092 | awk -F ‘:’ ‘{sum += $3 } END {print sum}’</li>
<li>bin/kafka-run-class.sh kafka.tools.GetOffsetShell –topic webui_input –broker-list localhost:9092 | awk -F ‘:’ ‘{sum += $3 } END {print sum}’</li>
<li>bin/kafka-run-class.sh kafka.tools.GetOffsetShell –topic monitor –broker-list 172.18.30.24:9092 | awk -F ‘:’ ‘{sum += $3 } END {print sum}’ &gt; /opt/kafka/config/2222.txt</li>
</ul>
</li>
<li><p>查看主题描述信息</p>
<ul>
<li>bin/kafka-topics.sh –zookeeper localhost:2181 –topic sensor_input –describe</li>
</ul>
</li>
<li><p>查看消费者组描述信息</p>
<ul>
<li>bin/kafka-consumer-groups.sh –bootstrap-server localhost:9092 –describe –group my-group –members</li>
</ul>
</li>
<li><p>查看消费者组的状态</p>
<ul>
<li>bin/kafka-consumer-groups.sh –bootstrap-server localhost:9092 –describe –group my-group –state</li>
</ul>
</li>
</ol>
<h2 id="为什么快"><a href="#为什么快" class="headerlink" title="为什么快"></a>为什么快</h2><ol>
<li>在生产者发送的时候将消息包装成ProducerRecord后拼凑成紧凑的ProducerBatch,可以减少网络请求次数，提升整体吞吐。主要通过linger.ms 参数控制，默认为0,增加会提升系统的吞吐，但是会有时延</li>
<li>提供compression.type参数，可以进行消息的压缩，减少网络IO ，达到加速的目的。但是如果对时延有要求，就不建议开启这个了，是时间换空间的方法</li>
<li>提出了消费者组的概念，加快消费速度</li>
<li>使用索引，偏移量索引，时间索引，加速查询</li>
<li>大量使用页缓存。<ul>
<li>页缓存免去了I/O的资源消耗</li>
<li>页缓存比使用进程缓存省去了一次缓存的开销</li>
</ul>
</li>
<li>顺序读写</li>
<li>零拷贝 所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。</li>
</ol>
<h2 id="遇到问题"><a href="#遇到问题" class="headerlink" title="遇到问题"></a>遇到问题</h2><p>获取元数据错误，导致生产者失败，官方从2.4开始对java 客户端进行了修改（将计时器进行了前置，即将计时器放到了获取元数据信息之前，来规避这个问题，或者将元数据信息存储到第三方服务中，这样也可以达到同样的效果），但是conflunce kafka 和kafka python 并没有做相应的修改</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/22/1-%E5%88%9D%E8%AF%86kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/22/1-%E5%88%9D%E8%AF%86kafka/" class="post-title-link" itemprop="url">初识kafka</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-22 07:41:18" itemprop="dateCreated datePublished" datetime="2021-06-22T07:41:18+08:00">2021-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-23 07:13:18" itemprop="dateModified" datetime="2021-06-23T07:13:18+08:00">2021-06-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="三大角色"><a href="#三大角色" class="headerlink" title="三大角色"></a>三大角色</h2><ul>
<li>消息系统<ul>
<li>具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。</li>
<li>消息顺序性保障及回溯消费的功能。</li>
</ul>
</li>
<li>存储系统<ul>
<li>支持永久存储到磁盘</li>
<li>副本机制</li>
<li>压缩机制</li>
</ul>
</li>
<li>流式处理平台<ul>
<li>窗口、连接、变换和聚合等各类操作。</li>
</ul>
</li>
</ul>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><img src="/2021/06/22/1-%E5%88%9D%E8%AF%86kafka/%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png" class="">

<ul>
<li>Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到Kafka中。</li>
<li>Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理。</li>
<li>Broker：服务代理节点。对于Kafka而言，Broker可以简单地看作一个独立的Kafka服务节点或Kafka服务实例。大多数情况下也可以</li>
<li>Topic: Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题（发送到Kafka集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。</li>
<li>Topic-Partition: 主题是一个逻辑上的概念，它还可以细分为多个分区，一个分区只属于单个主题,分区在存储层面可以看作一个可追加的日志（Log）文件</li>
<li>offset: offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，也就是说，Kafka保证的是分区有序而不是主题有序。</li>
<li>Replica: 每个分区都有相应的副本，只有leader对外提供读写</li>
<li>AR（Assigned Replicas）：所有副本总和。等于ISR 和OSR总和</li>
<li>HW是High Watermark：所有副本中最小的offset +1</li>
<li>LEO是Log End Offset：单个副本的最大offset +1</li>
</ul>
<img src="/2021/06/22/1-%E5%88%9D%E8%AF%86kafka/%E5%88%86%E5%8C%BA%E5%86%99%E5%85%A5.png" class="">
<img src="/2021/06/22/1-%E5%88%9D%E8%AF%86kafka/hw-leo.png" class="">

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><ol>
<li>下载JDK jdk-8u181-linux-x64.tar.gz</li>
<li>tar zxvf jdk-8u181-linux-x64.tar.gz</li>
<li>配置环境变量 /etc/profile  source后生效</li>
</ol>
<ul>
<li>export JAVA_HOME=/usr/local/java-se-8u41-ri</li>
<li>export PATH=$JAVA_HOME/bin:$PATH</li>
<li>export JRE_HOME=$JAVA_HOME/jre</li>
<li>export CLASSPATH=./://$JAVA_HOME/lib:$JAVA_HOME/lib</li>
</ul>
<ol>
<li>查看安装是否成功 java -version</li>
</ol>
<h3 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h3><ol>
<li><p>下载zookeeper zookeeper-3.4.12.tar.gz</p>
</li>
<li><p>tar zxvf zookeeper-3.4.12.tar.gz</p>
</li>
<li><p>配置环境变量</p>
<ul>
<li>export ZOOKEEPER_HOME=/opt/zookeeper-3.4.12.tar.gz</li>
<li>export PATH=$PATH:$ZOOKEEPER_HOME/bin</li>
</ul>
</li>
<li><p>修改zookeeper配置文件 conf目录下</p>
<ul>
<li>cp zoo_sample.cfg zoo.cfg</li>
<li>修改配置文件如图<img src="/2021/06/22/1-%E5%88%9D%E8%AF%86kafka/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.png" class=""></li>
</ul>
</li>
<li><p>创建日志路径及数据路径</p>
</li>
<li><p>在数据目录${dataDir}目录 下创建myid文件，只包含一个数值，例如0，是服务器编号</p>
</li>
<li><p>启动 zkServer.sh start</p>
</li>
<li><p>查看状态 zkServer.sh status</p>
</li>
<li><p>集群模式下，需要修改/etc/hosts 中IP 与域名映射，并在zoo.cfg 中增加如下配置</p>
<ul>
<li>server.0=192.168.1.0:2888:3888</li>
<li>2888是集群内机器通讯使用（Leader监听此端口）</li>
<li>3888选举leader使用</li>
</ul>
</li>
</ol>
<h3 id="安装kafka"><a href="#安装kafka" class="headerlink" title="安装kafka"></a>安装kafka</h3><ol>
<li><p>下载kafka kafka_2.11-2.0.0.tgz</p>
</li>
<li><p>配置环境变量</p>
<ul>
<li>export KAFKA_HOME=/opt/zookeeper-3.4.12.tar.gz</li>
<li>export PATH=$PATH:$KAFKA_HOME/bin</li>
</ul>
</li>
<li><p>配置文件修改</p>
<ul>
<li>$KAFKA_HOME/conf/server.properties</li>
<li>broker.id=0</li>
<li>listeners=PLAINTEXT://localhost:9092</li>
<li>log.dirs=/tmp/kafka-logs</li>
<li>zookeeper.connect=localhost:2181/kafka</li>
</ul>
</li>
<li><p>启动kafka bin/kafka-server-start.sh config/server.properties &amp;</p>
</li>
<li><p>jps 查看进程</p>
</li>
</ol>
<h2 id="生产消费"><a href="#生产消费" class="headerlink" title="生产消费"></a>生产消费</h2><h2 id="服务端参数"><a href="#服务端参数" class="headerlink" title="服务端参数"></a>服务端参数</h2><p>配置在$KAFKA_HOME/config/server.properties文件中 参数</p>
<ol>
<li>zookeeper.connect  zookeeper 服务地址</li>
<li>advertised.listeners 用来对外提供服务的网卡，listeners用来对内提供的服务网卡</li>
<li>broker.id 该参数用来指定Kafka集群中broker的唯一标识，默认值为-1。如果没有设置，那么Kafka会自动生成一个。这个参数还和meta.properties文件及服务端参数broker.id.generation.enable和reserved.broker.max.id有关</li>
<li>log.dir和log.dirs<ul>
<li>Kafka 把所有的消息都保存在磁盘上，而这两个参数用来配置 Kafka 日志文件存放的根目录。一般情况下，log.dir 用来配置单个根目录，而 log.dirs 用来配置多个根目录（以逗号分隔），但是Kafka并没有对此做强制性限制，也就是说，log.dir和log.dirs都可以用来配置单个或多个根目录。log.dirs 的优先级比 log.dir 高，但是如果没有配置log.dirs，则会以 log.dir 配置为准。默认情况下只配置了 log.dir 参数，其默认值为/tmp/kafka-logs。</li>
</ul>
</li>
<li>message.max.bytes<ul>
<li>该参数用来指定broker所能接收消息的最大值，默认值为1000012（B），约等于976.6KB。如果 Producer 发送的消息大于这个参数所设置的值，那么（Producer）就会报出RecordTooLargeException的异常。</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/17/%E6%A6%82%E8%A7%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/17/%E6%A6%82%E8%A7%88/" class="post-title-link" itemprop="url">概览</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-17 21:13:35" itemprop="dateCreated datePublished" datetime="2021-06-17T21:13:35+08:00">2021-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-22 07:51:07" itemprop="dateModified" datetime="2021-06-22T07:51:07+08:00">2021-06-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/zookeeper/" itemprop="url" rel="index"><span itemprop="name">zookeeper</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="Zookeeper概念"><a href="#Zookeeper概念" class="headerlink" title="Zookeeper概念"></a>Zookeeper概念</h3><p>Zookeeper 是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。Zookeeper 提供了一个类似于 Linux 文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制</p>
<h3 id="Zookeeper角色"><a href="#Zookeeper角色" class="headerlink" title="Zookeeper角色"></a>Zookeeper角色</h3><p>Zookeeper 集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种</p>
<h4 id="Leader"><a href="#Leader" class="headerlink" title="Leader"></a>Leader</h4><ol>
<li>一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader，它会发起并维护与各 Follwer及 Observer 间的心跳。</li>
<li>所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。只要有超过半数节点（不包括 observeer 节点）写入成功，该写请求就会被提交（类 2PC 协议）。</li>
</ol>
<h4 id="Follower"><a href="#Follower" class="headerlink" title="Follower"></a>Follower</h4><ol>
<li>一个 Zookeeper 集群可能同时存在多个 Follower，它会响应 Leader 的心跳，</li>
<li>Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，</li>
<li>并且负责在 Leader 处理写请求时对请求进行投票</li>
</ol>
<h4 id="Observer"><a href="#Observer" class="headerlink" title="Observer"></a>Observer</h4><p>角色与 Follower 类似，但是无投票权。Zookeeper 需保证高可用和强一致性，为了支持更多的客户端，需要增加更多 Server；Server 增多，投票阶段延迟增大，影响性能；引入 Observer，Observer 不参与投票； Observers 接受客户端的连接，并将写请求转发给 leader 节点； 加入更多 Observer 节点，提高伸缩性，同时不影响吞吐率。</p>
<h2 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h2><h3 id="事务编号-Zxid-（事务请求-计数器-epoch-）"><a href="#事务编号-Zxid-（事务请求-计数器-epoch-）" class="headerlink" title="事务编号 Zxid （事务请求 计数器 + epoch ）"></a>事务编号 Zxid （事务请求 计数器 + epoch ）</h3><p>在 ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议） 协议的事务编号 Zxid设计中，Zxid 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID，并从中读取epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数。</p>
<p>Zxid（Transaction id）类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal（提议）ID。为了保证顺序性，该 zkid 必须单调递增。</p>
<h3 id="epoch"><a href="#epoch" class="headerlink" title="epoch"></a>epoch</h3><p>epoch：可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。</p>
<h3 id="Zab-协议有两种模式-恢复模式（选主）、广播模式（同步-）"><a href="#Zab-协议有两种模式-恢复模式（选主）、广播模式（同步-）" class="headerlink" title="Zab 协议有两种模式 - 恢复模式（选主）、广播模式（同步 ）"></a>Zab 协议有两种模式 - 恢复模式（选主）、广播模式（同步 ）</h3><p>Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。</p>
<h3 id="ZAB-协议-4-阶段"><a href="#ZAB-协议-4-阶段" class="headerlink" title="ZAB 协议 4 阶段"></a>ZAB 协议 4 阶段</h3><ul>
<li>Leader election （选举阶段 - 选出准 Leader ）<ul>
<li>Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。只有到达 广播阶段（broadcast） 准 leader 才会成为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。</li>
</ul>
</li>
<li>Discovery （发现阶段 - 接受提议、生成 epoch 、接受 epoch ）<ul>
<li>Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch</li>
<li>一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。</li>
</ul>
</li>
<li>Synchronization （同步阶段 - 同步 follower 副本 ）<ul>
<li>同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。follower 只会接收 zxid 比自己的 lastZxid 大的提议。</li>
</ul>
</li>
<li>Broadcast （广播阶段 -leader 消息广播<ul>
<li>Broadcast（广播阶段）：到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步</li>
</ul>
</li>
</ul>
<p><strong>ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK，只需要得到超过半数的节点的 ACK 就可以了。</strong></p>
<h3 id="ZAB-协议-JAVA-实现-（-FLE-发现阶段和同步合并为-Recovery-Phase（恢复阶段）"><a href="#ZAB-协议-JAVA-实现-（-FLE-发现阶段和同步合并为-Recovery-Phase（恢复阶段）" class="headerlink" title="ZAB 协议 JAVA 实现 （ FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段）"></a>ZAB 协议 JAVA 实现 （ FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段）</h3><p>协议的 Java 版本实现跟上面的定义有些不同，选举阶段使用的是 Fast Leader Election（FLE），它包含了 选举的发现职责。因为 FLE 会选举拥有最新提议历史的节点作为 leader，这样就省去了发现最新提议的步骤。实际的实现将 发现阶段 和 同步合并为 Recovery Phase（恢复阶段）。所以，ZAB 的实现只有三个阶段：Fast Leader Election；Recovery Phase；Broadcast Phase。</p>
<h2 id="投票机制"><a href="#投票机制" class="headerlink" title="投票机制"></a>投票机制</h2><p>每个 sever 首先给自己投票，然后用自己的选票和其他 sever 选票对比，权重大的胜出，使用权重较大的更新自身选票箱。具体选举过程如下：</p>
<ol>
<li>每个 Server 启动以后都询问其它的 Server 它要投票给谁。对于其他 server 的询问，server 每次根据自己的状态都回复自己推荐的 leader 的 id 和上一次处理事务的 zxid（系统启动时每个 server 都会推荐自己）</li>
<li>收到所有 Server 回复以后，就计算出 zxid 最大的哪个 Server，并将这个 Server 相关信息设置成下一次要投票的 Server。</li>
<li>计算这过程中获得票数最多的的 sever 为获胜者，如果获胜者的票数超过半数，则改server 被选为 leader。否则，继续这个过程，直到 leader 被选举出来</li>
<li>leader 就会开始等待 server 连接</li>
<li>Follower 连接 leader，将最大的 zxid 发送给 leader</li>
<li>Leader 根据 follower 的 zxid 确定同步点，至此选举阶段完成。</li>
<li>选举阶段完成 Leader 同步后通知 follower 已经成为 uptodate 状态</li>
<li>Follower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了</li>
</ol>
<h3 id="目前有-5-台服务器，每台服务器均没有数据，它们的编号分别是-1-2-3-4-5-按编号依次启动，它们的选择举过程如下"><a href="#目前有-5-台服务器，每台服务器均没有数据，它们的编号分别是-1-2-3-4-5-按编号依次启动，它们的选择举过程如下" class="headerlink" title="目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下"></a>目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下</h3><ol>
<li>服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器 1 的状态一直属于 Looking。</li>
<li>服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。</li>
<li>服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器1,2 成为小弟。</li>
<li>服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。</li>
<li>服务器 5 启动，后面的逻辑同服务器 4 成为小弟。</li>
</ol>
<h2 id="Zookeeper-工作原理-工作原理-（-原子广播）"><a href="#Zookeeper-工作原理-工作原理-（-原子广播）" class="headerlink" title="Zookeeper 工作原理 工作原理 （ 原子广播）"></a>Zookeeper 工作原理 工作原理 （ 原子广播）</h2><ol>
<li>Zookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分别是恢复模式和广播模式。</li>
<li>当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 server 的完成了和 leader 的状态同步以后，恢复模式就结束了。</li>
<li>状态同步保证了 leader 和 server 具有相同的系统状态</li>
<li>一旦 leader 已经和多数的 follower 进行了状态同步后，他就可以开始广播消息了，即进入广播状态。这时候当一个 server 加入 zookeeper 服务中，它会在恢复模式下启动，发现 leader，并和 leader 进行状态同步。待到同步结束，它也参与消息广播。Zookeeper服务一直维持在 Broadcast 状态，直到 leader 崩溃了或者 leader 失去了大部分的followers 支持。</li>
<li>广播模式需要保证 proposal 被按顺序处理，因此 zk 采用了递增的事务 id 号(zxid)来保证。所有的提议(proposal)都在被提出的时候加上了 zxid。</li>
<li>实现中 zxid 是一个 64 为的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch。低 32 位是个递增计数。</li>
<li>当 leader 崩溃或者 leader 失去大多数的 follower，这时候 zk 进入恢复模式，恢复模式需要重新选举出一个新的 leader，让所有的 server 都恢复到一个正确的状态。</li>
</ol>
<h2 id="Znode-有四种形式的目录节点"><a href="#Znode-有四种形式的目录节点" class="headerlink" title="Znode  有四种形式的目录节点"></a>Znode  有四种形式的目录节点</h2><ol>
<li>PERSISTENT：持久的节点。</li>
<li>EPHEMERAL：暂时的节点。</li>
<li>PERSISTENT_SEQUENTIAL：持久化顺序编号目录节点。</li>
<li>EPHEMERAL_SEQUENTIAL：暂时化顺序编号目录节点。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/06/17/%E6%80%BB%E8%A7%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/17/%E6%80%BB%E8%A7%88/" class="post-title-link" itemprop="url">总览</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-17 14:04:08" itemprop="dateCreated datePublished" datetime="2021-06-17T14:04:08+08:00">2021-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-12 22:02:41" itemprop="dateModified" datetime="2021-07-12T22:02:41+08:00">2021-07-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Linux-概述"><a href="#Linux-概述" class="headerlink" title="Linux 概述"></a>Linux 概述</h2><h3 id="什么是Linux"><a href="#什么是Linux" class="headerlink" title="什么是Linux"></a>什么是Linux</h3><p>Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的Unix工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。</p>
<h3 id="Unix和Linux有什么区别"><a href="#Unix和Linux有什么区别" class="headerlink" title="Unix和Linux有什么区别"></a>Unix和Linux有什么区别</h3><p>Linux和Unix都是功能强大的操作系统，都是应用广泛的服务器操作系统，有很多相似之处，甚至有一部分人错误地认为Unix和Linux操作系统是一样的，然而，事实并非如此，以下是两者的区别。</p>
<p>开源性</p>
<ul>
<li>Linux是一款开源操作系统，不需要付费，即可使用；Unix是一款对源码实行知识产权保护的传统商业软件，使用需要付费授权使用。</li>
</ul>
<p>跨平台性</p>
<ul>
<li>Linux操作系统具有良好的跨平台性能，可运行在多种硬件平台上；Unix操作系统跨平台性能较弱，大多需与硬件配套使用。</li>
</ul>
<p>可视化界面</p>
<ul>
<li>Linux除了进行命令行操作，还有窗体管理系统；Unix只是命令行下的系统。</li>
</ul>
<p>硬件环境</p>
<ul>
<li>Linux操作系统对硬件的要求较低，安装方法更易掌握；Unix对硬件要求比较苛刻，安装难度较大。</li>
</ul>
<p>用户群体</p>
<ul>
<li>Linux的用户群体很广泛，个人和企业均可使用；Unix的用户群体比较窄，多是安全性要求高的大型企业使用，如银行、电信部门等，或者Unix硬件厂商使用，如Sun等。<br>相比于Unix操作系统，Linux操作系统更受广大计算机爱好者的喜爱，主要原因是Linux操作系统具有Unix操作系统的全部功能，并且能够在普通PC计算机上实现全部的Unix特性，开源免费的特性，更容易普及使用！</li>
</ul>
<h3 id="什么是-Linux-内核"><a href="#什么是-Linux-内核" class="headerlink" title="什么是 Linux 内核"></a>什么是 Linux 内核</h3><p>Linux 系统的核心是内核。内核控制着计算机系统上的所有硬件和软件，在必要时分配硬件，并根据需要执行软件。</p>
<ul>
<li>系统内存管理</li>
<li>应用程序管理</li>
<li>硬件设备管理</li>
<li>文件系统管理</li>
</ul>
<h3 id="Linux的基本组件是什么"><a href="#Linux的基本组件是什么" class="headerlink" title="Linux的基本组件是什么"></a>Linux的基本组件是什么</h3><p>就像任何其他典型的操作系统一样，Linux拥有所有这些组件：内核，shell和GUI，系统实用程序和应用程序。Linux比其他操作系统更具优势的是每个方面都附带其他功能，所有代码都可以免费下载。</p>
<h3 id="Linux-的体系结构"><a href="#Linux-的体系结构" class="headerlink" title="Linux 的体系结构"></a>Linux 的体系结构</h3><p>从大的方面讲，Linux 体系结构可以分为两块：</p>
<img src="/2021/06/17/%E6%80%BB%E8%A7%88/%E5%86%85%E6%A0%B8.png" class="">

<p>用户空间(User Space) ：用户空间又包括用户的应用程序(User Applications)、C 库(C Library) 。<br>内核空间(Kernel Space) ：内核空间又包括系统调用接口(System Call Interface)、内核(Kernel)、平台架构相关的代码(Architecture-Dependent Kernel Code) 。</p>
<h4 id="为什么-Linux-体系结构要分为用户空间和内核空间的原因"><a href="#为什么-Linux-体系结构要分为用户空间和内核空间的原因" class="headerlink" title="为什么 Linux 体系结构要分为用户空间和内核空间的原因"></a>为什么 Linux 体系结构要分为用户空间和内核空间的原因</h4><ol>
<li>现代 CPU 实现了不同的工作模式，不同模式下 CPU 可以执行的指令和访问的寄存器不同。<ul>
<li>实模式 （Real-Address Mode）：是指8086时代的工作模式，也就是通过 段寄存器«4 +偏移地址的寻址方式。</li>
<li>保护模式 （Protected Mode）: 从80386开始引入了保护模式，它的寄存器从16位扩展到了32位，而且不再使用之前的段寄存器«4 +偏移地址的寻址方式，而是使用段描述符的方式描述基址和限长，并通过描述符中的属性设置实现对内存段的访问限制和数据 保护。</li>
<li>虚拟8086模式（Virtual-8086 Mode）：这个就是所谓的准操作模式，在保护模式下，CPU支持运行8086的软件。</li>
<li>系统管理模式（System Management Mode ): 从80386以后引入的一个标准功能，最初应该是用于实现电源管理的功能或者用来让OEM做一些差异性的feature，它对OS或者其它应用是透明的。当有系统管理事件产生时，CPU上的SMI#（external system interrupt pin）就会被触发，CPU就会进入SMM mode并切换到一个单独的地址空间保存上下文然后执行相应的任务，当RSM从SMM返回时，CPU恢复之前的工作继续执行。</li>
</ul>
</li>
<li>Linux 从 CPU 的角度出发，为了保护内核的安全，把系统分成了两部分。</li>
</ol>
<p>用户空间和内核空间是程序执行的两种不同的状态，我们可以通过两种方式完成用户空间到内核空间的转移：1）系统调用；2）硬件中断。</p>
<h3 id="BASH和DOS之间的基本区别是什么"><a href="#BASH和DOS之间的基本区别是什么" class="headerlink" title="BASH和DOS之间的基本区别是什么"></a>BASH和DOS之间的基本区别是什么</h3><p>BASH和DOS控制台之间的主要区别在于3个方面：</p>
<ul>
<li>BASH命令区分大小写，而DOS命令则不区分;</li>
<li>在BASH下，/character是目录分隔符，\作为转义字符。在DOS下，/用作命令参数分隔符，\是目录分隔符</li>
<li>DOS遵循命名文件中的约定，即8个字符的文件名后跟一个点，扩展名为3个字符。BASH没有遵循这样的惯例。</li>
</ul>
<h3 id="Linux-开机启动过程"><a href="#Linux-开机启动过程" class="headerlink" title="Linux 开机启动过程"></a>Linux 开机启动过程</h3><ol>
<li>主机加电自检，加载 BIOS 硬件信息。</li>
<li>读取 MBR 的引导文件(GRUB、LILO)。</li>
<li>引导 Linux 内核。</li>
<li>运行第一个进程 init (进程号永远为 1 )。</li>
<li>进入相应的运行级别。</li>
<li>运行终端，输入用户名和密码</li>
</ol>
<h3 id="Linux-使用的进程间通信方式"><a href="#Linux-使用的进程间通信方式" class="headerlink" title="Linux 使用的进程间通信方式"></a>Linux 使用的进程间通信方式</h3><ol>
<li>管道(pipe)、流管道(s_pipe)、有名管道(FIFO)。</li>
<li>信号(signal) 。</li>
<li>消息队列。</li>
<li>共享内存。</li>
<li>信号量。</li>
<li>套接字(socket)。</li>
</ol>
<h3 id="Linux-有哪些系统日志文件"><a href="#Linux-有哪些系统日志文件" class="headerlink" title="Linux 有哪些系统日志文件"></a>Linux 有哪些系统日志文件</h3><p>比较重要的是 /var/log/messages 日志文件。</p>
<ul>
<li>该日志文件是许多进程日志文件的汇总，从该文件可以看出任何入侵企图或成功的入侵。</li>
<li>另外，如果胖友的系统里有 ELK 日志集中收集，它也会被收集进去。</li>
</ul>
<h3 id="什么是交换空间"><a href="#什么是交换空间" class="headerlink" title="什么是交换空间"></a>什么是交换空间</h3><p>交换空间是Linux使用的一定空间，用于临时保存一些并发运行的程序。当RAM没有足够的内存来容纳正在执行的所有程序时，就会发生这种情况。</p>
<h3 id="什么是root帐户"><a href="#什么是root帐户" class="headerlink" title="什么是root帐户"></a>什么是root帐户</h3><p>root帐户就像一个系统管理员帐户，允许你完全控制系统。你可以在此处创建和维护用户帐户，为每个帐户分配不同的权限。每次安装Linux时都是默认帐户。</p>
<h3 id="什么是LILO"><a href="#什么是LILO" class="headerlink" title="什么是LILO"></a>什么是LILO</h3><p>LILO是Linux的引导加载程序。它主要用于将Linux操作系统加载到主内存中，以便它可以开始运行。</p>
<h3 id="什么是BASH"><a href="#什么是BASH" class="headerlink" title="什么是BASH"></a>什么是BASH</h3><p>BASH是Bourne Again SHell的缩写。它由Steve Bourne编写，作为原始Bourne Shell（由/ bin / sh表示）的替代品。它结合了原始版本的Bourne Shell的所有功能，以及其他功能，使其更容易使用。从那以后，它已被改编为运行Linux的大多数系统的默认shell。</p>
<h2 id="磁盘、目录、文件"><a href="#磁盘、目录、文件" class="headerlink" title="磁盘、目录、文件"></a>磁盘、目录、文件</h2><h3 id="简单-Linux-文件系统"><a href="#简单-Linux-文件系统" class="headerlink" title="简单 Linux 文件系统"></a>简单 Linux 文件系统</h3><p>在 Linux 操作系统中，所有被操作系统管理的资源，例如网络接口卡、磁盘驱动器、打印机、输入输出设备、普通文件或是目录都被看作是一个文件。</p>
<p>也就是说在 Linux 系统中有一个重要的概念<strong>：一切都是文件</strong>。其实这是 Unix 哲学的一个体现，而 Linux 是重写 Unix 而来，所以这个概念也就传承了下来。在 Unix 系统中，把一切资源都看作是文件，包括硬件设备。UNIX系统把每个硬件都看成是一个文件，通常称为设备文件，这样用户就可以用读写文件的方式实现对硬件的访问。</p>
<p>Linux 支持 5 种文件类型，如下图所示：</p>
<img src="/2021/06/17/%E6%80%BB%E8%A7%88/linux%E6%96%87%E4%BB%B6.png" class="">

<h3 id="Linux-的目录结构是怎样的"><a href="#Linux-的目录结构是怎样的" class="headerlink" title="Linux 的目录结构是怎样的"></a>Linux 的目录结构是怎样的</h3><p>Linux 文件系统的结构层次鲜明，就像一棵倒立的树，最顶层是其根目录：</p>
<img src="/2021/06/17/%E6%80%BB%E8%A7%88/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png" class="">

<p>常见目录说明：</p>
<ul>
<li>/bin： 存放二进制可执行文件(ls,cat,mkdir等)，常用命令一般都在这里；</li>
<li>/etc： 存放系统管理和配置文件；</li>
<li>/home： 存放所有用户文件的根目录，是用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示；</li>
<li><strong>/usr</strong>： 用于存放系统应用程序；</li>
<li>/opt： 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把tomcat等都安装到这里；</li>
<li>/proc： 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息；</li>
<li>/root： 超级用户（系统管理员）的主目录（特权阶级o）；</li>
<li>/sbin: 存放二进制可执行文件，只有root才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如ifconfig等；</li>
<li>/dev： 用于存放设备文件；</li>
<li>/mnt： 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统；</li>
<li>/boot： 存放用于系统引导时使用的各种文件；</li>
<li><strong>/lib</strong>： 存放着和系统运行相关的库文件 ；</li>
<li>/tmp： 用于存放各种临时文件，是公用的临时文件存储点；</li>
<li>/var： 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等；</li>
<li>/lost+found： 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里。</li>
</ul>
<h3 id="什么是-inode"><a href="#什么是-inode" class="headerlink" title="什么是 inode"></a>什么是 inode</h3><p>理解inode，要从文件储存说起。</p>
<p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p>
<p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。</p>
<p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。</p>
<p>每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。</p>
<h4 id="简述-Linux-文件系统通过-i-节点把文件的逻辑结构和物理结构转换的工作过程"><a href="#简述-Linux-文件系统通过-i-节点把文件的逻辑结构和物理结构转换的工作过程" class="headerlink" title="简述 Linux 文件系统通过 i 节点把文件的逻辑结构和物理结构转换的工作过程"></a>简述 Linux 文件系统通过 i 节点把文件的逻辑结构和物理结构转换的工作过程</h4><p>Linux 通过 inode 节点表将文件的逻辑结构和物理结构进行转换。</p>
<ul>
<li>inode 节点是一个 64 字节长的表，表中包含了文件的相关信息，其中有文件的大小、文件所有者、文件的存取许可方式以及文件的类型等重要信息。在 inode 节点表中最重要的内容是磁盘地址表。在磁盘地址表中有 13 个块号，文件将以块号在磁盘地址表中出现的顺序依次读取相应的块。</li>
<li>Linux 文件系统通过把 inode 节点和文件名进行连接，当需要读取该文件时，文件系统在当前目录表中查找该文件名对应的项，由此得到该文件相对应的 inode 节点号，通过该 inode 节点的磁盘地址表把分散存放的文件物理块连接成文件的逻辑结构。</li>
</ul>
<h3 id="什么是硬链接和软链接"><a href="#什么是硬链接和软链接" class="headerlink" title="什么是硬链接和软链接"></a>什么是硬链接和软链接</h3><p>1）硬链接</p>
<p>由于 Linux 下的文件是通过索引节点(inode)来识别文件，硬链接可以认为是一个指针，指向文件索引节点的指针，系统并不为它重新分配 inode 。每添加一个一个硬链接，文件的链接数就加 1 。</p>
<p>不足：1）不可以在不同文件系统的文件间建立链接；2）只有超级用户才可以为目录创建硬链接。</p>
<p>2）软链接</p>
<p>ln  -s  [源文件或目录]  [目标文件或目录]</p>
<p>正确的删除方式（删除软链接，但不删除实际数据）<br>rm -rf  ./test_chk_ln</p>
<p>错误的删除方式<br>rm -rf ./test_chk_ln/ (这样就会把原来test_chk下的内容删除)</p>
<p>软链接克服了硬链接的不足，没有任何文件系统的限制，任何用户可以创建指向目录的符号链接。因而现在更为广泛使用，它具有更大的灵活性，甚至可以跨越不同机器、不同网络对文件进行链接。</p>
<p>不足：因为链接文件包含有原文件的路径信息，所以当原文件从一个目录下移到其他目录中，再访问链接文件，系统就找不到了，而硬链接就没有这个缺陷，你想怎么移就怎么移；还有它要系统分配额外的空间用于建立新的索引节点和保存原文件的路径。</p>
<p>实际场景下，基本是使用软链接。总结区别如下：</p>
<ul>
<li>硬链接不可以跨分区，软件链可以跨分区。</li>
<li>硬链接指向一个 inode 节点，而软链接则是创建一个新的 inode 节点。</li>
<li>删除硬链接文件，不会删除原文件，删除软链接文件，会把原文件删除。</li>
</ul>
<h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><h3 id="一台-Linux-系统初始化环境后需要做一些什么安全工作"><a href="#一台-Linux-系统初始化环境后需要做一些什么安全工作" class="headerlink" title="一台 Linux 系统初始化环境后需要做一些什么安全工作"></a>一台 Linux 系统初始化环境后需要做一些什么安全工作</h3><ol>
<li>添加普通用户登陆，禁止 root 用户登陆，更改 SSH 端口号,不一定干这个事。</li>
<li>服务器使用密钥登陆，禁止密码登陆。</li>
<li>开启防火墙，关闭 SElinux ，根据业务需求设置相应的防火墙规则。</li>
<li>装 fail2ban 这种防止 SSH 暴力破击的软件</li>
<li>设置只允许公司办公网出口 IP 能登陆服务器(看公司实际需要)</li>
<li>修改历史命令记录的条数为 10 条。</li>
<li>只允许有需要的服务器可以访问外网，其它全部禁止。</li>
<li>做好软件层面的防护。<ul>
<li>8.1 设置 nginx_waf 模块防止 SQL 注入。</li>
<li>8.2 把 Web 服务使用 www 用户启动，更改网站目录的所有者和所属组为 www 。</li>
</ul>
</li>
</ol>
<h3 id="什么叫-CC-攻击？什么叫-DDOS-攻击"><a href="#什么叫-CC-攻击？什么叫-DDOS-攻击" class="headerlink" title="什么叫 CC 攻击？什么叫 DDOS 攻击"></a>什么叫 CC 攻击？什么叫 DDOS 攻击</h3><ul>
<li>CC 攻击，主要是用来攻击页面的，模拟多个用户不停的对你的页面进行访问，从而使你的系统资源消耗殆尽。</li>
<li>DDOS 攻击，中文名叫分布式拒绝服务攻击，指借助服务器技术将多个计算机联合起来作为攻击平台，来对一个或多个目标发动 DDOS 攻击。</li>
</ul>
<p>攻击，即是通过大量合法的请求占用大量网络资源，以达到瘫痪网络的目的。</p>
<p>预防 CC、DDOS 攻击，这些只能是用硬件防火墙做流量清洗，将攻击流量引入黑洞。</p>
<h3 id="什么是网站数据库注入"><a href="#什么是网站数据库注入" class="headerlink" title="什么是网站数据库注入"></a>什么是网站数据库注入</h3><ul>
<li>由于程序员的水平及经验参差不齐，大部分程序员在编写代码的时候，没有对用户输入数据的合法性进行判断。</li>
<li>应用程序存在安全隐患。用户可以提交一段数据库查询代码，根据程序返回的结果，获得某些他想得知的数据，这就是所谓的 SQL 注入。</li>
<li>SQL注入，是从正常的 WWW 端口访问，而且表面看起来跟一般的 Web 页面访问没什么区别，如果管理员没查看日志的习惯，可能被入侵很长时间都不会发觉。</li>
</ul>
<p>如何过滤与预防？</p>
<p>数据库网页端注入这种，可以考虑使用 nginx_waf 做过滤与预防。</p>
<h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><h3 id="Shell-脚本是什么"><a href="#Shell-脚本是什么" class="headerlink" title="Shell 脚本是什么"></a>Shell 脚本是什么</h3><p>一个 Shell 脚本是一个文本文件，包含一个或多个命令。作为系统管理员，我们经常需要使用多个命令来完成一项任务，我们可以添加这些所有命令在一个文本文件(Shell 脚本)来完成这些日常工作任务。</p>
<h4 id="什么是默认登录-Shell"><a href="#什么是默认登录-Shell" class="headerlink" title="什么是默认登录 Shell"></a>什么是默认登录 Shell</h4><p>在 Linux 操作系统，”/bin/bash” 是默认登录 Shell，是在创建用户时分配的。</p>
<p>使用 chsh 命令可以改变默认的 Shell 。示例如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># chsh &lt;用户名&gt; -s &lt;新shell&gt;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># chsh ThinkWon -s /bin/sh</span></span></span><br></pre></td></tr></table></figure>

<h3 id="语法级"><a href="#语法级" class="headerlink" title="语法级"></a>语法级</h3><h4 id="可以在-Shell-脚本中使用哪些类型的变量"><a href="#可以在-Shell-脚本中使用哪些类型的变量" class="headerlink" title="可以在 Shell 脚本中使用哪些类型的变量"></a>可以在 Shell 脚本中使用哪些类型的变量</h4><ul>
<li>系统定义变量<ul>
<li>系统变量是由系统自己创建的。这些变量通常由大写字母组成，可以通过 set 命令查看。</li>
</ul>
</li>
<li>用户定义变量<ul>
<li>用户变量由系统用户来生成和定义，变量的值可以通过命令 “echo $&lt;变量名&gt;” 查看。</li>
</ul>
</li>
</ul>
<h4 id="Shell脚本中-标记的用途是什么"><a href="#Shell脚本中-标记的用途是什么" class="headerlink" title="Shell脚本中 $? 标记的用途是什么"></a>Shell脚本中 $? 标记的用途是什么</h4><p>在写一个 Shell 脚本时，如果你想要检查前一命令是否执行成功，在 if 条件中使用 $? 可以来检查前一命令的结束状态。</p>
<p>如果结束状态是 0 ，说明前一个命令执行成功。如果结束状态不是0，说明命令执行失败。例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:~## ls /usr/bin/shar</span><br><span class="line">/usr/bin/shar</span><br><span class="line">root@localhost:~## echo $?</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<h4 id="Bourne-Shell-bash-中有哪些特殊的变量"><a href="#Bourne-Shell-bash-中有哪些特殊的变量" class="headerlink" title="Bourne Shell(bash) 中有哪些特殊的变量"></a>Bourne Shell(bash) 中有哪些特殊的变量</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">内建变量    解释</span><br><span class="line"><span class="meta">$</span><span class="bash">0    命令行中的脚本名字</span></span><br><span class="line"><span class="meta">$</span><span class="bash">1    第一个命令行参数</span></span><br><span class="line"><span class="meta">$</span><span class="bash">2    第二个命令行参数</span></span><br><span class="line">…..    …….</span><br><span class="line"><span class="meta">$</span><span class="bash">9    第九个命令行参数</span></span><br><span class="line"><span class="meta">$</span><span class="bash"><span class="comment">##    命令行参数的数量</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">*    所有命令行参数，以空格隔开</span></span><br></pre></td></tr></table></figure>

<h4 id="如何取消变量或取消变量赋值"><a href="#如何取消变量或取消变量赋值" class="headerlink" title="如何取消变量或取消变量赋值"></a>如何取消变量或取消变量赋值</h4><p>unset 命令用于取消变量或取消变量赋值。语法如下所示：## unset &lt;变量名&gt;</p>
<h4 id="Shell-脚本中-if-语法如何嵌套"><a href="#Shell-脚本中-if-语法如何嵌套" class="headerlink" title="Shell 脚本中 if 语法如何嵌套"></a>Shell 脚本中 if 语法如何嵌套</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">if [ 条件 ]</span><br><span class="line">then</span><br><span class="line">命令1</span><br><span class="line">命令2</span><br><span class="line">…..</span><br><span class="line">else</span><br><span class="line">if [ 条件 ]</span><br><span class="line">then</span><br><span class="line">命令1</span><br><span class="line">命令2</span><br><span class="line">….</span><br><span class="line">else</span><br><span class="line">命令1</span><br><span class="line">命令2</span><br><span class="line">…..</span><br><span class="line">fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<h4 id="在-Shell-脚本中如何比较两个数字"><a href="#在-Shell-脚本中如何比较两个数字" class="headerlink" title="在 Shell 脚本中如何比较两个数字"></a>在 Shell 脚本中如何比较两个数字</h4><p>在 if-then 中使用测试命令（ -gt 等）来比较两个数字。例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">x=10</span><br><span class="line">y=20</span><br><span class="line">if [ $x -gt $y ]</span><br><span class="line">then</span><br><span class="line">echo “x is greater than y”</span><br><span class="line">else</span><br><span class="line">echo “y is greater than x”</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<h4 id="Shell-脚本中-for-循环语法"><a href="#Shell-脚本中-for-循环语法" class="headerlink" title="Shell 脚本中 for 循环语法"></a>Shell 脚本中 for 循环语法</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for 变量 in 循环列表</span><br><span class="line">do</span><br><span class="line">命令1</span><br><span class="line">命令2</span><br><span class="line">….</span><br><span class="line">最后命令</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="Shell-脚本中-while-循环语法"><a href="#Shell-脚本中-while-循环语法" class="headerlink" title="Shell 脚本中 while 循环语法"></a>Shell 脚本中 while 循环语法</h4><p>如同 for 循环，while 循环只要条件成立就重复它的命令块。<br>不同于 for循环，while 循环会不断迭代，直到它的条件不为真。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">while [ 条件 ]</span><br><span class="line">do</span><br><span class="line">命令…</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">do</span><br><span class="line">&#123;</span><br><span class="line">命令</span><br><span class="line">&#125; while (条件)</span><br></pre></td></tr></table></figure>

<h4 id="Shell-脚本中-break-命令的作用"><a href="#Shell-脚本中-break-命令的作用" class="headerlink" title="Shell 脚本中 break 命令的作用"></a>Shell 脚本中 break 命令的作用</h4><p>break 命令一个简单的用途是退出执行中的循环。我们可以在 while 和 until 循环中使用 break 命令跳出循环。</p>
<h4 id="Shell-脚本中-continue-命令的作用"><a href="#Shell-脚本中-continue-命令的作用" class="headerlink" title="Shell 脚本中 continue 命令的作用"></a>Shell 脚本中 continue 命令的作用</h4><p>continue 命令不同于 break 命令，它只跳出当前循环的迭代，而不是整个循环。continue 命令很多时候是很有用的，例如错误发生，但我们依然希望继续执行大循环的时候。</p>
<h3 id="如何使脚本可执行"><a href="#如何使脚本可执行" class="headerlink" title="如何使脚本可执行"></a>如何使脚本可执行</h3><p>使用 chmod 命令来使脚本可执行。例子如下：chmod a+x myscript.sh</p>
<h4 id="bin-bash-的作用"><a href="#bin-bash-的作用" class="headerlink" title="#!/bin/bash 的作用"></a>#!/bin/bash 的作用</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash 是 Shell 脚本的第一行，称为释伴（shebang）行。</span></span><br></pre></td></tr></table></figure>

<p>这里 # 符号叫做 hash ，而 ! 叫做 bang。<br>它的意思是命令通过 /bin/bash 来执行。</p>
<h4 id="如何将标准输出和错误输出同时重定向到同一位置"><a href="#如何将标准输出和错误输出同时重定向到同一位置" class="headerlink" title="如何将标准输出和错误输出同时重定向到同一位置"></a>如何将标准输出和错误输出同时重定向到同一位置</h4><p>方法一：2&gt;&amp;1 (如## ls /usr/share/doc &gt; out.txt 2&gt;&amp;1 ) 。<br>方法二：&amp;&gt; (如## ls /usr/share/doc &amp;&gt; out.txt )</p>
<h3 id="在-Shell-脚本如何定义函数呢"><a href="#在-Shell-脚本如何定义函数呢" class="headerlink" title="在 Shell 脚本如何定义函数呢"></a>在 Shell 脚本如何定义函数呢</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="function"><span class="title">diskusage</span></span> () &#123; df -h ; &#125;</span></span><br><span class="line">译注：下面是我给的shell函数语法，原文没有</span><br><span class="line">[ function ] 函数名 [()]</span><br><span class="line">&#123;</span><br><span class="line">命令;</span><br><span class="line">[return int;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="如何让-Shell-就脚本得到来自终端的输入"><a href="#如何让-Shell-就脚本得到来自终端的输入" class="headerlink" title="如何让 Shell 就脚本得到来自终端的输入"></a>如何让 Shell 就脚本得到来自终端的输入</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># vi /tmp/test.sh</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo ‘Please enter your name’</span><br><span class="line">read name</span><br><span class="line">echo “My Name is $name”</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># ./test.sh</span></span></span><br><span class="line">Please enter your name</span><br><span class="line">ThinkWon</span><br><span class="line">My Name is ThinkWon</span><br></pre></td></tr></table></figure>

<h3 id="如何执行算术运算"><a href="#如何执行算术运算" class="headerlink" title="如何执行算术运算"></a>如何执行算术运算</h3><ol>
<li>使用 expr 命令：## expr 5 + 2 。</li>
<li>用一个美元符号和方括号（$[ 表达式 ]）：test=$[16 + 4] ; test=$[16 + 4] 。</li>
</ol>
<h2 id="文件管理命令"><a href="#文件管理命令" class="headerlink" title="文件管理命令"></a>文件管理命令</h2><ul>
<li>cat 命令</li>
<li>cp 命令</li>
<li>ln 命令</li>
<li>mv 命令</li>
<li>rm 命令</li>
<li>tail 命令</li>
<li>vim 命令</li>
</ul>
<h3 id="chmod-命令"><a href="#chmod-命令" class="headerlink" title="chmod 命令"></a>chmod 命令</h3><p>-rw-r–r– 1 root root 296K 11-13 06:03 log2012.log</p>
<p>第一列共有 10 个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是 d，表示是一个目录。从第二个字符开始到第十个 9 个字符，3 个字符一组，分别表示了 3 组用户对文件或者目录的权限。权限字符用横线代表空许可，r 代表只读，w 代表写，x 代表可执行。</p>
<h3 id="chown-命令"><a href="#chown-命令" class="headerlink" title="chown 命令"></a>chown 命令</h3><p>-c 显示更改的部分的信息<br>-R 处理指定目录及子目录</p>
<p>chown -c mail:mail log2012.log</p>
<h3 id="find"><a href="#find" class="headerlink" title="find"></a>find</h3><ul>
<li>find ./ -name ‘*.log’ 在当前目录下xun</li>
<li>find /opt -perm 777 查找 /opt 目录下 权限为 777 的文件</li>
<li>find -size +1000c 查找大于 1K 的文件</li>
<li>find -size 1000c 查找等于 1000 字符的文件</li>
</ul>
<h3 id="head-命令"><a href="#head-命令" class="headerlink" title="head 命令"></a>head 命令</h3><ul>
<li>head 1.log -n 20 显示 1.log 文件中前 20 行</li>
<li>head -n -10 t.log 显示 t.log最后 10 行</li>
</ul>
<h3 id="which-命令"><a href="#which-命令" class="headerlink" title="which 命令"></a>which 命令</h3><p>which ls 查看 ls 命令是否存在，执行哪个</p>
<h2 id="文档编辑命令"><a href="#文档编辑命令" class="headerlink" title="文档编辑命令"></a>文档编辑命令</h2><ul>
<li>grep 命令</li>
</ul>
<h3 id="wc-命令"><a href="#wc-命令" class="headerlink" title="wc 命令"></a>wc 命令</h3><p>wc(word count)功能为统计指定的文件中字节数、字数、行数，并将统计结果输出</p>
<ul>
<li>-c 统计字节数</li>
<li>-l 统计行数</li>
<li>-m 统计字符数</li>
<li>-w 统计词数，一个字被定义为由空白、跳格或换行字符分隔的字符串</li>
<li>wc text.txt 查找文件的 行数 单词数 字节数 文件名</li>
<li>cat test.txt | wc -l 统计输出结果的行数</li>
</ul>
<h2 id="磁盘管理命令"><a href="#磁盘管理命令" class="headerlink" title="磁盘管理命令"></a>磁盘管理命令</h2><ul>
<li>cd 命令</li>
<li>df 命令 df -h</li>
<li>du 命令<ul>
<li>du -h scf/ 以易读方式显示文件夹内及子文件夹大小</li>
<li>du -ah scf/ 以易读方式显示文件夹内所有文件大小</li>
<li>du -hc test/ scf/ 显示几个文件或目录各自占用磁盘空间的大小，还统计它们的总和</li>
<li>du -hc –max-depth=1 scf/ 输出当前目录下各个子目录所使用的空间</li>
</ul>
</li>
<li>ls命令</li>
<li>mkdir 命令</li>
<li>pwd 命令</li>
<li>rmdir 命令</li>
</ul>
<h2 id="网络通讯命令"><a href="#网络通讯命令" class="headerlink" title="网络通讯命令"></a>网络通讯命令</h2><ul>
<li>ifconfig 命令</li>
<li>iptables 命令</li>
<li>netstat 命令</li>
<li>ping 命令</li>
<li>telnet 命令<ul>
<li>telnet 192.168.0.5  登录IP为 192.168.0.5 的远程主机</li>
</ul>
</li>
</ul>
<h2 id="系统管理命令"><a href="#系统管理命令" class="headerlink" title="系统管理命令"></a>系统管理命令</h2><p>date 命令<br>free 命令<br>kill 命令<br>ps 命令<br>top 命令<br>yum 命令</p>
<h2 id="备份压缩命令"><a href="#备份压缩命令" class="headerlink" title="备份压缩命令"></a>备份压缩命令</h2><ul>
<li>zip 命令 zip -r</li>
<li>unzip 命令<ul>
<li>解压 *.zip 文件：unzip test.zip 。</li>
<li>查看 *.zip 文件的内容：unzip -l jasper.zip</li>
</ul>
</li>
<li>tar 命令<ul>
<li>tar -zcvf /tmp/etc.tar.gz /etc  将 /etc 下的所有文件及目录打包到指定目录，并使用 gz 压缩</li>
</ul>
</li>
</ul>
<h2 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h2><p>ulimit -n 查看系统允许的最大文件描述符数量<br>ulimit -S/-Hn 分别查看软限制和硬限制。硬限制设定之后不能在添加，软限制可以增加到硬限制规定的值。<br>ls /proc/31796进程号/fd |wc -l 查看某个进程占用的文件描述符（遇到问题,时间一长就crash 了，通过拉取/var/message中日志，找到时间，然后去/var/crash 查看，发现是系统申请资源的时候申请不到，导致了crash，最终定位是有个程序的文件句柄未关闭，导致超过了限制，所以才发生的问题）<br>/etc/security/limits.conf文件中进行修改 root soft nofile 65535  或者ulimit -n 65535</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">sk-xinye</p>
  <div class="site-description" itemprop="description">愿所有努力都不被辜负</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">96</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sk-xinye</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
