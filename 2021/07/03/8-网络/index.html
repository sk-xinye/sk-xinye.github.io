<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sk-xinye.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.yml"};
  </script>

  <meta name="description" content="容器网络网络栈”，实际上是被隔离在它自己的 Network Namespace 当中的。 而所谓“网络栈”，就包括了：  网卡（Network Interface） 回环设备（Loopback Device） 路由表（Routing Table） iptables 规则。 对于一个进程来说，这些要素，其实就构成了它发起和响应网络请求的基本环境。  需要指出的是，作为一个容器，它可以声明直接使用宿主">
<meta property="og:type" content="article">
<meta property="og:title" content="8.网络">
<meta property="og:url" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="sk-xinyeの博客">
<meta property="og:description" content="容器网络网络栈”，实际上是被隔离在它自己的 Network Namespace 当中的。 而所谓“网络栈”，就包括了：  网卡（Network Interface） 回环设备（Loopback Device） 路由表（Routing Table） iptables 规则。 对于一个进程来说，这些要素，其实就构成了它发起和响应网络请求的基本环境。  需要指出的是，作为一个容器，它可以声明直接使用宿主">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E5%AE%B9%E5%99%A8%E9%80%9A%E4%BF%A1.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E5%AE%BF%E4%B8%BB%E6%9C%BA%E8%AE%BF%E9%97%AEdocker.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/docker%E8%AE%BF%E9%97%AE%E5%85%B6%E4%BB%96%E7%BD%91%E7%BB%9C.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E8%B7%A8%E4%B8%BB%E6%9C%BA%E9%80%9A%E4%BF%A1.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/UDP%E6%A8%A1%E5%BC%8F.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/UDP%E5%BC%83%E7%94%A8.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/vxlan%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/vxlan%E5%86%85%E9%83%A8%E5%B8%A7.png">
<meta property="article:published_time" content="2021-07-03T08:52:50.000Z">
<meta property="article:modified_time" content="2023-02-04T02:33:07.825Z">
<meta property="article:author" content="sk-xinye">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E5%AE%B9%E5%99%A8%E9%80%9A%E4%BF%A1.png">

<link rel="canonical" href="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>8.网络 | sk-xinyeの博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">sk-xinyeの博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习的脚步</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-fa fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">142</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2021/07/03/8-%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          8.网络
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-03 16:52:50" itemprop="dateCreated datePublished" datetime="2021-07-03T16:52:50+08:00">2021-07-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-04 10:33:07" itemprop="dateModified" datetime="2023-02-04T10:33:07+08:00">2023-02-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="容器网络"><a href="#容器网络" class="headerlink" title="容器网络"></a>容器网络</h2><p>网络栈”，实际上是被隔离在它自己的 Network Namespace 当中的。</p>
<p>而所谓“网络栈”，就包括了：</p>
<ul>
<li>网卡（Network Interface）</li>
<li>回环设备（Loopback Device）</li>
<li>路由表（Routing Table）</li>
<li>iptables 规则。</li>
<li>对于一个进程来说，这些要素，其实就构成了它发起和响应网络请求的基本环境。</li>
</ul>
<p>需要指出的是，作为一个容器，它可以声明直接使用宿主机的网络栈（–net=host），即：不开启 Network Namespace，比如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">docker run –d –net=host --name nginx-host nginx</span></span><br></pre></td></tr></table></figure>

<ul>
<li>在这种情况下，这个容器启动后，直接监听的就是宿主机的 80 端口。</li>
</ul>
<p>问题：</p>
<ul>
<li>像这样直接使用宿主机网络栈的方式，虽然可以为容器提供良好的网络性能，但也会不可避免地引入共享网络资源的问题，比如端口冲突。所以，在大多数情况下，我们都希望容器进程能使用自己 Network Namespace 里的网络栈，即：拥有属于自己的 IP 地址和端口。</li>
<li>这个被隔离的容器进程，该如何跟其他 Network Namespace 里的容器进程进行交互呢？</li>
</ul>
<h3 id="网桥"><a href="#网桥" class="headerlink" title="网桥"></a>网桥</h3><p>而为了实现上述目的，Docker 项目会默认在宿主机上创建一个名叫 docker0 的网桥，凡是连接在 docker0 网桥上的容器，就可以通过它来进行通信。</p>
<ul>
<li>我们就需要使用一种名叫Veth Pair的虚拟设备了。</li>
<li>Veth Pair 设备的特点是：它被创建出来后，总是以两张虚拟网卡（Veth Peer）的形式成对出现的。并且，从其中一个“网卡”发出的数据包，可以直接出现在与它对应的另一张“网卡”上，哪怕这两个“网卡”在不同的 Network Namespace 里。</li>
<li>这就使得 Veth Pair 常常被用作连接不同 Network Namespace 的“网线”。</li>
</ul>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><ul>
<li>当进入容器后，查看容器ifconfig网络，发现eth0的网卡，它正是一个 Veth Pair 设备在容器里的这一端。</li>
<li>通过 route 命令查看 nginx-1 容器的路由表，我们可以看到，这个 eth0 网卡是这个容器里的默认路由设备；所有对 172.17.0.0/16 网段的请求，也会被交给 eth0 来处理（第二条 172.17.0.0 路由规则）。</li>
<li>而这个 Veth Pair 设备的另一端，则在宿主机上。你可以通过查看宿主机的网络设备看到它，</li>
<li>通过 ifconfig 命令的输出，你可以看到，nginx-1 容器对应的 Veth Pair 设备，在宿主机上是一张虚拟网卡。它的名字叫作 veth9c02e56。</li>
<li>并且，通过 brctl show 的输出，你可以看到这张网卡被“插”在了 docker0 上。</li>
<li>如果我们再在这台宿主机上启动另一个 Docker 容器，比如 nginx-2：你就会发现一个新的、名叫 vethb4963f3 的虚拟网卡，也被“插”在了 docker0 网桥上。</li>
</ul>
<p>这其中的原理其实非常简单：</p>
<ul>
<li>当你在 nginx-1 容器里访问 nginx-2 容器的 IP 地址（比如 ping 172.17.0.3）的时候，这个目的 IP 地址会匹配到 nginx-1 容器里的第二条路由规则。可以看到，这条路由规则的网关（Gateway）是 0.0.0.0，这就意味着这是一条直连规则，即：凡是匹配到这条规则的 IP 包，应该经过本机的 eth0 网卡，通过二层网络直接发往目的主机。</li>
<li>而要通过二层网络到达 nginx-2 容器，就需要有 172.17.0.3 这个 IP 地址对应的 MAC 地址。所以 nginx-1 容器的网络协议栈，就需要通过 eth0 网卡发送一个 ARP 广播，来通过 IP 地址查找对应的 MAC 地址。<ul>
<li>ARP（Address Resolution Protocol），是通过三层的 IP 地址找到对应的二层 MAC 地址的协议。</li>
</ul>
</li>
<li>这个 eth0 网卡，是一个 Veth Pair，它的一端在这个 nginx-1 容器的 Network Namespace 里，而另一端则位于宿主机上（Host Namespace），并且被“插”在了宿主机的 docker0 网桥上。</li>
<li>一旦一张虚拟网卡被“插”在网桥上，它就会变成该网桥的“从设备”。从设备会被“剥夺”调用网络协议栈处理数据包的资格，从而“降级”成为网桥上的一个端口。</li>
<li>而这个端口唯一的作用，就是接收流入的数据包，然后把这些数据包的“生杀大权”（比如转发或者丢弃），全部交给对应的网桥。</li>
<li>所以，在收到这些 ARP 请求之后，docker0 网桥就会扮演二层交换机的角色，把 ARP 广播转发到其他被“插”在 docker0 上的虚拟网卡上。</li>
<li>这样，同样连接在 docker0 上的 nginx-2 容器的网络协议栈就会收到这个 ARP 请求，从而将 172.17.0.3 所对应的 MAC 地址回复给 nginx-1 容器。</li>
<li>有了这个目的 MAC 地址，nginx-1 容器的 eth0 网卡就可以将数据包发出去。</li>
<li>而根据 Veth Pair 设备的原理，这个数据包会立刻出现在宿主机上的 veth9c02e56 虚拟网卡上。不过，此时这个 veth9c02e56 网卡的网络协议栈的资格已经被“剥夺”，所以这个数据包就直接流入到了 docker0 网桥里。</li>
<li>docker0 处理转发的过程，则继续扮演二层交换机的角色。此时，docker0 网桥根据数据包的目的 MAC 地址（也就是 nginx-2 容器的 MAC 地址），在它的 CAM 表（即交换机通过 MAC 地址学习维护的端口和 MAC 地址的对应表）里查到对应的端口（Port）为：vethb4963f3，然后把数据包发往这个端口。</li>
<li>而这个端口，正是 nginx-2 容器“插”在 docker0 网桥上的另一块虚拟网卡，当然，它也是一个 Veth Pair 设备。这样，数据包就进入到了 nginx-2 容器的 Network Namespace 里。</li>
<li>所以，nginx-2 容器看到的情况是，它自己的 eth0 网卡上出现了流入的数据包。这样，nginx-2 的网络协议栈就会对请求进行处理，最后将响应（Pong）返回到 nginx-1。<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E5%AE%B9%E5%99%A8%E9%80%9A%E4%BF%A1.png" class=""></li>
<li>熟悉了 docker0 网桥的工作方式，你就可以理解，在默认情况下，被限制在 Network Namespace 里的容器进程，实际上是通过 Veth Pair 设备 + 宿主机网桥的方式，实现了跟同其他容器的数据交换。</li>
<li>与之类似地，当你在一台宿主机上，访问该宿主机上的容器的 IP 地址时，这个请求的数据包，也是先根据路由规则到达 docker0 网桥，然后被转发到对应的 Veth Pair 设备，最后出现在容器里。这个过程的示意图，<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E5%AE%BF%E4%B8%BB%E6%9C%BA%E8%AE%BF%E9%97%AEdocker.png" class=""></li>
<li>同样地，当一个容器试图连接到另外一个宿主机时，比如：ping 10.168.0.3，它发出的请求数据包，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机的路由表里的直连路由规则（10.168.0.0/24 via eth0)），对 10.168.0.3 的访问请求就会交给宿主机的 eth0 处理。</li>
<li>所以接下来，这个数据包就会经宿主机的 eth0 网卡转发到宿主机网络上，最终到达 10.168.0.3 对应的宿主机上。<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/docker%E8%AE%BF%E9%97%AE%E5%85%B6%E4%BB%96%E7%BD%91%E7%BB%9C.png" class=""></li>
<li>当你遇到容器连不通“外网”的时候，你都应该先试试 docker0 网桥能不能 ping 通，然后查看一下跟 docker0 和 Veth Pair 设备相关的 iptables 规则是不是有异常，往往就能够找到问题的答案了。</li>
<li>跨主机通信Overlay Network（覆盖网络）。<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/%E8%B7%A8%E4%B8%BB%E6%9C%BA%E9%80%9A%E4%BF%A1.png" class=""></li>
</ul>
<h2 id="深入解析容器跨主机网络-Flannel项目说起"><a href="#深入解析容器跨主机网络-Flannel项目说起" class="headerlink" title="深入解析容器跨主机网络 Flannel项目说起"></a>深入解析容器跨主机网络 Flannel项目说起</h2><p>Flannel 项目是 CoreOS 公司主推的容器网络方案。事实上，Flannel 项目本身只是一个框架，真正为我们提供容器网络功能的，是 Flannel 的后端实现。目前，Flannel 支持三种后端实现，分别是：</p>
<ul>
<li>VXLAN；</li>
<li>host-gw；</li>
<li>UDP。</li>
</ul>
<h3 id="UDP-模式开始，来为你讲解容器“跨主网络”的实现原理"><a href="#UDP-模式开始，来为你讲解容器“跨主网络”的实现原理" class="headerlink" title="UDP 模式开始，来为你讲解容器“跨主网络”的实现原理"></a>UDP 模式开始，来为你讲解容器“跨主网络”的实现原理</h3><p>例子：我有两台宿主机。</p>
<ul>
<li><p>宿主机 Node 1 上有一个容器 container-1，它的 IP 地址是 100.96.1.2，对应的 docker0 网桥的地址是：100.96.1.1/24。</p>
</li>
<li><p>宿主机 Node 2 上有一个容器 container-2，它的 IP 地址是 100.96.2.3，对应的 docker0 网桥的地址是：100.96.2.1/24。</p>
</li>
<li><p>我们现在的任务，就是让 container-1 访问 container-2。</p>
</li>
<li><p>container-1 容器里的进程发起的 IP 包，其源地址就是 100.96.1.2，目的地址就是 100.96.2.3。</p>
</li>
<li><p>由于目的地址 100.96.2.3 并不在 Node 1 的 docker0 网桥的网段里，所以这个 IP 包会被交给默认路由规则，通过容器的网关进入 docker0 网桥（如果是同一台宿主机上的容器间通信，走的是直连规则），从而出现在宿主机上。</p>
</li>
<li><p>这时候，这个 IP 包的下一个目的地，就取决于宿主机上的路由规则了。此时，Flannel 已经在宿主机上创建出了一系列的路由规则，以 Node 1 为例，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在 Node 1 上</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ip route</span></span><br><span class="line">default via 10.168.0.1 dev eth0</span><br><span class="line">100.96.0.0/16 dev flannel0  proto kernel  scope link  src 100.96.1.0</span><br><span class="line">100.96.1.0/24 dev docker0  proto kernel  scope link  src 100.96.1.1</span><br><span class="line">10.168.0.0/24 dev eth0  proto kernel  scope link  src 10.168.0.2</span><br></pre></td></tr></table></figure></li>
<li><p>可以看到，由于我们的 IP 包的目的地址是 100.96.2.3，它匹配不到本机 docker0 网桥对应的 100.96.1.0/24 网段，只能匹配到第二条、也就是 100.96.0.0/16 对应的这条路由规则，从而进入到一个叫作 flannel0 的设备中。</p>
</li>
<li><p>而这个 flannel0 设备的类型就比较有意思了：它是一个 TUN 设备（Tunnel 设备）。</p>
<ul>
<li>在 Linux 中，TUN 设备是一种工作在三层（Network Layer）的虚拟网络设备。TUN 设备的功能非常简单，即：在操作系统内核和用户应用程序之间传递 IP 包。</li>
<li>像上面提到的情况，当操作系统将一个 IP 包发送给 flannel0 设备之后，flannel0 就会把这个 IP 包，交给创建这个设备的应用程序，也就是 Flannel 进程。这是一个从内核态（Linux 操作系统）向用户态（Flannel 进程）的流动方向。</li>
<li>反之，如果 Flannel 进程向 flannel0 设备发送了一个 IP 包，那么这个 IP 包就会出现在宿主机网络栈中，然后根据宿主机的路由表进行下一步处理。这是一个从用户态向内核态的流动方向。</li>
</ul>
</li>
<li><p>所以，当 IP 包从容器经过 docker0 出现在宿主机，然后又根据路由表进入 flannel0 设备后，宿主机上的 flanneld 进程（Flannel 项目在每个宿主机上的主进程），就会收到这个 IP 包。然后，flanneld 看到了这个 IP 包的目的地址，是 100.96.2.3，就把它发送给了 Node 2 宿主机。</p>
</li>
<li><p>flanneld 通过子网Subnet来知道IP 地址对应的容器，是运行在 Node 2 上</p>
<ul>
<li><p>在由 Flannel 管理的容器网络里，一台宿主机上的所有容器，都属于该宿主机被分配的一个“子网”。</p>
</li>
<li><p>在我们的例子中，Node 1 的子网是 100.96.1.0/24，container-1 的 IP 地址是 100.96.1.2。</p>
</li>
<li><p>Node 2 的子网是 100.96.2.0/24，container-2 的 IP 地址是 100.96.2.3。</p>
</li>
<li><p>而这些子网与宿主机的对应关系，正是保存在 Etcd 当中，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> etcdctl ls /coreos.com/network/subnets</span></span><br><span class="line">/coreos.com/network/subnets/100.96.1.0-24</span><br><span class="line">/coreos.com/network/subnets/100.96.2.0-24</span><br><span class="line">/coreos.com/network/subnets/100.96.3.0-24</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>所以，flanneld 进程在处理由 flannel0 传入的 IP 包时，就可以根据目的 IP 的地址（比如 100.96.2.3），匹配到对应的子网（比如 100.96.2.0/24），从 Etcd 中找到这个子网对应的宿主机的 IP 地址是 10.168.0.3，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> etcdctl get /coreos.com/network/subnets/100.96.2.0-24</span></span><br><span class="line">&#123;&quot;PublicIP&quot;:&quot;10.168.0.3&quot;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>所以说，flanneld 在收到 container-1 发给 container-2 的 IP 包之后，就会把这个 IP 包直接封装在一个 UDP 包里，然后发送给 Node 2。</p>
<ul>
<li>不难理解，这个 UDP 包的源地址，就是 flanneld 所在的 Node 1 的地址，而目的地址，则是 container-2 所在的宿主机 Node 2 的地址。</li>
<li>当然，这个请求得以完成的原因是，每台宿主机上的 flanneld，都监听着一个 8285 端口，所以 flanneld 只要把 UDP 包发往 Node 2 的 8285 端口即可。</li>
</ul>
</li>
<li><p>Node 2 上监听 8285 端口的进程也是 flanneld，所以这时候，flanneld 就可以从这个 UDP 包里解析出封装在里面的、container-1 发来的原 IP 包。</p>
</li>
<li><p>而接下来 flanneld 的工作就非常简单了：flanneld 会直接把这个 IP 包发送给它所管理的 TUN 设备，即 flannel0 设备。</p>
</li>
<li><p>Linux 内核网络栈就会负责处理这个 IP 包，具体的处理方法，就是通过本机的路由表来寻找这个 IP 包的下一步流向。</p>
</li>
<li><p>而 Node 2 上的路由表，跟 Node 1 非常类似，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在 Node 2 上</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ip route</span></span><br><span class="line">default via 10.168.0.1 dev eth0</span><br><span class="line">100.96.0.0/16 dev flannel0  proto kernel  scope link  src 100.96.2.0</span><br><span class="line">100.96.2.0/24 dev docker0  proto kernel  scope link  src 100.96.2.1</span><br><span class="line">10.168.0.0/24 dev eth0  proto kernel  scope link  src 10.168.0.3</span><br></pre></td></tr></table></figure></li>
<li><p>由于这个 IP 包的目的地址是 100.96.2.3，它跟第三条、也就是 100.96.2.0/24 网段对应的路由规则匹配更加精确。所以，Linux 内核就会按照这条路由规则，把这个 IP 包转发给 docker0 网桥。</p>
</li>
<li><p>docker0 网桥会扮演二层交换机的角色，将数据包发送给正确的端口，进而通过 Veth Pair 设备进入到 container-2 的 Network Namespace 里。</p>
</li>
<li><p>需要注意的是，上述流程要正确工作还有一个重要的前提，那就是 docker0 网桥的地址范围必须是 Flannel 为宿主机分配的子网。这个很容易实现，以 Node 1 为例，你只需要给它上面的 Docker Daemon 启动时配置如下所示的 bip 参数即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">FLANNEL_SUBNET=100.96.1.1/24</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> dockerd --bip=<span class="variable">$FLANNEL_SUBNET</span> ...</span></span><br></pre></td></tr></table></figure></li>
</ul>
<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/UDP%E6%A8%A1%E5%BC%8F.png" class="">

<p>UDP被弃用原因：</p>
<ul>
<li>实际上，相比于两台宿主机之间的直接通信，基于 Flannel UDP 模式的容器通信多了一个额外的步骤，即 flanneld 的处理过程。而这个过程，由于使用到了 flannel0 这个 TUN 设备，仅在发出 IP 包的过程中，就需要经过三次用户态与内核态之间的数据拷贝，如下所示：<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/UDP%E5%BC%83%E7%94%A8.png" class=""><ul>
<li>第一次：用户态的容器进程发出的 IP 包经过 docker0 网桥进入内核态；</li>
<li>第二次：IP 包根据路由表进入 TUN（flannel0）设备，从而回到用户态的 flanneld 进程；</li>
<li>第三次：flanneld 进行 UDP 封包之后重新进入内核态，将 UDP 包通过宿主机的 eth0 发出去。</li>
</ul>
</li>
<li>此外，我们还可以看到，Flannel 进行 UDP 封装（Encapsulation）和解封装（Decapsulation）的过程，也都是在用户态完成的。在 Linux 操作系统中，上述这些上下文切换和用户态操作的代价其实是比较高的，这也正是造成 Flannel UDP 模式性能不好的主要原因</li>
</ul>
<p>我们在进行系统级编程的时候，有一个非常重要的优化原则，就是要减少用户态到内核态的切换次数，并且把核心的处理逻辑都放在内核态进行</p>
<h3 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h3><p>VXLAN，即 Virtual Extensible LAN（虚拟可扩展局域网），是 Linux 内核本身就支持的一种网络虚似化技术。所以说，VXLAN 可以完全在内核态实现上述封装和解封装的工作，从而通过与前面相似的“隧道”机制，构建出覆盖网络（Overlay Network）。</p>
<p>VXLAN 的覆盖网络的设计思想是：在现有的三层网络之上，“覆盖”一层虚拟的、由内核 VXLAN 模块负责维护的二层网络，使得连接在这个 VXLAN 二层网络上的“主机”（虚拟机或者容器都可以）之间，可以像在同一个局域网（LAN）里那样自由通信。当然，实际上，这些“主机”可能分布在不同的宿主机上，甚至是分布在不同的物理机房里。</p>
<p>而为了能够在二层网络上打通“隧道”，VXLAN 会在宿主机上设置一个特殊的网络设备作为“隧道”的两端。这个设备就叫作 VTEP，即：VXLAN Tunnel End Point（虚拟隧道端点）。</p>
<p>而 VTEP 设备的作用，其实跟前面的 flanneld 进程非常相似。只不过，它进行封装和解封装的对象，是二层数据帧（Ethernet frame）；而且这个工作的执行流程，全部是在内核里完成的（因为 VXLAN 本身就是 Linux 内核中的一个模块）。</p>
<p>上述基于 VTEP 设备进行“隧道”通信的流程，我也为你总结成了一幅图，如下所示：</p>
<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/vxlan%E5%8E%9F%E7%90%86.png" class="">

<ul>
<li><p>可以看到，图中每台宿主机上名叫 flannel.1 的设备，就是 VXLAN 所需的 VTEP 设备，它既有 IP 地址，也有 MAC 地址。</p>
</li>
<li><p>现在，我们的 container-1 的 IP 地址是 10.1.15.2，要访问的 container-2 的 IP 地址是 10.1.16.3。</p>
</li>
<li><p>那么，与前面 UDP 模式的流程类似，当 container-1 发出请求之后，这个目的地址是 10.1.16.3 的 IP 包，会先出现在 docker0 网桥，然后被路由到本机 flannel.1 设备进行处理。</p>
</li>
<li><p>为了能够将“原始 IP 包”封装并且发送到正确的宿主机，VXLAN 就需要找到这条“隧道”的出口，即：目的宿主机的 VTEP 设备。</p>
</li>
<li><p>而这个设备的信息，正是每台宿主机上的 flanneld 进程负责维护的。</p>
</li>
<li><p>比如，当 Node 2 启动并加入 Flannel 网络之后，在 Node 1（以及所有其他节点）上，flanneld 就会添加一条如下所示的路由规则：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">...</span><br><span class="line">10.1.16.0       10.1.16.0       255.255.255.0   UG    0      0        0 flannel.1</span><br></pre></td></tr></table></figure></li>
<li><p>这条规则的意思是：凡是发往 10.1.16.0/24 网段的 IP 包，都需要经过 flannel.1 设备发出，并且，它最后被发往的网关地址是：10.1.16.0。</p>
</li>
<li><p>10.1.16.0 正是 Node 2 上的 VTEP 设备（也就是 flannel.1 设备）的 IP 地址。</p>
</li>
<li><p>“源 VTEP 设备”收到“原始 IP 包”后，就要想办法把“原始 IP 包”加上一个目的 MAC 地址，封装成一个二层数据帧，然后发送给“目的 VTEP 设备”（当然，这么做还是因为这个 IP 包的目的地址不是本机）。</p>
</li>
<li><p>这里需要解决的问题就是：“目的 VTEP 设备”的 MAC 地址是什么？</p>
<ul>
<li><p>此时，根据前面的路由记录，我们已经知道了“目的 VTEP 设备”的 IP 地址。而要根据三层 IP 地址查询对应的二层 MAC 地址，这正是 ARP（Address Resolution Protocol ）表的功能。</p>
</li>
<li><p>而这里要用到的 ARP 记录，也是 flanneld 进程在 Node 2 节点启动时，自动添加在 Node 1 上的。我们可以通过 ip 命令看到它，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在 Node 1 上</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ip neigh show dev flannel.1</span></span><br><span class="line">10.1.16.0 lladdr 5e:f8:4f:00:e3:37 PERMANENT</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>有了这个“目的 VTEP 设备”的 MAC 地址，Linux 内核就可以开始二层封包工作了。这个二层帧的格式，如下所示：<img src="/2021/07/03/8-%E7%BD%91%E7%BB%9C/vxlan%E5%86%85%E9%83%A8%E5%B8%A7.png" class=""></p>
</li>
<li><p>然后，Linux 内核会把这个数据帧封装进一个 UDP 包里发出去。</p>
</li>
<li><p>…</p>
</li>
<li><p>接下来，Node 1 上的 flannel.1 设备就可以把这个数据帧从 Node 1 的 eth0 网卡发出去。显然，这个帧会经过宿主机网络来到 Node 2 的 eth0 网卡。</p>
</li>
<li><p>这时候，Node 2 的内核网络栈会发现这个数据帧里有 VXLAN Header，并且 VNI=1。所以 Linux 内核会对它进行拆包，拿到里面的内部数据帧，然后根据 VNI 的值，把它交给 Node 2 上的 flannel.1 设备。</p>
</li>
<li><p>而 flannel.1 设备则会进一步拆包，取出“原始 IP 包”。接下来就回到了我在上一篇文章中分享的单机容器网络的处理流程。最终，IP 包就进入到了 container-2 容器的 Network Namespace 里。</p>
</li>
</ul>
<p><strong>不难看到，上面的例子有一个共性，那就是用户的容器都连接在 docker0 网桥上。而网络插件则在宿主机上创建了一个特殊的设备（UDP 模式创建的是 TUN 设备，VXLAN 模式创建的则是 VTEP 设备），docker0 与这个设备之间，通过 IP 转发（路由表）进行协作。<br>然后，网络插件真正要做的事情，则是通过某种方法，把不同宿主机上的特殊设备连通，从而达到容器跨主机通信的目的。</strong></p>
<p>实际上，上面这个流程，也正是 Kubernetes 对容器网络的主要处理方法。只不过，Kubernetes 是通过一个叫作 CNI 的接口，维护了一个单独的网桥来代替 docker0。这个网桥的名字就叫作：CNI 网桥，它在宿主机上的设备名称默认是：cni0。</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://blog.opskumu.com/kubernetes-ext-service.html">https://blog.opskumu.com/kubernetes-ext-service.html</a><br>Kubernetes 外部服务映射<br>Table of Contents</p>
<ol>
<li>外部域名映射到内部 Service -&gt; ExternalName</li>
<li>外部 IP 映射到内部 Service<br> 2.1. IP 映射<br> 2.2. IP + 端口映射</li>
<li>小结<br>集群内的应用有时候需要调用外部的服务，我们知道集群内部服务调用都是通过 Service 互相访问，那么针对外部的服务是否也可以保持统一使用 Service 呢？答案是肯定的，通过 Service 访问外部服务，除了方式统一以外，还能带来其他好处。如配置统一，不同环境（空间）相同应用访问外部不同环境的数据库，可以通过 Service 映射保持两边配置统一，达到不同空间应用通过相同 Service Name 访问不同的外部数据库。如图 test-1 和 test-2 两个空间为两个不同的业务环境，通过服务映射，不同空间相同的 Service 访问到对应外部不同环境的数据库：</li>
</ol>
<p>external-service.png</p>
<p>另外，还可以保证最小化变更，如果外部数据库 IP 之类的变动，只需要修改 Service 对应映射即可，服务本身配置无需变动。具体场景如下：</p>
<p>1 外部域名映射到内部 Service -&gt; ExternalName<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: mysql<br>spec:<br>  externalName: mysql.example.com<br>  type: ExternalName<br>创建之后，同一空间 Pod 就可以通过 mysql:3306 访问外部的 MySQL 服务。</p>
<p>需要注意的是，虽然 externalName 也支持填写 IP，但是并不会被 Ingress 和 CoreDNS 解析（KubeDNS 支持）。如果有 IP 相关的需求，则可以使用 Headless Service -&gt; Type ExternalName 。另外一个需要注意的是，因为 CNAME 的缘故，如果外部的服务又经过一层代理转发，如 Nginx，除非配置对应的 server_name ，否则映射无效。</p>
<p>2 外部 IP 映射到内部 Service<br>2.1 IP 映射<br>前文提过，虽然 externalName 字段可以配置为 IP 地址，但是 Ingress 和 CoreDNS 并不会解析，如果外部服务为 IP 提供，那么可以使用 Headless Service 实现映射。</p>
<p>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: mysql<br>spec:<br>  clusterIP: None<br>  type: ClusterIP</p>
<hr>
<p>apiVersion: v1<br>kind: Endpoints<br>metadata:<br> name: mysql<br>subsets:</p>
<ul>
<li>addresses:<ul>
<li>ip: 192.168.1.10<br>service 不指定 selector，手动维护创建 endpoint，创建之后就可以通过 mysql:3306 访问 192.168.1.10:3306 服务的目的。Headless Service 不能修改端口相关，如果要修改访问端口，则需要进一步操作。</li>
</ul>
</li>
</ul>
<p>2.2 IP + 端口映射<br>如果外部的端口不是标准的端口，想通过 Service 访问时候使用标准端口，如外部 MySQL 提供端口为 3307，内部想通过 Service 3306 访问，这个时候则可以通过如下方式实现：</p>
<p>apiVersion: v1<br>kind: Service<br>metadata:<br> name: mysql<br>spec:<br> type: ClusterIP<br> ports:</p>
<ul>
<li>port: 3306<br>targetPort: 3307</li>
</ul>
<hr>
<p>apiVersion: v1<br>kind: Endpoints<br>metadata:<br> name: mysql<br>subsets:</p>
<ul>
<li>addresses:<ul>
<li>ip: 192.168.1.10<br>ports:</li>
<li>port: 3307<br>service 不指定 selector，手动维护创建 endpoint，创建之后就可以通过 mysql:3306 达到访问外部 192.168.1.10:3307 服务的目的。</li>
</ul>
</li>
</ul>
<p>参考 Kubernetes best practices: mapping external services<br>3 小结<br>我们可以看出以上外部服务映射，externalName 和 Headless Service 方式映射外部服务是没有经过中间层代理的，都是通过 DNS 劫持实现。而有端口变更需求的时候，则要经过内部 kube-proxy 层转发。正常情况下，能尽可能少的引入中间层就少引用，特别是数据库类的应用，因为引入中间层虽然带来了便利，但也意味着可能会带来性能损耗，特别是那些对延迟比较敏感的服务。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/07/02/7-pod/" rel="prev" title="7.pod">
      <i class="fa fa-chevron-left"></i> 7.pod
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/07/30/9-yaml%E7%9B%B8%E5%85%B3/" rel="next" title="9.yaml相关">
      9.yaml相关 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C"><span class="nav-number">1.</span> <span class="nav-text">容器网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E6%A1%A5"><span class="nav-number">1.1.</span> <span class="nav-text">网桥</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.1.</span> <span class="nav-text">原理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%E5%AE%B9%E5%99%A8%E8%B7%A8%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C-Flannel%E9%A1%B9%E7%9B%AE%E8%AF%B4%E8%B5%B7"><span class="nav-number">2.</span> <span class="nav-text">深入解析容器跨主机网络 Flannel项目说起</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#UDP-%E6%A8%A1%E5%BC%8F%E5%BC%80%E5%A7%8B%EF%BC%8C%E6%9D%A5%E4%B8%BA%E4%BD%A0%E8%AE%B2%E8%A7%A3%E5%AE%B9%E5%99%A8%E2%80%9C%E8%B7%A8%E4%B8%BB%E7%BD%91%E7%BB%9C%E2%80%9D%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">2.1.</span> <span class="nav-text">UDP 模式开始，来为你讲解容器“跨主网络”的实现原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VXLAN"><span class="nav-number">2.2.</span> <span class="nav-text">VXLAN</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">sk-xinye</p>
  <div class="site-description" itemprop="description">愿所有努力都不被辜负</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">142</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sk-xinye</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
