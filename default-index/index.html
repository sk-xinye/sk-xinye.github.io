<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sk-xinye.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.yml"};
  </script>

  <meta name="description" content="愿所有努力都不被辜负">
<meta property="og:type" content="website">
<meta property="og:title" content="sk-xinyeの博客">
<meta property="og:url" content="https://sk-xinye.github.io/default-index/index.html">
<meta property="og:site_name" content="sk-xinyeの博客">
<meta property="og:description" content="愿所有努力都不被辜负">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sk-xinye">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://sk-xinye.github.io/default-index/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>sk-xinyeの博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">sk-xinyeの博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习的脚步</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-fa fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">142</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/06/02/3-operator%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/02/3-operator%E6%B5%8B%E8%AF%95/" class="post-title-link" itemprop="url">3.operator测试</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-02 17:20:27" itemprop="dateCreated datePublished" datetime="2023-06-02T17:20:27+08:00">2023-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-16 21:14:55" itemprop="dateModified" datetime="2023-07-16T21:14:55+08:00">2023-07-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="hadoop环境搭建"><a href="#hadoop环境搭建" class="headerlink" title="hadoop环境搭建"></a>hadoop环境搭建</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><ol>
<li>地址： <a target="_blank" rel="noopener" href="https://archive.apache.org/dist/hadoop/common/">https://archive.apache.org/dist/hadoop/common/</a></li>
<li>hadoop-2.7.7.tar.gz 因要使用hive 2.1.1所以，使用对应的hadoop版本2.7.7</li>
<li>tar -xvf hadoop-2.7.7.tar.gz</li>
</ol>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol>
<li><p>路径 hadoop-2.7.7/etc/hadoop</p>
</li>
<li><p>hadoop-env.sh 修改 JAVA_HOME</p>
</li>
<li><p>修改core-site.xml</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node-193:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/data/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--以下为 开启 Kerberos --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.authentication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>kerberos<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.authorization<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.rpc.protection<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>authentication<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.auth_to_local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">            RULE:[2:$1/$2@$0](hadoop/.*@CONNECT.COM)s/.*/root/</span><br><span class="line">            DEFAULT</span><br><span class="line">            <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改hdfs-site.xml</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--以下为 开启 Kerberos --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.premissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 2 NameNode --&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.block.access.token.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.kerberos.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.keytab.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.kerberos.internal.spnego.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 3 Secondary NameNode --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.https.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:9869<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.namenode.keytab.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.namenode.kerberos.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.namenode.kerberos.internal.spnego.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.http.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HTTPS_ONLY<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.https-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-193:9871<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 5 DataNode --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir.perm<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>700<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;value&gt;0.0.0.0:1004&lt;/value&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:1104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;value&gt;0.0.0.0:1006&lt;/value&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:1106<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.https.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:9865<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.data.transfer.protection<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>integrity<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.kerberos.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.keytab.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.encrypt.data.transfer<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 6 WebHDFS --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.web.authentication.kerberos.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.web.authentication.kerberos.keytab<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置mapred-site.xml (kerberos时不配置该选项)</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置yarn-site.xml</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-193<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--以下为 开启 Kerberos --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/common/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/common/lib/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/hdfs/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/hdfs/lib/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/mapreduce/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/mapreduce/lib/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/yarn/*,</span><br><span class="line">            /home/ksun/k8s-env/hadoop/hadoop-2.7.7/share/hadoop/yarn/lib/*</span><br><span class="line">        <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Kerberos --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 1 ResourceManager --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.keytab<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.https.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 2 NodeManager --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.keytab<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.webapp.https.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:8044<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置java /etc/profile</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/home/ksun/k8s-env/hadoop/jdk1.8</span><br><span class="line">export HADOOP_HOME=/home/ksun/k8s-env/hadoop/hadoop-2.7.7</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span></span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span></span><br><span class="line"></span><br><span class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$&#123;HADOOP_HOME&#125;/lib/native</span><br><span class="line">export HADOOP_OPTS=&quot;-Djava.library.path=$&#123;HADOOP_HOME&#125;/lib&quot;</span><br><span class="line">export HIVE_HOME=/home/ksun/k8s-env/hadoop/hive-2.1.1</span><br><span class="line">export HIVE_CONF_DIR=$&#123;HIVE_HOME&#125;/conf</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> PATH=.:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> PATH=/home/ksun/k8s-env/hadoop/jdk1.8/bin:/home/ksun/k8s-env/hadoop/jdk1.8/jre/bin:/home/ksun/k8s-env/hadoop/hive-2.1.1/bin:/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/usr/sbin:/usr/<span class="built_in">local</span>/bin:/usr/bin</span></span><br><span class="line">export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin</span><br><span class="line">export  PATH=.:$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li>
<li><p>启动hadoop</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format   格式化hadoop</span><br><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line">如果出现了SencondaryNameNode NameNode DataNode NodeManager ResourceManager则没什么问题，启动成功</span><br></pre></td></tr></table></figure></li>
<li><p>root启动</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Attempting to operate on hdfs namenode as root 等问题</span><br><span class="line"></span><br><span class="line"> 在/hadoop/sbin路径下：</span><br><span class="line">     将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数</span><br><span class="line">          HDFS_DATANODE_USER=root</span><br><span class="line">          HADOOP_SECURE_DN_USER=hdfs</span><br><span class="line">          HDFS_NAMENODE_USER=root</span><br><span class="line">          HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">     start-yarn.sh，stop-yarn.sh顶部也需添加以下</span><br><span class="line">        YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">        HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">        YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure></li>
<li><p>相关命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">export KRB5CCNAME=/tmp/krb5cc_0</span><br><span class="line">[root@node-193 hadoop]# kinit -kt /home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab hadoop/node-193@CONNECT.COM</span><br><span class="line">/home/ksun/k8s-env/hadoop/hadoop-2.7.7/data/</span><br><span class="line">hive</span><br><span class="line">    beeline</span><br><span class="line">        /opt/module/hive/bin/beeline -u &quot;jdbc:hive2://192.168.83.187:10000/;auth=KERBEROS;principal=hive1/node187@CONNECT.COM&quot;</span><br><span class="line">        show databases;</span><br><span class="line">        create database if not exists pp2_test;</span><br><span class="line">        show tables;</span><br><span class="line">        show create table e_mp_read_curve;</span><br><span class="line">        load data local inpath &#x27;/home/robot/&#x27; overwrite into table pp2_test.yc_meter_archives partition(dt=&#x27;20221213&#x27;)</span><br><span class="line">        insert overwrite local directory &#x27;/home/data/&#x27; select * from hive_table;</span><br><span class="line">        cloudera-scm/admin</span><br><span class="line">    cloudera-scm/admin</span><br><span class="line">hdfs:</span><br><span class="line">    hdfs dfs -mkdir /demo1</span><br><span class="line">    hdfs dfs -ls /user/hive/csv/jibei_hubiao</span><br><span class="line">    hdfs dfs -get /user/hive/csv/jibei_hubiao/e_mp_read_curve ./;</span><br><span class="line">    hdfs dfs -put /root/sql_tmp/1wtg/ /user/pp2/binary_data/</span><br><span class="line">    hdfs dfs -rm -r 文件夹路径</span><br><span class="line">    hdfs dfs -chmod -R +w /user/hive/warehouse 设置权限</span><br><span class="line">导数据可以直接-get 然后-put就可以了</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Hive环境搭建"><a href="#Hive环境搭建" class="headerlink" title="Hive环境搭建"></a>Hive环境搭建</h2><h3 id="下载hive"><a href="#下载hive" class="headerlink" title="下载hive"></a>下载hive</h3><ol>
<li>地址：<a target="_blank" rel="noopener" href="https://github.com/apache/hive/tree/rel/release-2.1.1">https://github.com/apache/hive/tree/rel/release-2.1.1</a></li>
<li>提前安装好mysql需要</li>
<li>tar -xvf apache-hive-2.1.1-bin.tar.gz</li>
</ol>
<h3 id="配置与启动"><a href="#配置与启动" class="headerlink" title="配置与启动"></a>配置与启动</h3><ol>
<li><p>配置环境变量，如上述内容7所示</p>
</li>
<li><p>修改hive-env.sh文件</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /home/ksun/k8s-env/hadoop/hive-2.1.1/conf 下进行修改</span><br><span class="line"></span><br><span class="line">export HIVE_HOME=/home/ksun/k8s-env/hadoop/hive-2.1.1</span><br><span class="line">export HIVE_CONF_DIR=$&#123;HIVE_HOME&#125;/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=$&#123;HIVE_HOME&#125;/lib</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> HADOOP_HOME=/home/ksun/k8s-env/hadoop/hadoop-3.0.0</span></span><br><span class="line">export HADOOP_HOME=/home/ksun/k8s-env/hadoop/hadoop-2.7.7</span><br></pre></td></tr></table></figure></li>
<li><p>hive-site.xml</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cp hive-default.xml.template hive-site.xml</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vim hive-site.xml</span></span><br><span class="line">由于在该配置文件中有如下两个配置项注明了hive在HDFS中数据存储的目录，因此我们需要在HDFS上手动创建并赋权限，也就是需要在hdfs上创建/tmp/hive 和/user/hive/warehouse</span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop fs -mkdir -p /user/hive/warehouse</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop fs -chmod -R 777 /user/hive/warehouse <span class="comment">#递归赋予读写权限</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop fs -mkdir -p /tmp/hive/ <span class="comment">#创建/tmp/hive/目录</span></span>  </span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop fs -chmod -R 777 /tmp/hive <span class="comment">#目录赋予读写权限</span></span>  </span><br></pre></td></tr></table></figure>

 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.default.fileformat<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>TextFile<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--端口改为你自己的端口，这里是连接数据库中zxhive数据库--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://node187:3306/hive30<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--最新版本连接MySQL的jar包 所有写com.mysql.cj.jdbc.Driver,如果是旧版本用com.mysql.jdbc.Driver--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--连接MySQL的用户名--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.authentication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>KERBEROS<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.authentication.kerberos.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.authentication.kerberos.keytab<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node-193:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.sasl.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.kerberos.keytab.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.kerberos.principal<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/node-193@CONNECT.COM<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动测试</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">schematool -initSchema -dbType mysql</span><br><span class="line">hive</span><br><span class="line">kinit -c /tmp/krb5cc_0 -k -t /zshield/BGconf/hive/conf/hive.keytab hive/node-192@ZSHIELD.REALM</span><br><span class="line">beeline -u &quot;jdbc:hive2://192.168.81.192:10000/;principal=hive/node-192@ZSHIELD.REALM&quot;</span><br><span class="line"></span><br><span class="line">kinit -kt /home/ksun/k8s-env/hadoop/hadoop-2.7.7/etc/hadoop/hadoop.keytab hadoop/node-193@CONNECT.COM  &amp;&amp; export KRB5CCNAME=/tmp/krb5cc_0</span><br></pre></td></tr></table></figure></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/04/25/2-k8s%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/25/2-k8s%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">2.k8s部署</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-25 14:15:33" itemprop="dateCreated datePublished" datetime="2023-04-25T14:15:33+08:00">2023-04-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-16 21:14:55" itemprop="dateModified" datetime="2023-07-16T21:14:55+08:00">2023-07-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="k8s搭建"><a href="#k8s搭建" class="headerlink" title="k8s搭建"></a>k8s搭建</h2><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><ol>
<li><p>关闭防火墙</p>
<p> $ systemctl stop firewalld<br> $ systemctl disable firewalld</p>
<p> 由于 CentOS8 防火墙使用了 nftables，但 Docker 尚未支持 nftables， 我们可以使用如下设置使用 iptables：<br> 更改 /etc/firewalld/firewalld.conf<br> #FirewallBackend=nftables<br> FirewallBackend=iptables</p>
</li>
<li><p>关闭selinux</p>
<p> $ sed -i ‘s/enforcing/disabled/‘ /etc/selinux/config  # 永久<br> $ setenforce 0  # 临时</p>
</li>
<li><p>关闭swap<br> $ swapoff -a  # 临时<br> $ vim /etc/fstab  注释掉 swap行挂载 # 永久  </p>
</li>
<li><p>设置主机名：<br> $ hostnamectl set-hostname <hostname></p>
</li>
<li><p>在master添加hosts：<br> $ cat &gt;&gt; /etc/hosts &lt;&lt; EOF<br> 192.168.81.192 node-192<br> 192.168.81.193 node-193<br> 192.168.81.194 node-194<br> EOF</p>
</li>
<li><p>将桥接的IPv4流量传递到iptables的链：<br> $ cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF<br> net.bridge.bridge-nf-call-ip6tables = 1<br> net.bridge.bridge-nf-call-iptables = 1<br> EOF<br> $ sysctl –system  # 生效</p>
</li>
<li><p>时间同步：<br> $ yum install ntpdate -y<br> $ ntpdate time.windows.com</p>
</li>
<li><p>安装docker<br>yum install -y yum-utils<br>yum-config-manager     –add-repo     <a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a><br>sed -i ‘s/download.docker.com/mirrors.aliyun.com/docker-ce/g’ /etc/yum.repos.d/docker-ce.repo<br>yum-config-manager –enable docker-ce-test<br>yum install docker-ce docker-ce-cli containerd.io<br>systemctl enable docker<br>systemctl start docker<br>systemctl enable docker.service</p>
<p>问题发生时，清理镜像：</p>
<pre><code> docker system prune
 systemctl stop kubelet
 systemctl stop docker
 systemctl start docker
 systemctl start kubelet
</code></pre>
</li>
<li><p>配置镜像仓库</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat &gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span></span><br><span class="line">&#123;</span><br><span class="line">&quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li>
<li><p>添加k8s yum源</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; <span class="string">EOF</span></span></span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li>
<li><p>安装kubeadm，kubelet和kubectl</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0</span><br><span class="line">systemctl enable kubelet</span><br><span class="line">kubeadm version #查看版本</span><br></pre></td></tr></table></figure></li>
<li><p>加载镜像</p>
<p>kubeadm config images list  查看需要的镜像列表<br>./load-images.sh</p>
</li>
<li><p>部署 K8S master</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">    --apiserver-advertise-address=192.168.81.192 \</span><br><span class="line">    --image-repository registry.aliyuncs.com/google_containers \  内网需要去掉这行</span><br><span class="line">    --kubernetes-version v1.18.0 \</span><br><span class="line">    --service-cidr=10.92.0.0/12 \</span><br><span class="line">    --pod-network-cidr=10.220.0.0/16 \</span><br><span class="line">    --ignore-preflight-errors=all</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.81.192:6443 --token xivvbs.rdmeg2w6g8i0m1ww --discovery-token-ca-cert-hash sha256:3f475490aaf5a86a4d0a83e40579b73b5ac4debf17dece0300e910fc542c2b70</span><br><span class="line"></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config   # 如果需要node节点使用kubectl ，可以将该文件复制到对应的node 节点位置</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes</span></span><br><span class="line"></span><br><span class="line">kubectl get pods -n kube-system  查看状态</span><br><span class="line">kubeadm token create --print-join-command 查看加入集群命令</span><br><span class="line">kubectl taint nodes --all node-role.kubernetes.io/master-  容忍master部署服务</span><br></pre></td></tr></table></figure></li>
<li><p>node节点加入集群</p>
<p>kubeadm join 192.168.81.192:6443 –token xivvbs.rdmeg2w6g8i0m1ww –discovery-token-ca-cert-hash sha256:3f475490aaf5a86a4d0a83e40579b73b5ac4debf17dece0300e910fc542c2b70<br>kubectl label node node-193 node-role.kubernetes.io/worker=worker 打标签 可做可不做<br>kubectl label node node-194 node-role.kubernetes.io/worker=worker</p>
</li>
<li><p>安装网络插件</p>
<p>docker load -i mirrored-flannelcni-flannel-cni-plugin.xz<br>docker load -i flannel.xz</p>
<p>docker apply -f kubectl apply -f kube-flannel.yml<br>问题：open /etc/resolv.conf: no such file or directory  随意添加一个dns文件即可 nameserver 8.8.8.8</p>
</li>
<li><p>helm安装</p>
</li>
</ol>
<ol start="17">
<li>问题</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">解决 Error: cannot re-use a name that is still in use</span><br><span class="line">解决方案如下：</span><br><span class="line">helm ls --all-namespaces</span><br><span class="line">kubectl delete namespace kuberhealthy</span><br><span class="line">kubectl create namespace kuberhealthy</span><br></pre></td></tr></table></figure>


<p>python -m zbuild.command.cloud_pkg pkg.include=[‘zs_power’] cache=/home/zshield/zhaoyu/v3 pkg.name=test_0506 pkg.zip=true server.zs_power.git.branch=feature/feature/PBUZZSHYY-2854-tmp-0506 server.zs_power.git.tag=null server.zs_power.git.build_shell=container/aliyun_zs_power_3.6/build.sh server.zs_power.version=test0506-3 extra_vars=qa</p>
<p>kubectl delete –all pods –namespace=foo<br>kubectl delete po <code>kubectl get po -n spark-sk | grep test | awk &#39;&#123;print $1&#125;&#39;</code>  –grace-period=0 –force -n spark-sk 批量删除pod<br>kubectl delete pods <pod> –grace-period=0 –force</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/04/25/1-cdh%E6%90%AD%E5%BB%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/25/1-cdh%E6%90%AD%E5%BB%BA/" class="post-title-link" itemprop="url">1.cdh搭建</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-25 14:00:11" itemprop="dateCreated datePublished" datetime="2023-04-25T14:00:11+08:00">2023-04-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-16 21:14:55" itemprop="dateModified" datetime="2023-07-16T21:14:55+08:00">2023-07-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="CDH平台搭建"><a href="#CDH平台搭建" class="headerlink" title="CDH平台搭建"></a>CDH平台搭建</h2><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><ol>
<li><p>配置初始化环境</p>
<p> 3台机器 213 214 215<br> cd /etc/yum.repos.d<br> mkdir bak<br> mv *.repo back<br> curl -O <a target="_blank" rel="noopener" href="http://192.168.2.7/files/dev7.repo">http://192.168.2.7/files/dev7.repo</a><br> yum clean all<br> yum makecache fast<br> yum install docker-ce docker-ce-cli containerd.io<br> cp ./docker-compose /usr/local/sbin/<br> systemctl start docker<br> echo “vm.max_map_count=655360” &gt;&gt; /etc/sysctl.conf</p>
</li>
<li><p>解压缩</p>
<p> unzip CDH6.3.2.zip</p>
</li>
<li><p>hosts配置</p>
<p> vim /etc/hosts<br> 192.168.82.213 node-213<br> 192.168.82.214 node-214<br> 192.168.82.215 node-215<br> source /etc/hosts</p>
</li>
<li><p>关闭防火墙<br> systemctl stop firewalld<br> systemctl disable firewalld<br> 临时关闭：setenforce 0<br> 永久关闭：vim /etc/selinux/config 修改SELINUX=disabled(重启生效)</p>
</li>
<li><p>配置免密登录（所有节点分别执行）<br> ssh-keygen -t rsa<br> ssh-copy-id node-214</p>
</li>
<li><p>时区、时间同步<br> 找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用1分钟同步一次</p>
<ol>
<li><p>时间服务器配置（必须root用户）<br> 1.1 查看所有节点ntpd服务状态和开机自启动状态<br> 查看：systemctl status ntpd<br> 启动：systemctl start ntpd<br> 开机启动：systemctl is-enabled ntpd</p>
<p> 1.2 修改node-213的ntp.conf配置文件<br> vim /etc/ntp.conf<br> 修改内容如下<br> （a）修改1（授权192.168.6.0-192.168.6.255网段上的所有机器可以从这台机器上查询和同步时间）<br> #restrict 192.168.6.0 mask 255.255.255.0 nomodify notrap<br> 为restrict 192.168.82.0 mask 255.255.255.0 nomodify notrap<br> （b）修改2（注释掉默认的上层主机，局域网内访问不到）：<br> server 0.centos.pool.ntp.org iburst<br> server 1.centos.pool.ntp.org iburst<br> server 2.centos.pool.ntp.org iburst<br> server 3.centos.pool.ntp.org iburst<br> （c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）<br> server 127.127.1.0<br> （d）设置本机作为时间服务器的等级（0为最高等级）<br> fudge 127.127.1.0 stratum 10</p>
<p> 1.3 修改node-213的/etc/sysconfig/ntpd 文件<br> vim /etc/sysconfig/ntpd<br> 增加内容如下（让硬件时间与系统时间一起同步）<br> SYNC_HWCLOCK=yes<br> 1.4 重新启动ntpd服务<br> systemctl start ntpd<br> 1.5 设置ntpd服务开机启动<br> systemctl enable ntpd</p>
</li>
<li><p>其他机器配置（必须root用户）方式二<br>(1)systemctl stop ntpd<br>(2)各台agent服务器编辑 /etc/ntp.conf文件b<br> 修改内容如下<br> (a)修改1（注释掉默认的上层主机，局域网内访问不到）：<br> server 0.centos.pool.ntp.org iburst<br> server 1.centos.pool.ntp.org iburst<br> server 2.centos.pool.ntp.org iburst<br> server 3.centos.pool.ntp.org iburst<br> (b)将node-213服务器作为时间服务器<br> server node-213<br>service ntpd restart<br>(3) 启动ntpd服务：systemctl start ntpd<br>(4) 设置开机启动：systemctl enable ntpd<br>(5)同步时间<br> ntpd -gq<br>(6) 大约5分钟后查看是否时间同步，出现下图以 * 开头的包含本机服务器的行说明没问题；<br> ntpdc -nc</p>
</li>
</ol>
</li>
<li><p>安装java<br> rpm -ivh oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm #update-alternatives –install /usr/bin/java java /usr/java/jdk1.8.0_181-cloudera/bin/java 3<br> vim /etc/profile<br> export JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera<br> export JRE_HOME=$JAVA_HOME/jre<br> export PATH=$PATH:$JAVA_HOME/bin<br> export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br> source /etc/profile</p>
</li>
<li><p>安装mysql<br> yum install krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel<br> yum install –skip-broken krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel<br> docker-compose up -d (需要注意映射文件目录)</p>
<p> create database cmf default character set utf8;<br> create database amon default character set utf8;<br> create database hive default character set utf8;<br> create database hue default character set utf8;<br> create database oozie default character set utf8;<br> grant all privileges on cmf.* to ‘cmf’@’%’ identified by ‘123456’;<br> grant all privileges on amon.* to ‘amon’@’%’ identified by ‘123456’;<br> grant all privileges on hive.* to ‘hive’@’%’ identified by ‘123456’;<br> grant all privileges on hue.* to ‘hue’@’%’ identified by ‘123456’;<br> flush privileges;</p>
<p> create database hue default charset utf8 collate utf8_general_ci;<br> grant all on hue.* to ‘root’@’%’ identified by ‘123456’;</p>
<p> create database hive default charset utf8;<br> create user ‘hive’@’%’ identified by ‘123456’;<br> grant all on hive.* TO ‘hive’@’localhost’ identified by ‘123456’;<br> grant all on hive.* TO ‘hive’@’%’ identified by ‘123456’;<br> flush privileges;</p>
<p> 2.5 重命名mysql jdbc jar<br> 1.准备 mysql-connector-java.jar</p>
<pre><code> mkdir -p /usr/share/java
</code></pre>
<p> 2.重命名</p>
<pre><code> cp mysql-connector-java-5.1.47.jar /usr/share/java/mysql-connector-java.jar
</code></pre>
</li>
<li><p>CM server部署<br> rpm -ivh cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm –nodeps –force<br> rpm -ivh cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm –nodeps –force</p>
<p> cd /etc/cloudera-scm-server<br> vim db.properties</p>
<pre><code> com.cloudera.cmf.db.host=node-213:13306
 com.cloudera.cmf.db.name=cmf
 com.cloudera.cmf.db.user=root
 com.cloudera.cmf.db.password=123456
 com.cloudera.cmf.db.setupType=EXTERNAL
</code></pre>
<p> 目录： /var/log/cloudera-scm-server<br> service cloudera-scm-server start</p>
</li>
<li><p>部署CM agent（所有节点）:<br>rpm -ivh cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm –nodeps –force<br>rpm -ivh cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm –nodeps –force</p>
<p>rpm -e –nodeps cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm<br>rpm -e –nodeps cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm   #卸载  卸载一次在安装就可以了<br>vim /etc/cloudera-scm-agent/conf.ini</p>
<pre><code>server_host=node-213
</code></pre>
<p>service cloudera-scm-agent start    多重启两次<br>日志：/var/log/cloudera-manager-agent/cloudera-manager-agent.log</p>
</li>
<li><p>安装httpd服务</p>
<ol>
<li>yum install httpd</li>
<li>mkdir /var/www/html/cdh6_parcel</li>
<li>把parcel文件放到文件夹下<br> CDH-6.3.2-1.cdh6.3.2.p0.1600554-el7.parcel<br> CDH-6.3.2-1.cdh6.3.2.p0.1600554-el7.parcel.sha<br> Manifest.json</li>
<li>启动httpd服务<br> systemctl start httpd</li>
<li>访问 <a target="_blank" rel="noopener" href="http://node-213/cdh6_parcel">http://node-213/cdh6_parcel</a></li>
</ol>
</li>
<li><p>访问安装即可</p>
<p><a target="_blank" rel="noopener" href="http://node-213:7180/">http://node-213:7180</a></p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/README/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/README/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="文件-I-O-简明概述"><a href="#文件-I-O-简明概述" class="headerlink" title="文件 I/O 简明概述"></a>文件 I/O 简明概述</h1><p>文件 I/O 性能是后台应用的主要瓶颈之一，一直以来想对文件 I/O 这个偌大的系统进行总结，故写此文。</p>
<p>文件 I/O 内容较多，书籍的意义在于能更系统地说明问题，避免博客文章散乱的问题。</p>
<p>书籍有涉及很大部分非原创内容，相关引用会在 REFERENCE 小节中指出。</p>
<p>书籍内容包括：</p>
<ul>
<li>[1.page cache](1. page cache.html)</li>
<li>[2.DMA 与零拷贝技术](2. DMA 与零拷贝技术.html)</li>
<li>[3.mmap](3. mmap.html)</li>
<li>[4.文件分区](4. 文件分区.html)</li>
<li>[5.Java ByteBuffer与 Channel](5. Java ByteBuffer与 Channel.html)</li>
<li>[6.FileChannel](6. FileChannel.html)</li>
<li>[7.JavaVisual 工具](7. Visual VM.html)</li>
<li>[8.Java ByteBuffer 测试](8. Java ByteBuffer 测试.html)</li>
<li>[9.如何实现顺序读写](9. 如何实现顺序读写.html)</li>
</ul>
<p>一些章节可能会需要一定的 Java 语言基础，其中：1<del>4 小节完全不需要 Java 基础，而 5</del>9 小节会涉及一定的 Java 代码。读者朋友可以有选择性地阅读。</p>
<p><img src="images/linux_io_stack_diagram.jpg" alt="linux_io_stack_diagram"></p>
<blockquote>
<p>Figure1.Linux IO Stack Diagram</p>
</blockquote>
<hr>
<p><strong>其他</strong></p>
<ul>
<li><p>个人博客地址：<a target="_blank" rel="noopener" href="https://spongecaptain.cool/">https://spongecaptain.cool</a></p>
</li>
<li><p>书籍 GitHub 地址：<a target="_blank" rel="noopener" href="https://github.com/Spongecaptain/SimpleClearFileIO">https://github.com/Spongecaptain/SimpleClearFileIO</a>，如有意见或者建议，特别希望读者朋友能够提 issue&amp;pr。若有帮助，欢迎 star&amp;fork。</p>
</li>
</ul>
<p><strong>推荐阅读</strong></p>
<ol>
<li><a target="_blank" rel="noopener" href="https://medium.com/databasss/on-disk-io-part-1-flavours-of-io-8e1ace1de017">On Disk IO, Part 1: Flavors of IO</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/databasss/on-disk-io-part-2-more-flavours-of-io-c945db3edb13">On Disk IO, Part 2: More Flavours of IO</a></li>
<li><a target="_blank" rel="noopener" href="http://smalldatum.blogspot.com/2015/11/read-write-space-amplification-pick-2_23.html">Read, write &amp; space amplification - pick 2</a></li>
</ol>
<p><strong>致谢</strong></p>
<p>本书受到 <a target="_blank" rel="noopener" href="https://www.cnkirito.moe/file-io-best-practise/">文件 IO 操作的一些最佳实践</a> 一文启发，很感谢阿里巴巴中间件团队的徐靖峰，其所写文章带来的启发意义非凡。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/9.%20%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%A1%BA%E5%BA%8F%E8%AF%BB%E5%86%99/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/9.%20%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%A1%BA%E5%BA%8F%E8%AF%BB%E5%86%99/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="如何实现顺序读写"><a href="#如何实现顺序读写" class="headerlink" title="如何实现顺序读写"></a>如何实现顺序读写</h1><h2 id="1-为什么顺序读写更快"><a href="#1-为什么顺序读写更快" class="headerlink" title="1. 为什么顺序读写更快"></a>1. 为什么顺序读写更快</h2><p>顺序读写快的原因主要有俩：</p>
<ol>
<li>顺序写比随机写更节约磁盘指针的移动总长度；</li>
<li>顺序写最大化利用到了文件系统的缓存机制，提高了缓存命中率；</li>
</ol>
<p>下面我们说一说原因 2 的由来：</p>
<p><img src="./images/1364556742_9652.gif" alt="PageCache"></p>
<p>如上图所示，以顺序读为例，当用户发起一个 fileChannel.read(4kb) 之后，实际发生了两件事：</p>
<ol>
<li>操作系统从磁盘加载了 16kb 进入 PageCache，这被称为预读</li>
<li>操作通从 PageCache 拷贝 4kb 进入用户内存；</li>
</ol>
<p>最终我们在用户内存访问到了 4kb，为什么顺序读快？很容量想到，当用户继续访问接下来的 [4kb,16kb] 的磁盘内容时，便是直接从 PageCache 去访问了。试想一下，当需要访问 16kb 的磁盘内容时，是发生 4 次磁盘 I/O 快，还是发生 1 次磁盘 I/O+4 次内存 I/O 快呢？答案是显而易见的，这一切都是 PageCache 带来的优化。</p>
<p>深度思考：当内存吃紧时，PageCache 的分配会受影响吗？PageCache 的大小如何确定，是固定的 16kb 吗？我可以监控 PageCache 的命中情况吗？ PageCache 会在哪些场景失效，如果失效了，我们又要哪些补救方式呢？</p>
<p>我进行简单的自问自答，背后的逻辑还需要读者去推敲：</p>
<ul>
<li>当内存吃紧时，PageCache 的预读会受到影响，实测，并没有搜到到文献支持</li>
<li>PageCache 是动态调整的，可以通过 linux 的系统参数进行调整，默认是占据总内存的 20%</li>
<li><a target="_blank" rel="noopener" href="https://github.com/brendangregg/perf-tools">https://github.com/brendangregg/perf-tools</a> github 上一款工具可以监控 PageCache</li>
<li>如果用 PageCache 做缓存不可控，不妨自己做预读。</li>
</ul>
<p>顺序写的原理和顺序读一致，都是收到了 PageCache 的影响，留给读者自己推敲一下。</p>
<h2 id="2-Java-上利用锁实现顺序读写"><a href="#2-Java-上利用锁实现顺序读写" class="headerlink" title="2. Java 上利用锁实现顺序读写"></a>2. Java 上利用锁实现顺序读写</h2><p>一个公认的事实是：无论是传统机械磁盘，还是固体硬盘，顺序读写比随机读写效率更高，那么<strong>如何实现顺序读写呢？</strong></p>
<p>为了说明这个问题，我们首先需要分清读写过程涉及的两种顺序（以写操作为例）：</p>
<ol>
<li>应用层的顺序性：接收端先后接收到两个消息：消息A、消息B，我们要求磁盘最终落盘时，消息就是以 A、B 次序保存的；</li>
<li>磁盘指针的顺序性：如果有两个线程负责写入 I/O 操作，线程 1 负责写消息 B，线程 2 负责写消息 A，但如果要确保磁盘指针的顺序移动，在消息 A 必须先于消息 B 落盘的大前提下，必然要求线程 2 先写，线程 B 后写。</li>
</ol>
<p>我们再举一个代码上的例子，这里没有应用层的顺序要求，只有磁盘指针的顺序要求。</p>
<p>写入方式一：64 个线程，用户自己使用一个 atomic 变量记录写入指针的位置，并发写入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executor &#x3D; Executors.newFixedThreadPool(64);&#x2F;&#x2F;64 大小的线程池</span><br><span class="line">AtomicLong wrotePosition &#x3D; new AtomicLong(0);&#x2F;&#x2F;指针</span><br><span class="line">for(int i&#x3D;0;i&lt;1024;i++)&#123;</span><br><span class="line">    final int index &#x3D; i;</span><br><span class="line">    executor.execute(()-&gt;&#123;</span><br><span class="line">        fileChannel.write(ByteBuffer.wrap(new byte[4*1024]),wrote.getAndAdd(4*1024));</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>写入方式二：给 write 加了锁，保证了同步：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executor = Executors.newFixedThreadPool(<span class="number">64</span>);</span><br><span class="line">AtomicLong wrotePosition = <span class="keyword">new</span> AtomicLong(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1024</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    executor.execute(()-&gt;&#123;</span><br><span class="line">        write(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>*<span class="number">1024</span>]);</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span>[] data)</span></span>&#123;</span><br><span class="line">    fileChannel.write(ByteBuffer.wrap(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>*<span class="number">1024</span>]),wrote.getAndAdd(<span class="number">4</span>*<span class="number">1024</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>只有方式二才算顺序写，顺序读也是同理。在方式 1 中，可能有如下顺序的写入：</p>
<ul>
<li>时序 1：thread1 write position[0~4096)；</li>
<li>时序 2：thread3 write position[8194~12288)；</li>
<li>时序 3：thread2 write position[4096~8194)；</li>
</ul>
<p>所以，方式一并不是完全的“顺序写”。</p>
<p><strong>对于文件操作，加锁并不是一件非常可怕的事，不敢同步 write/read 才可怕！</strong></p>
<blockquote>
<p>读时加锁 —&gt; 读的阻塞耗时期间锁会迟迟不释放。但是即使如此，为了顺序 I/O，我们还是要使用锁机制。</p>
</blockquote>
<p><strong>有人会问：FileChannel 内部不是已经有 positionLock 保证写入的线程安全了吗，为什么还要自己加同步？</strong></p>
<p>确实如此，但是 FileChannel#write 方法入口处的 position 生成（即<code>wrotePosition.getAndAdd(4*1024)</code>）与 FileChannel#write 方法内部的上锁不是原子操作，此时如果不粗粒度地上锁，就会导致顺序写失效。</p>
<h2 id="3-扩展-锁"><a href="#3-扩展-锁" class="headerlink" title="3. 扩展-锁"></a>3. 扩展-锁</h2><p>操作系统提供的 write 系统调用并没有确保原子语义，这意味着如果多个线程同时执行多个 write 操作来对同一个文件的同一个部分进行修改操作，那么最终执行结果取决于实际的执行逻辑顺序（这是无法预计的）。这种写场景类似于多线程访问共享变量，都是线程不安全的操作。</p>
<p>不过，文件系统提供两个操作的原子性，即当 open 系统调用以 flag 为 O_CREAT 或 O_APPEND 打开文件时。</p>
<ul>
<li>O_CREAT：文件不存在就创建；</li>
<li>O_APPEND：每次写文件时把文件游标移动到文件最后追加写；Java 中使用追加式文件写的例子为 <a target="_blank" rel="noopener" href="https://github.com/Spongecaptain/testAppendIoInJava">testAppendIoInJava</a>（NFS等文件系统不保证这个flag）；</li>
</ul>
<p>不过，即使确保原子操作，也无法确保并发安全性，因为原子性只是并发安全的一个条件。</p>
<p>我们通常使用锁来实现并发安全性，例如 Linux 有提供两种类型的文件锁：</p>
<ul>
<li>flock：只能对整个文件上锁，而不能对文件的某一部分上锁；</li>
<li>fcntl：即可以锁住整个文件，又能只锁文件的某一部分；</li>
</ul>
<p>但在事实上，我们通常会避免使用操作系统提供的文件锁，而是要么选择避免多线程同时写一个文件的情况，要么在应用层上实现锁，比如 Java 代码中的 synchronized 关键字。</p>
<h2 id="REFERENCE"><a href="#REFERENCE" class="headerlink" title="REFERENCE"></a>REFERENCE</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.cnkirito.moe/file-io-best-practise/">文件 IO 操作的一些最佳实践</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/charlesblc/p/6287631.html">Linux文件锁学习-flock, lockf, fcntl</a></p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/8.%20Java%20ByteBuffer%20%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/8.%20Java%20ByteBuffer%20%E6%B5%8B%E8%AF%95/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Java-ByteBuffer-测试"><a href="#Java-ByteBuffer-测试" class="headerlink" title="Java ByteBuffer 测试"></a>Java ByteBuffer 测试</h1><h2 id="1-Java-HeapByteBuffer-的读-写操作时会自动构造一个-DirectByteBuffer-实例"><a href="#1-Java-HeapByteBuffer-的读-写操作时会自动构造一个-DirectByteBuffer-实例" class="headerlink" title="1. Java-HeapByteBuffer 的读/写操作时会自动构造一个 DirectByteBuffer 实例"></a>1. Java-HeapByteBuffer 的读/写操作时会自动构造一个 DirectByteBuffer 实例</h2><p>JVM 的 HeapByteBuffer 在进行读写操作时，JVM 会在堆外自动构造一个 DirectByteBuffer 实例（这里的意思是需要在堆外在开辟一个一样大小的内存区域），过程如下图所示：</p>
<p>HeapByteBuffer(created by user) &lt;-automatically-&gt; DirectByteBuffer(created by JVM) &lt;-system call-&gt; pagecache &lt;-DMA-&gt; File on Disk</p>
<p><strong>1.JVM 为何如此设计？</strong></p>
<p>这么设计的理由可以参考：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/57374068/answer/152691891">https://www.zhihu.com/question/57374068/answer/152691891</a></p>
<p><strong>2.测试向</strong></p>
<p>为了测试 HeapByteBuffer 的这个性质，我们可以利用 Visual VM 工具来测试，我们需额外安装 VisualVM-BufferMonitor 插件。</p>
<p>测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cool.spongecaptain;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.FileSystems;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Path;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.StandardOpenOption;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestHeapByteBufferWithWrite</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, IOException </span>&#123;</span><br><span class="line">        <span class="comment">//allocate 1MB size HeapByteBuffer</span></span><br><span class="line">        ByteBuffer heapByteBuffer = ByteBuffer.allocate(<span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        <span class="comment">//make sure you have this file in the path</span></span><br><span class="line">        Path path = FileSystems.getDefault().getPath(<span class="string">&quot;/Users/wjjiang/Desktop/temp.md&quot;</span>);</span><br><span class="line">        FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ,StandardOpenOption.WRITE);</span><br><span class="line">        <span class="comment">//block on purpose</span></span><br><span class="line">        System.in.read();</span><br><span class="line">        fileChannel.write(heapByteBuffer);</span><br><span class="line">        <span class="comment">//block on purpose</span></span><br><span class="line">        <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>).await();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以在 VisualVM-BufferMonitor 插件对应的页面中看到如下结果：</p>
<p><img src="./images/image-20210202105507047.png" alt="image-20210202105507047"></p>
<p>测试结果证明了这个说法。</p>
<h2 id="2-DirectByteBuffer-会受到-GC-作用吗？"><a href="#2-DirectByteBuffer-会受到-GC-作用吗？" class="headerlink" title="2. DirectByteBuffer 会受到 GC 作用吗？"></a>2. DirectByteBuffer 会受到 GC 作用吗？</h2><p>虽然有“堆外内存的好处就在于不受 GC 影响”的说法，但在事实上，GC 能够回收堆外内存。</p>
<p><strong>1.GC 如何管理堆外内存？</strong></p>
<p>当 JVM 发生 full GC 时，会找到指向堆外内存的 DirectByteBuffer 实例，然后进行回收。但是 GC 并不会自己去负责回收 DirectByteBuffer 实例，而是依赖于 DirectByteBuffer 的静态内部类 Deallocator，后者实现了一个 Runnable 接口，后者的执行逻辑是创建一个线程释放该 DirectByteBuffer 对象 malloc 申请的直接内存空间。</p>
<p>正是因为如此，虽然 GC 算法（除了 CMS 算法）之外在 GC 发生时都需要移动 DirectBuffer 对象，但由于回收 DirectByteBuffer 对象所指向的内存空间不是由 GC 线程完成的，所以保证了堆外内存地址的不变性。</p>
<p>注意区分堆内 DirectByteBuffer 与堆外 DirectByteBuffer 实例指向的内存地址空间：</p>
<ul>
<li>DirectByteBuffer 实例是由 GC 线程回收的，其地址会随着 GC 改变；</li>
<li>DirectByteBuffer 实例指向的堆外地址由 Deallocator 线程回收，其地址不会随着回收改变。</li>
</ul>
<p>在堆内的 DirectByteBuffer 实例指向堆外一个较大的内存区域，这种对象被称为冰山对象。</p>
<p>总之，堆外内存不是直接由 GC 线程负责回收，因此减少了 GC 线程的压力，但同时也受到了 GC 线程管理。</p>
<p><strong>2.测试</strong></p>
<p>为了证明堆外内存也受到 GC 的管理，写了如下的测试案例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cool.spongecaptain;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestDirectByteBufferWithGC</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, IOException </span>&#123;</span><br><span class="line">        <span class="comment">//allocate 1MB size DirectByteBuffer</span></span><br><span class="line">        ByteBuffer directBytebuffer = ByteBuffer.allocateDirect(<span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">        System.in.read();</span><br><span class="line">        <span class="comment">//help the GC to free</span></span><br><span class="line">        directBytebuffer = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        System.gc();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//block on purpose</span></span><br><span class="line">        <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>).await();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="./images/image-20210202193642370.png" alt="image-20210202193642370"></p>
<h2 id="3-DirectByteBuffer-的主动内存释放"><a href="#3-DirectByteBuffer-的主动内存释放" class="headerlink" title="3. DirectByteBuffer 的主动内存释放"></a>3. DirectByteBuffer 的主动内存释放</h2><p><strong>1.DirectByteBuffer 不应依赖于 JVM 的 GC 进行回收</strong></p>
<p>正如第二节所说，只有 JVM 进行 full GC 时，GC 线程才会触发 DirectByteBuffer 的“标记”，然后利用非 GC 线程去回收堆外内存。但在另一方面，DirectByteBuffer 实例在堆内所占内存空间非常小，因此 DirectByteBuffer 实例本身的构造难以导致 full GC。堆外内存使用再多，也无法触发 full GC。</p>
<p>如果 DirectByteBuffer 完全依赖于 JVM 的 GC 机制进行内存回收管理，那么很容易导致堆外内存分配过多，最终导致 <code>OutOfMemoryError(&quot;Direct buffer memory”)</code> 异常。</p>
<p><strong>2.JVM 之上的 DirectByteBuffer 主动释放</strong></p>
<p>DirectByteBuffer 的释放可以由用户代码主动触发。方法是利用 Cleaner#clean 方法。</p>
<p><strong>3.测试</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cool.spongecaptain;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sun.nio.ch.DirectBuffer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestDirectBufferCleaner</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//allocate 1MB size DirectByteBuffer</span></span><br><span class="line">        ByteBuffer directBytebuffer = ByteBuffer.allocateDirect(<span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        <span class="comment">//block on purpose</span></span><br><span class="line">        System.in.read();</span><br><span class="line">        <span class="comment">//help the GC to free</span></span><br><span class="line">        ((DirectBuffer)directBytebuffer).cleaner().clean();</span><br><span class="line">        <span class="comment">//block on purpose</span></span><br><span class="line">        <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>).await();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过 VisualVM 工具观察结果如下：</p>
<p><img src="./images/image-20210202193520655.png" alt="image-20210202193520655"></p>
<h2 id="4-MMAP-的内存大小可以远大于内存？"><a href="#4-MMAP-的内存大小可以远大于内存？" class="headerlink" title="4. MMAP 的内存大小可以远大于内存？"></a>4. MMAP 的内存大小可以远大于内存？</h2><p>我们通过 FileChannel#map 方法能够在 Java 中实现 MMAP 机制，我们可以发现，mmap 能够“申请”到远大于物理机内存大小的内存。</p>
<p>测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cool.spongecaptain;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.FileSystems;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Path;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.StandardOpenOption;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMmapMomoryOccupy</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//allocate 1MB size HeapByteBuffer</span></span><br><span class="line">        ByteBuffer heapByteBuffer = ByteBuffer.allocate(<span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        <span class="comment">//make sure you have this file in the path</span></span><br><span class="line">        Path path = FileSystems.getDefault().getPath(<span class="string">&quot;/Users/wjjiang/Desktop/temp.md&quot;</span>);</span><br><span class="line">        FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ,StandardOpenOption.WRITE);</span><br><span class="line">        <span class="comment">//allocate 1000G size memory</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            fileChannel.map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, <span class="number">1024L</span> * <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//block on purpose</span></span><br><span class="line">        <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>).await();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码通过“申请”，映射得到了 1000G 大小的内存，但是我本机只有 16G 大小的内存，如何能够得到如此大的内存空间呢？</p>
<p>VisualVM 的监控结果如下图所示：</p>
<p><img src="./images/image-20210202194613544.png" alt="image-20210202194613544"></p>
<p>我们向操作系统询问一下该线程（pid 为 5950）一共占据了多大的内存空间，命令为 <code>top -pid 5950</code>。</p>
<p><img src="./images/image-20210202195247615.png" alt="image-20210202195247615"></p>
<p>可见，此 Java 线程仅仅占用了 106MB 大小的内存，远远不及 1000GB 大小。而且事实上，我的机器只有 16GB 的内存大小。</p>
<p>从测试结果中反映出如下两个事实：</p>
<ol>
<li>内存映射并不等于内存占用，很多文章认为内存映射这种方式可以大幅度提升文件的读写速度，并宣称“写 MappedByteBuffer 就等于写内存”，实际是非常错误的认知。通过控制面板可以查看到该 Java 进程（pid 5950）实际占用的内存仅仅不到 100M。很多写操作会会触发页缺失异常，然后需要进行磁盘 I/O。</li>
<li>MappedByteBuffer 映射出一片文件内容之后，不会全部加载到内存中，而是会进行一部分的预读（体现在占用的那 100M 上），MappedByteBuffer 不是文件读写的银弹，它仍然依赖于 PageCache 异步刷盘的机制。 <strong>通过 Java VisualVM 可以监控到 mmap 总映射的大小，但并不是实际占用的物理内存大小</strong>。</li>
</ol>
<h2 id="REFERENCE"><a href="#REFERENCE" class="headerlink" title="REFERENCE"></a>REFERENCE</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.cnkirito.moe/nio-buffer-recycle/">一文探讨堆外内存的监控与回收</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/57374068/answer/152691891">Java NIO中，关于DirectBuffer，HeapBuffer的疑问？</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/7.%20Visual%20VM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/7.%20Visual%20VM/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="JavaVisusal-工具"><a href="#JavaVisusal-工具" class="headerlink" title="JavaVisusal 工具"></a>JavaVisusal 工具</h1><h2 id="1-什么是-JavaVisusal-工具"><a href="#1-什么是-JavaVisusal-工具" class="headerlink" title="1. 什么是 JavaVisusal 工具"></a>1. 什么是 JavaVisusal 工具</h2><p>JavaVisusal 工具的介绍非常简洁直白，如下：</p>
<blockquote>
<p>VisualVM is a visual tool integrating commandline JDK tools and lightweight profiling capabilities.</p>
<p>Designed for both development and production time use.</p>
</blockquote>
<p>可见 JavaVisusal 工具的特性可以总结为：可视化、内置命令行 JDK 工具、轻量、同时适用于开发以及远程部署。</p>
<p>JDK8 中 JavaVisual 工具属于一款自带工具，而在 JDK11 中，JavaVisual 已经不自带，而需要我们从 <a target="_blank" rel="noopener" href="https://visualvm.github.io/download.html">https://visualvm.github.io/download.html</a> 上自行下载，并进行安装。</p>
<h2 id="2-连接"><a href="#2-连接" class="headerlink" title="2. 连接"></a>2. 连接</h2><p>VisualVM 支持的连接远程节点有 2 种方式：jstatd 和 jmx。其中 jstatd 仅支持 monitor，jmx 才能支持 threads 和 sampler。</p>
<p>推荐使用 JMX 方式，不过，如果检测本地，那么完全不需要配置以及连接，使用 Local 节点即可。</p>
<h2 id="3-界面介绍"><a href="#3-界面介绍" class="headerlink" title="3. 界面介绍"></a>3. 界面介绍</h2><p>VisualVM 一共分为四个页面，如下图所示：</p>
<p><img src="./images/image-20210201225009078.png" alt="image-20210201225009078"></p>
<p>其中 Local 下面显示了本地运行的 Java 应用，例如：</p>
<ul>
<li>VisualVM 软件自身就是一个 Java 应用；</li>
<li>坚果云也是一个 Java 应用；</li>
</ul>
<p>我们以 VisualVM 应用为例，依次介绍这 4 个页面的作用。</p>
<h3 id="3-1-Overview"><a href="#3-1-Overview" class="headerlink" title="3.1 Overview"></a>3.1 Overview</h3><p>对当前应用的概述性信息，如下图所示：</p>
<p><img src="./images/image-20210201231505887.png" alt="image-20210201231505887"></p>
<p>应用有关信息：线程号、主机名称、入口类名称、运行参数</p>
<p>JVM 有关信息：JVM 版本号、$JAVA_HOME 参数、JVM Flags、JVM 参数、系统参数。</p>
<h3 id="3-2-Monitor"><a href="#3-2-Monitor" class="headerlink" title="3.2 Monitor"></a>3.2 Monitor</h3><p>监视器界面如下图所示：</p>
<p><img src="./images/image-20210201231914711.png" alt="image-20210201231914711"></p>
<p>上图展示的信息有：</p>
<ul>
<li>CPU 栏：本机 CPU 使用率，JVM GC 活动频率；</li>
<li>Heap/Metaspace 栏：这是受到 JVM 管理的内存空间信息，橙色代表总大小，蓝色代表实际使用的大小。肉眼可读的大小至少为 MB，我们可见粗略地去除后六位得到内存大小，例如上图中的 VisualVM 软件的最大内存大小为 104MB；</li>
<li>Classes 栏：类的加载情况（统计单位为个数）；</li>
<li>Threads 栏：线程的统计分为 Live 以及 Daemon，如果只有 Daemon 线程，那么意味着 JVM 会退出；</li>
</ul>
<h3 id="3-3-Threads"><a href="#3-3-Threads" class="headerlink" title="3.3 Threads"></a>3.3 Threads</h3><p>Threads 界面如下图所示：</p>
<p><img src="./images/image-20210201233618518.png" alt="image-20210201233618518"></p>
<p>线程的排序方式是以名称的字母顺序，线程状态包括：</p>
<ul>
<li>Running：线程处于正常运行状态；</li>
<li>Sleeping：线程休眠，通过调用 Thread#sleep 方法会进入此状态；</li>
<li>Wait：线程等待一个条件的发生，例如通过在 synchronized 语句块中调用 Object#wait 方法可以进入此状态；</li>
<li>Park：线程进入等待状态，例如通过调用 Unsafe#park 方法就会进入此状态。事实上，由于 JUC 包中的锁都是基于 Unsafe#park 方法实现，因此只要人为构造一个基于 ReentrantLock 的死锁状况，就能够使线程进入 Park 状态。</li>
<li>Monitor 状态：线程没有抢占到锁资源时会进入阻塞等待状态，此时线程的状态就是 Monitor 状态。</li>
</ul>
<p><strong>注意</strong>：Running 状态下的线程不一定都处于非阻塞状态，例如使用 Java 的 ServerSocket 会有阻塞问题，但是观察 JavaVisual 工具能够发现线程处于 Running 状态。</p>
<p>具体 Demo 可以参考个人项目：<a target="_blank" rel="noopener" href="https://github.com/Spongecaptain/ThreadStateInJava">ThreadStateInJava</a></p>
<h3 id="3-4-Sampler"><a href="#3-4-Sampler" class="headerlink" title="3.4 Sampler"></a>3.4 Sampler</h3><p>Sampler 界面用于采样，如下图所示：</p>
<p><img src="./images/image-20210202001155224.png" alt="image-20210202001155224"></p>
<p>可以对 CPU 以及 Memory 进行采样，CPU 专注于对线程的执行时间的采样，Memory 专注于对内存中各种数据类型大小的采样。</p>
<h3 id="3-5-其他插件"><a href="#3-5-其他插件" class="headerlink" title="3.5 其他插件"></a>3.5 其他插件</h3><p>除了 CPU、线程、堆、类等信息，还可以通过 Toos 安装插件，例如可以通过安装 VisualVM-BufferMonitor 插件来监控堆外内存（包含 DirectByteBuffer 和 MappedByteBuffer）。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/6.%20FileChannel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/6.%20FileChannel/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="FileChannel-学习"><a href="#FileChannel-学习" class="headerlink" title="FileChannel 学习"></a>FileChannel 学习</h1><h2 id="1-FileChannel-的用途"><a href="#1-FileChannel-的用途" class="headerlink" title="1. FileChannel 的用途"></a>1. FileChannel 的用途</h2><p>JDK 提供三种文件 I/O 方式，如下：</p>
<ol>
<li><strong>普通 I/O</strong>：存在于 java.io 包中的 FileWriter 与 FileReader 类；</li>
<li><strong>FileChannel（文件通道）</strong>：存在于 java.nio 包中的 FileChannel 类；</li>
<li><strong>MMAP（内存映射）</strong>：此方法较为特殊，由 FileChannel#map 方法衍生出的一种特殊的读写文件方式；</li>
</ol>
<h2 id="2-FileChannel-优势"><a href="#2-FileChannel-优势" class="headerlink" title="2. FileChannel 优势"></a>2. FileChannel 优势</h2><p>FileChannel 被 JavaDocs 称呼为：A channel for reading, writing, mapping, and manipulating a file，即 FileChannel 是用于读、写、映射、维护一个文件的通道。</p>
<blockquote>
<p>本节有参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.baeldung.com/java-filechannel">Guide to Java FileChannel</a></li>
</ul>
</blockquote>
<p>FileChannel 的优势如下：</p>
<ul>
<li>可以在文件的特定位置进行读写操作；</li>
<li>可以直接将文件的一部分加载到内存中；</li>
<li>可以以更快的速度从一个通道传输文件数据到另一个通道；</li>
<li>可以锁定文件的一部分，以限制其他线程访问；</li>
<li>为了避免数据丢失，我们可以强制将对文件的写入更新立即写入存储；</li>
</ul>
<p>总结起来有：</p>
<table>
<thead>
<tr>
<th>FileInputStream/FileOutputStream</th>
<th align="center">FileChannel</th>
</tr>
</thead>
<tbody><tr>
<td>单向</td>
<td align="center">双向</td>
</tr>
<tr>
<td>面向字节的读写</td>
<td align="center">面向 Buffer 读写</td>
</tr>
<tr>
<td>不支持</td>
<td align="center">支持内存文件映射</td>
</tr>
<tr>
<td>不支持</td>
<td align="center">支持转入或转出其他通道</td>
</tr>
<tr>
<td>不支持</td>
<td align="center">支持文件锁</td>
</tr>
<tr>
<td>不支持操作文件元信息</td>
<td align="center">不支持操作文件元信息</td>
</tr>
</tbody></table>
<p><strong>注意</strong>：虽然 FileChannel 类位于 java.nio 包下，FileChannel 只能运行在阻塞（blocking）模式下，而无法运行在非阻塞非模式（non-blocking）下。</p>
<h2 id="3-FileChannel-的-API"><a href="#3-FileChannel-的-API" class="headerlink" title="3. FileChannel 的 API"></a>3. FileChannel 的 API</h2><blockquote>
<p>本节参考于：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/lxyit/p/9170741.html">https://www.cnblogs.com/lxyit/p/9170741.html</a></p>
</blockquote>
<p>FileChannel 类提供的重要 API 如下表所示：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td>open</td>
<td align="center">创建 FileChannel</td>
</tr>
<tr>
<td>read/write</td>
<td align="center">基于 FileChannel 读写</td>
</tr>
<tr>
<td>force</td>
<td align="center">强制将 FileChannel 中的数据刷入文件中</td>
</tr>
<tr>
<td>map</td>
<td align="center">内存文件映射</td>
</tr>
<tr>
<td>transferTo 和 transferFrom</td>
<td align="center">转入与转出通道</td>
</tr>
<tr>
<td>lock/tryLock</td>
<td align="center">获取文件锁</td>
</tr>
</tbody></table>
<h3 id="3-1-得到一个-FileChannel-实例"><a href="#3-1-得到一个-FileChannel-实例" class="headerlink" title="3.1 得到一个 FileChannel 实例"></a>3.1 得到一个 FileChannel 实例</h3><p>创建 FileChannel 实例的方式一共有三个：</p>
<ol>
<li>FileChanel#open 方法；</li>
<li>RandomAccessFile#getChannel 方法；</li>
<li>RandomAccessFile#getChannel 方法；</li>
</ol>
<p>还可以设置文件的操作模式（OpenOption 操作符控制）：</p>
<ul>
<li><strong>READ</strong>：只读方式；</li>
<li><strong>WRITE</strong>：只写方式；</li>
<li><strong>APPEND</strong>：只追加方式；</li>
<li><strong>CREATE</strong>：创建新文件；</li>
<li><strong>CREATE_NEW</strong>：创建新文件，如果存在则失败；</li>
<li><strong>TRUNCATE_EXISTING</strong>：如果以读方式访问文件，它的长度将被清除至 0；</li>
</ul>
<p>示例1：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//只读模式</span></span><br><span class="line">Path path = FileSystems.getDefault().getPath(<span class="string">&quot;/Users/wjjiang/Desktop/temp.md&quot;</span>);</span><br><span class="line">        FileChannel channel2 = FileChannel.open(path, StandardOpenOption.READ);</span><br></pre></td></tr></table></figure>

<p>示例 2：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//通过 FileInputStream/FileOutputStream 得到</span></span><br><span class="line">FileInputStream inputStream = <span class="keyword">new</span> FileInputStream(<span class="string">&quot;D:/test.txt&quot;</span>);</span><br><span class="line">FileChannel channel = inputStream.getChannel();</span><br><span class="line"></span><br><span class="line">FileOutputStream outputStream = <span class="keyword">new</span> FileOutputStream(<span class="string">&quot;D:/test.txt&quot;</span>);</span><br><span class="line">FileChannel channel1 = outputStream.getChannel();</span><br></pre></td></tr></table></figure>

<p>示例 3：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//通过 RandomAccessFile 得到，&quot;rw&quot; 代表可读可写</span></span><br><span class="line">RandomAccessFile randomAccessFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">&quot;./test.txt&quot;</span>, <span class="string">&quot;rw&quot;</span>);</span><br><span class="line">FileChannel channel2 = randomAccessFile.getChannel();</span><br></pre></td></tr></table></figure>

<h3 id="3-2-读写"><a href="#3-2-读写" class="headerlink" title="3.2 读写"></a>3.2 读写</h3><p>通过调用 FileChannel#read/FileChannel#write 方法在文件上进行读写操作，示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer byteBuffer = ByteBuffer.allocate(<span class="number">16</span>);</span><br><span class="line"><span class="keyword">int</span> count = channel2.read(byteBuffer);</span><br><span class="line"></span><br><span class="line">ByteBuffer byteBuffer = ByteBuffer.allocate(<span class="number">16</span>);</span><br><span class="line"><span class="keyword">byte</span>[] bs = <span class="string">&quot;s&quot;</span>.getBytes();</span><br><span class="line">byteBuffer.put(bs);</span><br><span class="line">byteBuffer.flip();</span><br><span class="line">channel2.write(byteBuffer);</span><br></pre></td></tr></table></figure>

<p>可见见得，FileChannel 与其他 java.nio 包下的类有一个最大的共同点，就是基于 ByteBuffer 类进行（而不是 byte[] 数组）。</p>
<blockquote>
<p>在传统 I/O 中，流是基于字节的方式进行读写的。</p>
<p>在 NIO 中，使用通道（Channel）基于缓冲区数据块的读写。</p>
</blockquote>
<p><strong>注意</strong>：FileChannel 的 write 以及 read 是线程安全的，其内部有用到 synchronized 同步锁机制。</p>
<h3 id="3-3-刷盘"><a href="#3-3-刷盘" class="headerlink" title="3.3 刷盘"></a>3.3 刷盘</h3><p>FileChannel#force 方法用于这个 Channel 更新的内容写入文件中，</p>
<p>FileChannel #force 方法，接收一个布尔参数 metaData，表示是否需要确保文件元数据落盘，如果为 true，则调用 fsync。如果为 false，则调用 fdatasync。但无论如何，此方法都会确保有非元数据的文件内容落盘。</p>
<h3 id="3-4-内存映射"><a href="#3-4-内存映射" class="headerlink" title="3.4 内存映射"></a>3.4 内存映射</h3><p>FileChannel#map 方法将外存文件某段映射至内存，返回 MappedByteBuffer，具有以下几种映射模式：</p>
<ul>
<li><strong>READ_ONLY</strong>：以只读的方式映射，如果发生修改，则抛出 ReadOnlyBufferException；</li>
<li><strong>READ_WRITE</strong>：读写方式；</li>
<li><strong>PRIVATE</strong>：对这个 MappedByteBuffer 的修改不写入文件，且其他程序是不可见的；</li>
</ul>
<p><strong>注意</strong>：一旦经过 map 映射后，MappedByteBuffer 将与用于映射的 FileChannel 没有联系，即使 Channel 关闭，也对 MappedByteBuffer 没有影响。</p>
<p>map 通产应用在超大文件的处理中时使用，整体的性能才得以提升。对于数十 Kb 的文件处理，使用 map 的性能不一定比传统基于流式的读写好，因为直接映射进入内存的代价开销较大。需要在这两者之间进行权衡选择。</p>
<p>示例代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Path path = FileSystems.getDefault().getPath(<span class="string">&quot;./test.txt&quot;</span>);</span><br><span class="line">FileChannel channel = FileChannel.open(path, StandardOpenOption.READ, StandardOpenOption.WRITE);</span><br><span class="line">MappedByteBuffer mappedByteBuffer = channel.map(MapMode.READ_ONLY, <span class="number">0</span>, <span class="number">100000</span>);</span><br><span class="line"><span class="keyword">byte</span>[] bs = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">100</span>];</span><br><span class="line">mappedByteBuffer.get(bs);</span><br></pre></td></tr></table></figure>

<h3 id="3-5-FileChannel-间数据传输"><a href="#3-5-FileChannel-间数据传输" class="headerlink" title="3.5 FileChannel 间数据传输"></a>3.5 FileChannel 间数据传输</h3><p>FileChannel#transferTo 以及 FileChannel#transferFrom 用于文件通道的内容转出到另一个通道或者将另一个通道的内容转入当前通道。</p>
<p>案例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">srcChannel.transferTo(<span class="number">0</span>, Integer.MAX_VALUE, dstChannel);</span><br><span class="line">srcChannel.transferFrom(fromChannel, <span class="number">0</span>, Integer.MAX_VALUE);</span><br></pre></td></tr></table></figure>

<p>该两个方法可以实现通道字节数据的快速转移，不仅在简化代码量（少了中间内存的数据拷贝转移）而且还大幅到提高了性能。</p>
<h3 id="3-6-文件锁"><a href="#3-6-文件锁" class="headerlink" title="3.6 文件锁"></a>3.6 文件锁</h3><p>文件锁是作用在文件区域上的锁，即文件区域是同步资源，多个程序访问时，需要先获取该区域的锁，才能进入访问文件，访问结束释放锁，实现程序串行化访问文件。这里可以类比 Java 中的对象锁或者 lock 锁理解。</p>
<p>示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileChannel channel = rf.getChannel();</span><br><span class="line">FileLock lock = channel.lock(<span class="number">0L</span>, <span class="number">23L</span>, <span class="keyword">false</span>);</span><br></pre></td></tr></table></figure>

<p>其中，false 意味着独占模式，true 则对应共享模式。</p>
<p>FileLock 的几个重要重点事项如下：</p>
<ol>
<li>文件锁 FileLock 是被整个 Java Vitrual Machine 持有的，即 FileLock 是进程级别的，所以不可用于作为多线程安全控制的同步工具。</li>
<li>虽然上面提到 FileLock 不可用于多线程访问安全控制，但是多线程访问是安全的。如果线程 1 获取了文件锁 FileLock（共享或者独占），线程 2 再来请求获取该文件的文件锁，则会抛出 <code>OverlappingFileLockException</code></li>
<li>一个程序获取到 FileLock 后，是否会阻止另一个程序访问相同文件具重叠内容的部分取决于操作系统的实现，具有不确定性。FileLock 的实现依赖于底层操作系统实现的本地文件锁设施。</li>
<li>以上所说的文件锁的作用域是文件的区域，可以时整个文件内容或者只是文件内容的一部分。独占和共享也是针对文件区域而言。程序（或者线程）获取文件 0 至 23 范围的锁，另一个程序（或者线程）仍然能获取文件 23 至以后的范围。只要作用的区域无重叠，都相互无影响。</li>
</ol>
<h2 id="4-FileChannel-的读写效率"><a href="#4-FileChannel-的读写效率" class="headerlink" title="4. FileChannel 的读写效率"></a>4. FileChannel 的读写效率</h2><blockquote>
<p>本节参考于：<a target="_blank" rel="noopener" href="https://www.cnkirito.moe/file-io-best-practise/">https://www.cnkirito.moe/file-io-best-practise/</a></p>
</blockquote>
<p>FileChannel 为什么比普通 I/O 要快呢？这么说可能不严谨，因为你要用对它，<strong>FileChannel 只有在一次写入 4kb 的整数倍时，才能发挥出实际的性能</strong>，这得益于 FileChannel 采用了 ByteBuffer 这样的内存缓冲区，让我们可以非常精准的控制写盘的大小，这是普通 I/O 无法实现的。4kb 一定快吗？也不严谨，这主要取决你机器的磁盘结构，并且受到操作系统，文件系统，CPU 的影响，例如中间件性能挑战赛时的那块盘，一次至少写入 64kb 才能发挥出最高的 IOPS。</p>
<p><img src="./images/image-20180714180739936-20210131212047482.png" alt="中间件性能挑战复赛的盘"></p>
<blockquote>
<p>中间件性能挑战复赛的盘</p>
</blockquote>
<p>另外，正如 FileChannel API 中分别介绍了 FileChannel#write 以及 FileChannel#force 方法，因此ByteBuffer 中的数据和磁盘中的数据还隔了一层，这一层便是 PageCache，是用户内存和磁盘之间的一层缓存。我们都知道磁盘 IO 和内存 IO 的速度可是相差了好几个数量级。我们可以认为 filechannel.write 写入 PageCache 便是完成了落盘操作，但实际上，操作系统最终帮我们完成了 PageCache 到磁盘的最终写入。</p>
<p>同理，当我们使用 FileChannel 进行读操作时，同样经历了：磁盘 -&gt;PageCache-&gt; 用户内存这三个阶段，对于日常使用者而言，你可以忽略掉 PageCache，但作为挑战者参赛，PageCache 在调优过程中是万万不能忽视的，关于读操作这里不做过多的介绍，我们再下面的小结中还会再次提及，这里当做是引出 PageCache 的概念。</p>
<h2 id="5-MMAP-的读写效率"><a href="#5-MMAP-的读写效率" class="headerlink" title="5. MMAP 的读写效率"></a>5. MMAP 的读写效率</h2><p>利用 FileChannel 进行 MMAP 读写示例如下图所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写</span></span><br><span class="line"><span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>];</span><br><span class="line"><span class="keyword">int</span> position = <span class="number">8</span>;</span><br><span class="line"><span class="comment">// 从当前 mmap 指针的位置写入 4b 的数据</span></span><br><span class="line">mappedByteBuffer.put(data);</span><br><span class="line"><span class="comment">// 指定 position 写入 4b 的数据</span></span><br><span class="line">MappedByteBuffer subBuffer = mappedByteBuffer.slice();</span><br><span class="line">subBuffer.position(position);</span><br><span class="line">subBuffer.put(data);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读</span></span><br><span class="line"><span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>];</span><br><span class="line"><span class="keyword">int</span> position = <span class="number">8</span>;</span><br><span class="line"><span class="comment">// 从当前 mmap 指针的位置读取 4b 的数据</span></span><br><span class="line">mappedByteBuffer.get(data);</span><br><span class="line"><span class="comment">// 指定 position 读取 4b 的数据</span></span><br><span class="line">MappedByteBuffer subBuffer = mappedByteBuffer.slice();</span><br><span class="line">subBuffer.position(position);</span><br><span class="line">subBuffer.get(data);</span><br></pre></td></tr></table></figure>

<p>我们通过执行如下语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 1L * 1024 * 1024 * 1024);</span><br></pre></td></tr></table></figure>

<p>观察一下磁盘上的变化，会立刻获得一个 1.5G 的文件，但此时文件的内容全部是 0（字节 0）。这符合 MMAP 的中文描述：内存映射文件，我们之后对内存中 MappedByteBuffer 做的任何操作，都会被最终映射到文件之中。如下图所示：</p>
<img src="./images/image-20210131214016788.png" alt="image-20210131214016788" style="zoom:50%;" />

<p>网上很多文章都在说，MMAP 操作大文件性能比 FileChannel 高出一个数量级！然而，通过我比赛的认识，MMAP 并非是文件 IO 的银弹，它只有在<strong>一次写入很小量数据的场景</strong>下才能表现出比 FileChannel 稍微优异的性能。紧接着我还要告诉你一些令你沮丧的事，至少在 JAVA 中使用 MappedByteBuffer 是一件非常麻烦并且痛苦的事，主要表现为三点：</p>
<ol>
<li>MMAP 使用时必须实现指定好内存映射的大小，并且一次 map 的大小限制在 1.5G 左右，重复 map 又会带来虚拟内存的回收、重新分配的问题，对于文件不确定大小的情形实在是太不友好了。</li>
<li>MMAP 使用的是虚拟内存，和 PageCache 一样是由操作系统来控制刷盘的，虽然可以通过 force() 来手动控制，但这个时间把握不好，在小内存场景下会很令人头疼。</li>
<li>MMAP 的回收问题，当 MappedByteBuffer 不再需要时，可以手动释放占用的虚拟内存，但…方式非常的诡异。</li>
</ol>
<p>下面这么长的代码仅仅是为了干回收 MappedByteBuffer 这一件事。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">clean</span><span class="params">(MappedByteBuffer mappedByteBuffer)</span> </span>&#123;</span><br><span class="line">    ByteBuffer buffer = mappedByteBuffer;</span><br><span class="line">    <span class="keyword">if</span> (buffer == <span class="keyword">null</span> || !buffer.isDirect() || buffer.capacity()== <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    invoke(invoke(viewed(buffer), <span class="string">&quot;cleaner&quot;</span>), <span class="string">&quot;clean&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Object <span class="title">invoke</span><span class="params">(<span class="keyword">final</span> Object target, <span class="keyword">final</span> String methodName, <span class="keyword">final</span> Class&lt;?&gt;... args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> AccessController.doPrivileged(<span class="keyword">new</span> PrivilegedAction&lt;Object&gt;() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Object <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Method method = method(target, methodName, args);</span><br><span class="line">                method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">                <span class="keyword">return</span> method.invoke(target);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Method <span class="title">method</span><span class="params">(Object target, String methodName, Class&lt;?&gt;[] args)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> NoSuchMethodException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> target.getClass().getMethod(methodName, args);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchMethodException e) &#123;</span><br><span class="line">        <span class="keyword">return</span> target.getClass().getDeclaredMethod(methodName, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> ByteBuffer <span class="title">viewed</span><span class="params">(ByteBuffer buffer)</span> </span>&#123;</span><br><span class="line">    String methodName = <span class="string">&quot;viewedBuffer&quot;</span>;</span><br><span class="line">    Method[] methods = buffer.getClass().getMethods();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; methods.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (methods[i].getName().equals(<span class="string">&quot;attachment&quot;</span>)) &#123;</span><br><span class="line">            methodName = <span class="string">&quot;attachment&quot;</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ByteBuffer viewedBuffer = (ByteBuffer) invoke(buffer, methodName);</span><br><span class="line">    <span class="keyword">if</span> (viewedBuffer == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> buffer;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> viewed(viewedBuffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>所以建议优先使用 FileChannel 去完成初始代码的提交，在必须使用小数据量 (例如几个字节) 刷盘的场景下，再换成 MMAP 的实现，其他场景 FileChannel 完全可以 cover(前提是你理解怎么合理使用 FileChannel)。至于 MMAP 为什么在一次写入少量数据的场景下表现的比 FileChannel 优异，我还没有查到理论根据，如果你有相关的线索，欢迎留言。理论分析下，FileChannel 同样是写入内存，但是在写入小数据量时，MMAP 表现的更加优秀，所以在索引数据落盘时，大多数情况应该选择使用 MMAP。至于 MMAP 分配的虚拟内存是否就是真正的 PageCache 这一点，我觉得可以近似理解成 PageCache。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/5.%20Java%20ByteBuffer%E4%B8%8E%20Channel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/5.%20Java%20ByteBuffer%E4%B8%8E%20Channel/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Java-ByteBuffer与-Chanel"><a href="#Java-ByteBuffer与-Chanel" class="headerlink" title="Java ByteBuffer与 Chanel"></a>Java ByteBuffer与 Chanel</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>Java NIO（Socket）由以下几个核心部分组成：</p>
<ol>
<li>Buffer</li>
<li>Channel</li>
<li>Selector</li>
</ol>
<p>Selector 重在实现 Socket 的事件驱动模型，是实现 NIO 的关键。而 Buffer 以及 Channel 则提供了一种面向缓冲区的尽力读写功能。</p>
<ul>
<li>传统的 I/O 操作面向数据流，意味着每次从流中读一个或多个字节，直至完成，数据没有被缓存在任何地方。</li>
<li>NIO 操作面向缓冲区，数据从 Channel 读取到 Buffer 缓冲区，随后在 Buffer 中处理数据。</li>
</ul>
<p>本节会结合 Netty 框架进行说明，因为其是一个出色的高性能 Java NIO 通信框架。</p>
<h2 id="1-Buffer"><a href="#1-Buffer" class="headerlink" title="1. Buffer"></a>1. Buffer</h2><h3 id="1-1-Buffer-概述"><a href="#1-1-Buffer-概述" class="headerlink" title="1.1 Buffer 概述"></a>1.1 Buffer 概述</h3><blockquote>
<p>A buffer is a linear, finite sequence of elements of a specific primitive type.</p>
</blockquote>
<p>一块缓存区，内部使用字节数组存储数据，并维护几个特殊变量，实现数据的反复利用。</p>
<blockquote>
<p>下面虽然会介绍 Buffer 内部字段，但不用过于纠结 Buffer 内部的字段的含义，重要的是了解 Buffer 的特性：</p>
<ul>
<li>同一个 Buffer 既可读又可写；</li>
<li>Buffer 的读模式、写模式之间的相互转换需要调用具体方法，读模式式下写会报错，写模式写读也会报错。</li>
<li>当我们需要与 NIO Channel 进行交互时，我们就需要使用到 NIO Buffer，即数据从 Buffer 读取到 Channel 中，或者从 Channel 中写入到 Buffer 中。</li>
<li>实际上，一个 Buffer 其实就是一块内存区域，我们可以在这个内存区域中进行数据的读写。NIO Buffer 其实是这样的内存块的一个封装，并提供了一些操作方法让我们能够方便地进行数据的读写。</li>
</ul>
</blockquote>
<ol>
<li><strong>mark</strong>：初始值为 - 1，用于备份当前的 position;</li>
<li><strong>position</strong>：初始值为 0，position 表示当前可以写入或读取数据的位置，当写入或读取一个数据后，position 向前移动到下一个位置；因为仅仅支持顺序读写，所以当 Buffer 的读写模式切换时，position 会切换到可读的初始索引处以及可写的初始索引处。</li>
<li><strong>limit</strong>：写模式下，limit 表示最多能往 Buffer 里写多少数据，等于 capacity 值；读模式下，limit 表示最多可以读取多少数据。</li>
<li><strong>capacity</strong>：缓存数组大小。</li>
</ol>
<p><img src="./images/image-20200516175258273.png" alt="image-20200516175258273"></p>
<p>**mark()**：把当前的 position 赋值给 mark</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">mark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mark = position;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>**reset()**：把 mark 值还原给 position</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">reset</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> m = mark;</span><br><span class="line">    <span class="keyword">if</span> (m &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InvalidMarkException();</span><br><span class="line">    position = m;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>**clear()**：一旦读完 Buffer 中的数据，需要让 Buffer 准备好再次被写入，clear 会恢复状态值，但不会擦除数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    limit = capacity;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>**flip()**：Buffer 有两种模式，写模式和读模式，flip 后 Buffer 从写模式变成读模式，或者相反。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    limit = position;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>**rewind()**：重置 position 为 0，从头读写数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">rewind</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>目前 Buffer 的实现类包括：ByteBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer、LongBuffer、ShortBuffer、MappedByteBuffer，继承关系如下图所示：</p>
<p><img src="./images/image-20200516175651521.png" alt="image-20200516175651521"></p>
<h3 id="1-2-ByteBuffer-以及-HeapByteBuffer、DirectByteBuffer"><a href="#1-2-ByteBuffer-以及-HeapByteBuffer、DirectByteBuffer" class="headerlink" title="1.2 ByteBuffer 以及 HeapByteBuffer、DirectByteBuffer"></a>1.2 ByteBuffer 以及 HeapByteBuffer、DirectByteBuffer</h3><blockquote>
<p>它们本质上都是字节数组，只是一个在堆内，一个堆外（直接内存）。</p>
</blockquote>
<p>ByteBuffer 的实现类包括 “HeapByteBuffer” 和 “DirectByteBuffer” 两种。</p>
<p>我们可以调用 ByteBuffer 类的两个静态方法得到上述两个子类实现：</p>
<ul>
<li><p><strong>HeapByteBuffer#allocate</strong></p>
<p>这个实例的构造实际上最终调用的是 Buffer 类的构造器，也就是说内存空间直接上分配在由 JVM 管理的堆空间中，其内部实际上为一个 byte 数组。</p>
</li>
<li><p><strong>DirectByteBuffer#allocateDirect</strong></p>
<p>这个实例通过 unsafe#allocateMemory 方法申请堆外内存，并在 ByteBuffer 的 address 变量中维护指向该内存的地址。</p>
</li>
</ul>
<p>可见，这两种 Buffer 的最大区别于数据在内存何处，是位于 JVM 堆内还是堆外，Java 的 NIO 模式同时支持这两种 Buffer。</p>
<blockquote>
<p>注意：Java 中的 Direct 并不是指操作系统的 Direct I/O，不过他们的作用是类似的。</p>
</blockquote>
<h3 id="1-3-为什么通常和-NIO-搭配的是-DirectByteBuffer"><a href="#1-3-为什么通常和-NIO-搭配的是-DirectByteBuffer" class="headerlink" title="1.3 为什么通常和 NIO 搭配的是 DirectByteBuffer"></a>1.3 为什么通常和 NIO 搭配的是 DirectByteBuffer</h3><blockquote>
<p>参考网址：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/60892134">知乎：Java NIO direct buffer 的优势在哪儿？</a></p>
<p>其它一些平台可能是在错误地把一些概念整混了。</p>
<p>这个问题也是个伪命题，因为 NIO 和 HeapByteBuffer 以及 DirectByteBuffer 可以随意搭配，没有任何关系。NIO 对比于 BIO 的性能提升并不在于可以使用 DirectByteBuffer（这仅仅是一个影响非常小的优势）。更大的优势在于凭借单线程就能够处理在 BIO 中多线程才能够处理好的众多网络连接。</p>
</blockquote>
<ul>
<li><p>HeapByteBuffer：</p>
<p>Socket&lt;—-&gt; <strong>内核空间的缓存区 &lt;—-&gt; 堆外 &lt;—-&gt;堆内</strong>。</p>
</li>
<li><p>DirectByteBuffer：</p>
<p>Socket &lt;—-&gt; <strong>内核空间的缓存区 &lt;—-&gt; 堆外</strong>。</p>
</li>
</ul>
<blockquote>
<p>堆内的数据结构一般称为 Java Heap，而堆外的一般称为 C Heap，它们都处于用户空间。</p>
<p>Socket/文件到内核空间的缓冲区的数据拷贝现在一般由 DMA 机制负责完成，CPU 并不需要参与这个过程。CPU 可能参与的过程是内核空间到堆外（这里的堆外对于非 JVM 应用而言，就是普通用户空间），堆外到堆内。</p>
</blockquote>
<p>结论：DirectByteBuffer 相对于 HeapByteBuffer 的优势仅仅在于少了一次堆内与堆外的数据拷贝过程。</p>
<p><strong>为什么 HeapByteBuffer 也需要使用堆外的内存空间？</strong></p>
<p>因为 JVM 对内存中的实例实行 GC 管理，GC 可能会导致实例地址的变动，<strong>堆外内存的好处就在于其地址不受 GC 影响</strong>。地址被要求不能够改变的原因是：当我们把一个地址通过 JNI 传递给底层的 C 库的时候，有一个基本的要求，就是这个地址上的内容不能失效。所以无论我们是否使用 DirectByteBuffer，都需要使用一个堆外内存来保存和内核空间交互的数据。</p>
<blockquote>
<p>如果要把一个 Java 里的 byte[] 对象的引用传给 native 代码，让 native 代码直接访问数组的内容的话，就必须要保证 native 代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。</p>
<p>可惜 HotSpot VM 出于一些取舍而决定不实现单个对象层面的 object pinning，要 pin 的话就得暂时禁用 GC——也就等于把整个 Java 堆都给 pin 住。</p>
<p>所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的 I/O 可能是一个很慢的操作。</p>
</blockquote>
<p>因此，DirectByteBuffer 相对于 HeapByteBuffer 的优势是很有限的：</p>
<ul>
<li>两种方式都有内核空间与用户空间之间的数据拷贝，只是 HeapByteBuffer 额外多一次堆内、堆外数据的拷贝；</li>
<li>DirectByteBuffer 本身也是一个内存隐患，使用 DirectByteBuffer 并不能像 HeapByteBuffer 或 byte[] 一样任意使用可以被 GC 及时的回收。所以使用 DirectByteBuffer 最好是分配好缓存起来重复使用，否则很容易出现 OOM 错误（内存事实上管理非常复杂）。</li>
</ul>
<p><strong>描述 DirectByteBuffer 的精辟总结</strong>：DirectByteBuffer 只是给了用户(Java 程序员)一个操作堆外内存的机会，并不代表 JVM 没有堆外内存的管理（对于 JVM 来说堆外内一直是搓手可得的，因为本来就都在用户空间内，堆外内存并不是随着 JDK 推出 DirectByteBuffer 才可以进行管理的）。</p>
<h3 id="1-4-使用-Buffer-的典型案例"><a href="#1-4-使用-Buffer-的典型案例" class="headerlink" title="1.4 使用 Buffer 的典型案例"></a>1.4 使用 Buffer 的典型案例</h3><p>这里举一个使用 Buffer 的典型案例。</p>
<p>Buffer 由 <code>ByteBuffer.allocate(100);</code> 定义，所以是一个 Java 堆内的 HeapByteBuffer，当然也可以通过 <code>DirectBuffer.allocateDirect()</code> 来构造一个 DirectByteBuffer。</p>
<p>一个完成的 NIO 流程是这样的：</p>
<ul>
<li>将 SocketChannel(与本地的一个 Socket 绑定的) 注册到 Selector 中，注册时的兴趣为可读事件。</li>
<li>当 <code>Selector.slect()</code> 方法返回时，预示着事件发生了，并且此方法停滞阻塞。</li>
<li>然后服务器线程去遍历 Socket 队列（epoll/select 遍历的范围有所区别），寻找可读的 Socket；</li>
<li>找到之后，服务器利用已经创建好的 （Buffer 一般要求是复用的，不要每个事件就创建一个）Buffer 进行非阻塞读取；</li>
<li>然后遍历 Socket 队列的下一个 Socket。</li>
<li>Socket 队列遍历完毕，继续调用 <code>Selector.slect()</code> 方法。</li>
</ul>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleNioServer</span> </span>&#123;</span><br><span class="line">    <span class="comment">//这个 map 用于存储分批尽力读取的字节数据</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">static</span> HashMap&lt;SelectionKey, Object&gt; hashMap = <span class="keyword">new</span> HashMap();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Selector selector = <span class="keyword">null</span>;</span><br><span class="line">        ServerSocketChannel serverSocket = <span class="keyword">null</span>;</span><br><span class="line">        ByteBuffer buffer = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1. 创建 Selector 实例</span></span><br><span class="line">            selector = Selector.open();</span><br><span class="line">            <span class="comment">//2. 创建 ServerSocketChannel 实例</span></span><br><span class="line">            serverSocket = ServerSocketChannel.open();</span><br><span class="line">            <span class="comment">//3. 初始化 ServerSocketChannel 内部的 serverSocket 实例确定绑定的本地端口</span></span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;localhost&quot;</span>, <span class="number">2333</span>));</span><br><span class="line">            <span class="comment">//4. 将 ServerSocketChannel 配置成非阻塞模式，这是必要的，</span></span><br><span class="line">            <span class="comment">// 因为 ServerSocketChannel 和由其生产出来的 SocketChannel 实例都在 while 循环中被检查是否触发了事件，</span></span><br><span class="line">            <span class="comment">// 否则，没有新的请求导致 SocketChannel.accept() 阻塞，会影响 selector 去判别 SocketChannel 是否可读。</span></span><br><span class="line">            serverSocket.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//5. 将 ServerSocketChannel 注册到 Selector 中，事件是 OP_ACCEPT，一旦有 TCP 连接请求就会触发</span></span><br><span class="line">            serverSocket.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">            <span class="comment">// 测试性地尝试注册两次</span></span><br><span class="line">            serverSocket.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">            <span class="comment">//6. 创建 Buffer 用于从 SocketChannel 中读取字节数据</span></span><br><span class="line">            buffer = ByteBuffer.allocate(<span class="number">100</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 7. 如果迭代器内部有事件发生，那么不阻塞，否则阻塞</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.select();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 8. 阻塞结束，说明 selector 中有事件触发，所以获得其迭代器进行处理</span></span><br><span class="line">            Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; iter = selectedKeys.iterator();</span><br><span class="line">            <span class="comment">//9. 迭代器中全体元素的循环</span></span><br><span class="line">            <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line"></span><br><span class="line">                SelectionKey key = iter.next();</span><br><span class="line">                <span class="comment">//10. 因为仅仅对 ServerSocketChannel 单例进行了 OP_ACCEPT 事件注册，所以断定地知道来了一个建立 TCP 连接请求。</span></span><br><span class="line">                <span class="comment">//调用此 register 方法得到 ServerSocketChannel 中的一个 SocketChannel 并注册到 Selector 中，事件为 OP_READ</span></span><br><span class="line">                <span class="keyword">if</span> (key.isAcceptable()) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="comment">//这里的含义是将 ServerSocketChannel 实例 serverSocket 注册到 selector 内部</span></span><br><span class="line">                        register(selector, serverSocket);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//11. 我们为所有的 SocketChannel 注册了 OP_READ 事件，所以此事件发生时意味着可读了,于是调用 answerWithEcho 方法进行读</span></span><br><span class="line">                <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        read(buffer, key);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//12. 将此 SelectableChannel 移出迭代器是必要的，否则会进行没有必要的事件是否准备好的询问</span></span><br><span class="line">                iter.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">(ByteBuffer buffer, SelectionKey key)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;read 方法被调用了&quot;</span>);</span><br><span class="line">        <span class="comment">//1. 得到 SelectionKey 实例内部的 SocketChannel 实例，因为可读状态下需要利用 Channel 进行读取字节数据</span></span><br><span class="line">        SocketChannel socketChannel = (SocketChannel) key.channel();</span><br><span class="line">        <span class="comment">//2. 构造一组键值对，key 为 SelectionKey 实例，value 为 List，用于存储多次尽力读取的字节数组</span></span><br><span class="line">        <span class="keyword">if</span> (!hashMap.containsKey(key))</span><br><span class="line">            hashMap.put(key, <span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line">        <span class="comment">//3. 此标志用于判断：</span></span><br><span class="line">        <span class="comment">//0： UNIX 底层的缓冲字节数组被读完了或者 ByteBuffer 没有写一个字节，这里指的是前者，因为每次读取后都 clear 了；</span></span><br><span class="line">        <span class="comment">//-1: 意味这 EOF，即 HTTP 请求数据已经全部传输到服务端 Socket 了。</span></span><br><span class="line">        <span class="comment">//其他大于 0 的数字：意味着这里从底层 UNIX 缓冲字节数组读取了几个字节</span></span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (buffer.hasRemaining() &amp;&amp; (count = socketChannel.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//使 Buffer 变成可读</span></span><br><span class="line">            buffer.flip();</span><br><span class="line">            ArrayList list = (ArrayList) hashMap.get(key);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">byte</span>[] arr = <span class="keyword">new</span> <span class="keyword">byte</span>[buffer.remaining()];</span><br><span class="line">            buffer.get(arr);</span><br><span class="line">            buffer.rewind();</span><br><span class="line">            list.add(arr);</span><br><span class="line">            buffer.clear();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//当 socketChannel.read(buffer) 返回 -1 时，意味着此时彼通道数据传输已经完成，因为遇到了流传输中的 EOF 标志</span></span><br><span class="line">        <span class="comment">// 如果没有读到字节流末尾，那么选择不关闭，因为下一次还是要继续读取</span></span><br><span class="line">        <span class="keyword">if</span> (count == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">//这些代码用于验证一次次的 Buffer 工作是否正确地转换为 byte 数组保存起来。</span></span><br><span class="line">            ArrayList list = (ArrayList) hashMap.get(key);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> Iterator iterator = list.iterator();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="keyword">byte</span>[] next = (<span class="keyword">byte</span>[]) iterator.next();</span><br><span class="line">                System.out.println(next.length);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            socketChannel.close();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(Selector selector, ServerSocketChannel serverSocket)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1. 利用 ServerSocketChannel accept 方法能够得到一个此次连接请求对应的 SocketChannel 实例</span></span><br><span class="line">        SocketChannel client = serverSocket.accept();</span><br><span class="line">        <span class="comment">//2. 将此 SocketChannel 实例设置为非阻塞模式</span></span><br><span class="line">        client.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//3. 将此 SocketChannel 注册到 Selector 中，事件为 OP_READ，即可读事件，此方法返回的 SelectionKey 并不需要保存并引用起来</span></span><br><span class="line">        client.register(selector, SelectionKey.OP_READ);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-5-Benchmark-of-DirectBuffer"><a href="#1-5-Benchmark-of-DirectBuffer" class="headerlink" title="1.5 Benchmark of DirectBuffer"></a>1.5 Benchmark of DirectBuffer</h3><p>正如前文所述，DirectByteBuffer 与 HeapDirectBuffer 的性能差距不大，实际上应用层的 Buffer 缓存管理分配机制（内存池化）才是影响性能的最重要原因。当然，上述说法需要在具体应用场景下的 benchmark 来证明。</p>
<p>使用 HeapByteBuffer 的应用可以选择全权把内存管理交给 GC 线程，虽然使用应用层的 Buffer 缓存管理分配机制能得到更好的性能。</p>
<p>但是使用 DirectByteBuffer 的应用必须使用基于应用层的 Buffer 缓存管理分配机制，这是因为 DirectByteBuffer 在 GC 上存在问题：通常申请再多的 DirectByteBuffer 实例也难以触发 full GC，但是只有触发 full GC，GC 线程才会负责去触发 DirectByteBuffer 实例的回收。因此，使用 DirectByteBuffer 的应用通常需要在应用层实现一个 Buffer 缓存管理分配机制。</p>
<p>Netty 为 DirectByteBuffer 与 HeapDirectBuffer 都实现了 Buffer 缓存管理分配机制（内存池化）。</p>
<p>总之，事实上，使用 DirectByteBuffer 虽然可以提升性能，但实际上是出于不提升白不提升的目的，提升性能远远没有想象中那么大，因为其仅仅节约了堆外、堆内的数据复制操作，而这部分工作由 CPU 来完成是非常快的。</p>
<p>下图是 Twitter 对 Netty 的测试结果：</p>
<p><img src="./images/image-20200520114203738.png" alt="image-20200520114203738"></p>
<blockquote>
<p>数值越大代表时间越长，性能越差。</p>
</blockquote>
<ul>
<li>Polled Heap 和 Polled Direct 相比几乎没有太大的区别；</li>
<li>Unpolled Heap 和 unpolled Direct 相比区别略为大了一点，但是不够显著。</li>
</ul>
<p>由图可知，DirectByteBuffer 相较于 HeapByteBuffer 可以提升一定性能，但是远远没有达到 Poll 相比于 Unpoll 的提升。</p>
<h3 id="1-6-堆外内存的回收"><a href="#1-6-堆外内存的回收" class="headerlink" title="1.6 堆外内存的回收"></a>1.6 堆外内存的回收</h3><p>这里先回顾一下 JVM 堆内的内存回收的相关概念（粗略）：</p>
<ul>
<li><strong>新生代</strong>：一般来说新创建的对象都分配在这里。</li>
<li><strong>年老代</strong>：经多次垃圾回收仍存活，新生代的对象就会放在年老代中。年老代中的对象保存的 GC 轮次更多。</li>
<li><strong>永久代</strong>：这里面存放的是 class 相关的信息，一般是不会进行垃圾回收的。</li>
</ul>
<p><strong>JVM 的垃圾回收策略</strong>：</p>
<ul>
<li><strong>Minor GC</strong>: 当新创建对象，内存空间不够的时候，就会执行这个垃圾回收。由于执行最频繁，因此一般采用标记复制机制。</li>
<li><strong>Major GC</strong>: 清理年老代的内存，这里一般采用的是标记整理机制。</li>
<li><strong>Full GC</strong>: 有的说与 Major GC 差不多，有的说相当于执行 minor+major 回收，但在这里我们暂且可以认为 Full GC 就是全面的垃圾回收吧。</li>
</ul>
<p>需要我们回收内存的原因有 3 个：</p>
<ol>
<li>内存空间有限：如果应用程序不断申请内存空间但是不回收，那么内存很快就会分配完毕，最终导致内存异常异常，包括：<ol>
<li>java.lang.OutOfMemoryError: Direct buffer memory</li>
<li>java.lang.OutOfMemoryError: Requested array size exceeds VM limit</li>
</ol>
</li>
<li>内存池化技术性能高：内存池化技术能够实现内存复用，因为反复的内存的申请以及分配代价高昂，池化技术能够提高整体系统性能；</li>
<li>堆外内存需要应用层自己实现一套内存回收机制，GC 对堆外内存的回收能力非常有限；</li>
</ol>
<p><strong>1.DirectByteBuffer 的内存回收</strong></p>
<p>由前面的文章可知，堆外内存分配很简单，直接调用 ByteBuffer#allocateDirect 方法即可。</p>
<p>在 C 语言的内存分配和释放函数 malloc/free，必须要一一对应，否则就会出现内存泄露或者是野指针的非法访问。但是 JVM 拥有 GC 机制，通常并不需要应用层负责实例的内存释放。</p>
<p>DirectByteBuffer 的的内存回收非常受限，因为其所占内存只有发生 full GC 的情况下才会被回收（而且不是 GC 线程负责回收）。而 full GC 的触发是无法通过 Java 代码控制的，例如 System#gc 方法的语义无法确保 JVM 马上执行 GC 线程，它只是建议 JVM 进行垃圾回收。因此，很容易发送堆外内存溢出的问题。</p>
<p>DirectByteBuffer 的另一个缺陷是即使 GC 线程能够确保不发生堆外内存溢出，但是反复的堆外内存回收、分配会导致不尽人意的性能。</p>
<p>因此就像 Netty 一样，需要实现一套应用层 DirectByteBuffer 的池化技术，既负责内存回收，也负责内存缓存与分配。</p>
<blockquote>
<p>补充说明：</p>
<p>Netty 的堆外内存分配是直接基于 Unsafe 进行，而不是基于 DirectByteBuffer#allocate 方法。所以 GC 线程完全不会管理 Netty 框架中堆外内存的分配，后者全权由 Netty 应用层逻辑负责回收。</p>
</blockquote>
<p><strong>2.源码分析</strong></p>
<p>先来看一个 jdk nio 的 DirectByteBuffer 类的 package-private 构造器，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">DirectByteBuffer(<span class="keyword">int</span> cap) &#123;</span><br><span class="line">    <span class="keyword">super</span>(-<span class="number">1</span>, <span class="number">0</span>, cap, cap);</span><br><span class="line">    <span class="comment">//是否页对齐</span></span><br><span class="line">    <span class="keyword">boolean</span> pa = VM.isDirectMemoryPageAligned();</span><br><span class="line">    <span class="comment">//页的大小4K</span></span><br><span class="line">    <span class="keyword">int</span> ps = Bits.pageSize();</span><br><span class="line">    <span class="comment">//最小申请1K，若需要页对齐，那么多申请1页，以应对初始地址的页对齐问题</span></span><br><span class="line">    <span class="keyword">long</span> size = Math.max(<span class="number">1L</span>, (<span class="keyword">long</span>)cap + (pa ? ps : <span class="number">0</span>));</span><br><span class="line">    <span class="comment">//检查堆外内存是否够用, 并对分配的直接内存做一个记录</span></span><br><span class="line">    Bits.reserveMemory(size, cap);</span><br><span class="line">    <span class="keyword">long</span> base = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//直接内存的初始地址, 返回初始地址</span></span><br><span class="line">        base = unsafe.allocateMemory(size);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (OutOfMemoryError x) &#123;</span><br><span class="line">        Bits.unreserveMemory(size, cap);</span><br><span class="line">        <span class="keyword">throw</span> x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//对直接内存初始化</span></span><br><span class="line">    unsafe.setMemory(base, size, (<span class="keyword">byte</span>) <span class="number">0</span>);</span><br><span class="line">    <span class="comment">//若需要页对齐，并且不是页的整数倍，在需要将页对齐（默认是不需要进行页对齐的）</span></span><br><span class="line">    <span class="keyword">if</span> (pa &amp;&amp; (base % ps != <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="comment">// Round up to page boundary //初始地址取整页，注意申请的地址为取整数页</span></span><br><span class="line">        address = base + ps - (base &amp; (ps - <span class="number">1</span>));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        address = base;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//声明一个Cleaner对象用于清理该DirectBuffer内存</span></span><br><span class="line">    cleaner = Cleaner.create(<span class="keyword">this</span>, <span class="keyword">new</span> Deallocator(base, size, cap));</span><br><span class="line">    att = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，DirectByteBuffer 通过直接调用 base=unsafe.allocateMemory (size) 操作堆外内存，返回的是该堆外内存的直接地址，存放在 address 中，以便通过 address 进行堆外数据的读取与写入。</p>
<p>我们需要了解下，<code>Bits.reserveMemory()</code> 如何判断堆外内存是否可用的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">reserveMemory</span><span class="params">(<span class="keyword">long</span> size, <span class="keyword">int</span> cap)</span> </span>&#123;  <span class="comment">//对分配的直接内存做一个记录</span></span><br><span class="line">       <span class="keyword">synchronized</span> (Bits.class) &#123;</span><br><span class="line">           <span class="keyword">if</span> (!memoryLimitSet &amp;&amp; VM.isBooted())</span><br><span class="line">           &#123;</span><br><span class="line">               <span class="comment">//堆外直接内存默认等于堆内内存大小, 可以通过</span></span><br><span class="line">               maxMemory = VM.maxDirectMemory();</span><br><span class="line">               memoryLimitSet = <span class="keyword">true</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="comment">// -XX:MaxDirectMemorySize limits the total capacity rather than the</span></span><br><span class="line">           <span class="comment">// actual memory usage, which will differ when buffers are page</span></span><br><span class="line">           <span class="comment">// aligned.</span></span><br><span class="line">           <span class="comment">//如果够分的话，则直接退出</span></span><br><span class="line">           <span class="keyword">if</span> (cap &lt;= maxMemory - totalCapacity) &#123;</span><br><span class="line">               reservedMemory += size;</span><br><span class="line">               totalCapacity += cap; <span class="comment">//</span></span><br><span class="line">               count++;</span><br><span class="line">               <span class="keyword">return</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//不够分的话，则调用System.gc()进行一次full gc. 一般不要在线程启动时添加-XX:+DisableExplicitGC（禁止代码显示调用gc）</span></span><br><span class="line">       System.gc(); <span class="comment">//只是告知机器，这里应该GC一次， 但是实际并不一定进行垃圾回收</span></span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//再等待100ms使gc有时间完成，然后再看是否够分配</span></span><br><span class="line">           Thread.sleep(<span class="number">100</span>);</span><br><span class="line">       &#125; <span class="keyword">catch</span> (InterruptedException x) &#123;</span><br><span class="line">           <span class="comment">// Restore interrupt status</span></span><br><span class="line">           Thread.currentThread().interrupt();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">synchronized</span> (Bits.class) &#123;</span><br><span class="line">           <span class="comment">//此时不够分的话，再调用向外抛出oom</span></span><br><span class="line">           <span class="keyword">if</span> (totalCapacity + cap &gt; maxMemory)</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError(<span class="string">&quot;Direct buffer memory&quot;</span>);</span><br><span class="line">           reservedMemory += size;</span><br><span class="line">           totalCapacity += cap;</span><br><span class="line">           count++;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>首先检查堆外内存是否够分</li>
<li>若不够分的话，再进行一次 full gc 显式推动对堆外内存的回收，再次尝试分配堆外内存，不够分的话，则抛出 OOM 异常。</li>
</ul>
<p><strong>堆外内存的回收-JDK-nio 的 DirectByteBuffer</strong></p>
<p>在 DirectByteBuffer 的构造函数中，我们可以看到这样的一行代码 <code>cleaner = Cleaner.create(this, new Deallocator(base, size, cap));</code>, 没错，<strong>直接内存释放主要由 cleaner 来完成</strong>。我们知道 <strong>JVM GC 并不能直接释放直接内存，但是 GC 可以释放管理直接内存的 DirectByteBuffer 对象</strong>。我们需要注意下 cleaner 的类型:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Cleaner</span>  <span class="keyword">extends</span> <span class="title">PhantomReference</span>&lt;<span class="title">Object</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>PhantomReference 并不会对对象的垃圾回收产生任何影响，当进行 gc 完成后，当发现某个对象只剩下虚引用后，会将该引用迁移至 Reference 类的 pending 队列进行回收。这里可以看到 DirectByteBuffer 被 Cleaner 引用着。Reference 操作回收代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Lock</span> </span>&#123; &#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Lock lock = <span class="keyword">new</span> Lock();</span><br><span class="line"><span class="comment">/* List of References waiting to be enqueued.  The collector adds</span></span><br><span class="line"><span class="comment"> * References to this list, while the Reference-handler thread removes</span></span><br><span class="line"><span class="comment"> * them.  This list is protected by the above lock object. The</span></span><br><span class="line"><span class="comment"> * list uses the discovered field to link its elements.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//当gc时，发现DirectByteBuffer除了PhantomReference对象引用,没有其他对象引用， 会把DirectByteBuffer放入其中，等待被回收</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Reference&lt;Object&gt; pending = <span class="keyword">null</span>;</span><br><span class="line"><span class="comment">/* High-priority thread to enqueue pending References</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReferenceHandler</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    ReferenceHandler(ThreadGroup g, String name) &#123;</span><br><span class="line">        <span class="keyword">super</span>(g, name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            Reference&lt;Object&gt; r;</span><br><span class="line">            <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                <span class="keyword">if</span> (pending != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    r = pending;</span><br><span class="line">                    pending = r.discovered;</span><br><span class="line">                    r.discovered = <span class="keyword">null</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// The waiting on the lock may cause an OOME because it may try to allocate</span></span><br><span class="line">                    <span class="comment">// exception objects, so also catch OOME here to avoid silent exit of the</span></span><br><span class="line">                    <span class="comment">// reference handler thread.</span></span><br><span class="line">                    <span class="comment">//</span></span><br><span class="line">                    <span class="comment">// Explicitly define the order of the two exceptions we catch here</span></span><br><span class="line">                    <span class="comment">// when waiting for the lock.</span></span><br><span class="line">                    <span class="comment">//</span></span><br><span class="line">                    <span class="comment">// We do not want to try to potentially load the InterruptedException class</span></span><br><span class="line">                    <span class="comment">// (which would be done if this was its first use, and InterruptedException</span></span><br><span class="line">                    <span class="comment">// were checked first) in this situation.</span></span><br><span class="line">                    <span class="comment">//</span></span><br><span class="line">                    <span class="comment">// This may lead to the VM not ever trying to load the InterruptedException</span></span><br><span class="line">                    <span class="comment">// class again.</span></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="comment">//如果没有的话，会一直等待唤醒</span></span><br><span class="line">                            lock.wait();</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (OutOfMemoryError x) &#123; &#125;</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException x) &#123; &#125;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Fast path for cleaners</span></span><br><span class="line">            <span class="keyword">if</span> (r <span class="keyword">instanceof</span> Cleaner) &#123;</span><br><span class="line">                 <span class="comment">//从头开始进行clena()调用</span></span><br><span class="line">                ((Cleaner)r).clean();</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ReferenceQueue&lt;Object&gt; q = r.queue;</span><br><span class="line">            <span class="keyword">if</span> (q != ReferenceQueue.NULL) q.enqueue(r);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    ThreadGroup tg = Thread.currentThread().getThreadGroup();</span><br><span class="line">    <span class="keyword">for</span> (ThreadGroup tgn = tg;</span><br><span class="line">         tgn != <span class="keyword">null</span>;</span><br><span class="line">         tg = tgn, tgn = tg.getParent());</span><br><span class="line">    Thread handler = <span class="keyword">new</span> ReferenceHandler(tg, <span class="string">&quot;Reference Handler&quot;</span>);</span><br><span class="line">    <span class="comment">/* If there were a special system-only priority greater than</span></span><br><span class="line"><span class="comment">     * MAX_PRIORITY, it would be used here</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    handler.setPriority(Thread.MAX_PRIORITY);</span><br><span class="line">    handler.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">    handler.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出来，JVM 会新建名为 <code>Reference Handler</code> 的线程，时刻回收被挂到 pending 上面的虚拟引用 (该线程在 JVM 启动时就会产生)。 当 DirectByteBuff 对象仅被 Cleaner 引用时，Cleaner 被放入 pending 队列，之后调用 <code>Cleaner.clean()</code> 方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clean</span><span class="params">()</span> </span>&#123;  <span class="comment">//这里的clean(）会在Reference回收时显示调用</span></span><br><span class="line">        <span class="keyword">if</span> (!remove(<span class="keyword">this</span>))</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            thunk.run();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> Throwable x) &#123;</span><br><span class="line">            AccessController.doPrivileged(<span class="keyword">new</span> PrivilegedAction&lt;Void&gt;() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Void <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">if</span> (System.err != <span class="keyword">null</span>)</span><br><span class="line">                            <span class="keyword">new</span> Error(<span class="string">&quot;Cleaner terminated abnormally&quot;</span>, x)</span><br><span class="line">                                .printStackTrace();</span><br><span class="line">                        System.exit(<span class="number">1</span>);</span><br><span class="line">                        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">                    &#125;&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//就是一个释放直接内存的线程</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Deallocator</span>  <span class="keyword">implements</span> <span class="title">Runnable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">long</span> address;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">long</span> size;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="title">Deallocator</span><span class="params">(<span class="keyword">long</span> address, <span class="keyword">long</span> size, <span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">assert</span> (address != <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">this</span>.address = address;</span><br><span class="line">            <span class="keyword">this</span>.size = size;</span><br><span class="line">            <span class="keyword">this</span>.capacity = capacity;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (address == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// Paranoia</span></span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            unsafe.freeMemory(address); <span class="comment">//释放地址</span></span><br><span class="line">            address = <span class="number">0</span>;</span><br><span class="line">            Bits.unreserveMemory(size, capacity); <span class="comment">//修改统计</span></span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也就是说最终是通过调用 <code>Unsafe.freeMemory()</code> 方法来释放直接内存的。</p>
<p>所以如果简化 JDK nio 中 DirectByteBuffer 的创建与回收，那么步骤为：</p>
<ul>
<li><p>利用静态方法 <code>DirectByteBuffer.allocateDirect()</code> 进行堆外内存的分配，本质上是利用 <code>unsafe.allocateMemory(size);</code> 来申请堆外内存。</p>
</li>
<li><p>DirectByteBuffer 的构造过程中，在最后将自己作为引用传入 Cleaner 实例中。</p>
</li>
<li><p>当 GC 完成后，当发现某个对象只剩下虚引用后，会将该 Cleaner 实例迁移至 Reference 类的 pending 队列进行回收。</p>
<blockquote>
<p>GC 本身不负责 DirectByteBuffer 的回收，其只是负责将将 DirectByteBuffer 的引用迁移至 Reference 类的 pending 队列进行回收。</p>
<p>这个队列始终在进行回收工作。</p>
</blockquote>
</li>
<li><p>在 pending 队列中，会负责回调 cleaner 实例的 clean() 方法，clean() 方法中会调用 Deallocator 实例的 run() 方法，在这个方法中会负责将 cleaner 对应的堆外内存释放。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unsafe.freeMemory(address);</span><br></pre></td></tr></table></figure></li>
</ul>
<p>DirectByteBuffer 就是如此依靠着 JVM 的 GC 进行内存回收的。实际上，通过下面两个组合就能够实现堆外内存的分配和回收：</p>
<ul>
<li><code>unsafe.allocateMemory(size);</code></li>
<li><code>unsafe.freeMemory(address);</code></li>
</ul>
<p>因为 Netty 的堆外内存管理自己使用了一套机制：jemalloc，目的就是在应用层实现一套自己的内存管理（内存分配和内存回收），而不依赖 JVM 的 GC 机制。</p>
<p>本质上，Netty 的内存管理也是依赖于 Unsafe 的两个方法，见上。Netty 选择自己实现另一套（完全没有继承、包含关系）的 ByteBuf，最终的目的就是为了使用自己的应用层内存分配管理机制。</p>
<h3 id="1-7-ByteBuffer-的-JVM-配置"><a href="#1-7-ByteBuffer-的-JVM-配置" class="headerlink" title="1.7 ByteBuffer 的 JVM 配置"></a>1.7 ByteBuffer 的 JVM 配置</h3><p>堆内、堆外的内存空间都是有限的，当内存申请超过启动时的最大内存配置就会报错：</p>
<ul>
<li>HeapByteBuffer 的内存限制主要受到 JVM 内存配置的影响，<code>-Xms</code> 参数用于控制初始堆大小，<code>-Xmx</code> 参数用于控制最大堆大小。由于堆内还需要存放其他实例，因此实际上 HeapByteBuffer 能够申请的内存大小小于 <code>-Xms</code> 配置；</li>
<li>DirectByteBuffer 的内存限制受到 <code>-XX:MaxDirectMemorySize</code> 参数的影响；</li>
</ul>
<p>当然，上述内存配置都无法超过物理机的虚拟内存大小。</p>
<p>另一方面，单个 HeapByteBuffer 与 DirectByteBuffer 的最大数据量都为 Integer.MAXVALUE 个 byte，也就是 2000 MB 左右的内存大小。如果要申请 4GB 的内存，那么至少需要两个 ByteBuffer 实例。</p>
<h2 id="2-Channel"><a href="#2-Channel" class="headerlink" title="2. Channel"></a>2. Channel</h2><blockquote>
<p>A channel represents an open connection to an entity such as a hardware device, a file, a network socket, or a program component that is capable of performing one or more distinct I/O operations, for example reading or writing.</p>
</blockquote>
<p>Channel 类位于 java.nio.channels 包中，但并不是 Channel 仅仅支持 NIO，其分为两种类型：</p>
<ul>
<li>FileChannel：完全不支持 NIO；</li>
<li>SocketChannel/ServerSocketChannel 等 Channel 默认情况下并不支持 NIO，只有显式地调用配置方法才能够进入非阻塞模式（<code>ServerSocketChannel.configBlocking(false)</code>）。</li>
</ul>
<p>下面主要以 SocketChannel 的角度来介绍 Channel 类。</p>
<p>Channel 我们可以理解为对应于 BIO 中的 Socket，也可以理解为 Scoket.inputStream/SocketOutputStream。如果认为是流，那么我们做一个比较：</p>
<ul>
<li>传统 Socket：我们调用 Socket 的 <code>getInputStream()</code> 以及 <code>getOutputStream()</code> 进行数据的读和写。</li>
<li>Channel：我们不再需要得到输入输出流进行读和写，而是通过 Channel 的 <code>read()</code> 以及 <code>write()</code> 方法进行读和写。</li>
</ul>
<p>Channel 如此实现也付出了代价（如下图所示）：</p>
<ul>
<li>读写模式需要调用 <code>flip()</code> 方法进行切换，读模式下调用 <code>write()</code> 试图进行写操作会报错。</li>
<li>读写不再能够接受一个简单的字节数组，而是必须是封装了字节数组的 Buffer 类型。</li>
</ul>
<p><img src="./images/image-20200516195346349.png" alt="image-20200516195346349"></p>
<p>目前已知 Channel 的实现类有：</p>
<ul>
<li><p>FileChannel</p>
<blockquote>
<p>一个用来写、读、映射和操作文件的通道。</p>
</blockquote>
</li>
<li><p>DatagramChannel</p>
</li>
<li><p>SocketChannel</p>
<p>SocketChannel 可以看做是具有非阻塞模式的 Socket。其可以运行在阻塞模式，也可以运行在非阻塞模式。其只能依靠 ByteBuffer 进行读写，而且是尽力读写，尽力的含义是：</p>
<ul>
<li>ByteBuffer 满了就不能在读了；</li>
<li>即使此次 Socket 流没有传输完毕，但是一旦 Channel 中的数据读完了，那么就返回了，这就是非阻塞读。所以读的方法有 -1（EOF），0（Channel 中的数据读完了，但是整个数据流本身没有消耗完），其他整数，此次读的数据（因为 ByteBuffer 并不是每次都是空的，原来就有数据时只能够尽力装满）。</li>
</ul>
</li>
<li><p>ServerSocketChannel</p>
<p>这个类似于 ServerSocket 起到的作用。</p>
</li>
</ul>
<h2 id="3-为什么-Netty-要封装原有的-Buffer-以及-Channel"><a href="#3-为什么-Netty-要封装原有的-Buffer-以及-Channel" class="headerlink" title="3. 为什么 Netty 要封装原有的 Buffer 以及 Channel"></a>3. 为什么 Netty 要封装原有的 Buffer 以及 Channel</h2><ul>
<li>原生的 Buffer + Channel 的读写方式容易导致错误，比如写和读共用一个 index，经常容易犯的错误是写完在读的时候忘记 <code>flip()</code>。Netty 的有 readerindex 和 writerindex，用起来更方便了。</li>
<li>提供更高层次的封装，提供更为丰富的功能。比如 Netty 的 Buffer 可以让我们方便的将两个小 Buffer 合并为一个大 Buffer 而不需要进行 byte 的复制。</li>
<li>Netty 提供了更好的内存管理：<strong>JDK 的 DirectBytebuffer 虽然也使用堆外内存，但是依赖 JVM 进行 GC</strong>。但是 Netty 自己实现了 ByteBuf 的内存管理 jemalloc，性能更好，且完全不受到 GC 的管理。</li>
</ul>
<h2 id="REFERENCE"><a href="#REFERENCE" class="headerlink" title="REFERENCE"></a>REFERENCE</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/60892134">知乎：Java NIO direct buffer 的优势在哪儿？</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/57374068/answer/152691891">Java NIO中，关于DirectBuffer，HeapBuffer的疑问？</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/duanxz/p/6089485.html">Java堆外内存之三：堆外内存回收方法</a></li>
<li><a target="_blank" rel="noopener" href="http://www.datascienceassn.org/sites/default/files/Netty%20-%20Asynchronous%20Network%20Application%20Framework.pdf">Netty - One Framework to rule them all</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sk-xinye.github.io/2023/02/04/4.%20%E6%96%87%E4%BB%B6%E5%88%86%E5%8C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sk-xinye">
      <meta itemprop="description" content="愿所有努力都不被辜负">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="sk-xinyeの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/02/04/4.%20%E6%96%87%E4%BB%B6%E5%88%86%E5%8C%BA/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-02-04 10:34:09 / 修改时间：10:33:07" itemprop="dateCreated datePublished" datetime="2023-02-04T10:34:09+08:00">2023-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="文件分区"><a href="#文件分区" class="headerlink" title="文件分区"></a>文件分区</h1><h2 id="1-文件分区是指什么？"><a href="#1-文件分区是指什么？" class="headerlink" title="1. 文件分区是指什么？"></a>1. 文件分区是指什么？</h2><p>文件分区很少有资料介绍，但是在众多数据库组件的最佳实践中通常会以 benchmark 告诉我们这一个建议。</p>
<p>文件分区包括两件事：</p>
<ol>
<li><strong>将原本一个大文件分为多个小文件</strong>。例如，将一个大数据量的文件分为多个小文件进行存储。例如 Kafka 中为避免 WAL Log 过大，使用了 LogSegment 概念，当某一个 LogSegment 足够大时，就创建一个新的 LogSegment，用于后续的日志写入；</li>
<li><strong>将用途不同的文件存储于不同的磁盘上</strong>。例如，MySQL 通常推荐将事务日志文件与数据文件分别存储于本机挂载的不同磁盘上。</li>
</ol>
<p>下面我们分析一下文件分区的意义。</p>
<h2 id="2-文件分区的意义"><a href="#2-文件分区的意义" class="headerlink" title="2. 文件分区的意义"></a>2. 文件分区的意义</h2><h3 id="2-1-减少文件锁粒度，提高并发-I-O-潜力"><a href="#2-1-减少文件锁粒度，提高并发-I-O-潜力" class="headerlink" title="2.1 减少文件锁粒度，提高并发 I/O 潜力"></a>2.1 减少文件锁粒度，提高并发 I/O 潜力</h3><p>正如<a target="_blank" rel="noopener" href="https://spongecaptain.cool/SimpleClearFileIO/9.%20%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%A1%BA%E5%BA%8F%E8%AF%BB%E5%86%99.html"> 如何实现顺序读写</a>中指出，为了确保实现物理上真正的顺序 I/O，在涉及多线并发读写时，我们必须使用锁机制。这里的锁通常是文件锁，一个文件一把锁。锁可以由操作系统提供，但更常见的是在用户应用中额外使用一把锁。</p>
<p>依赖于锁机制的线程并发能力提高可以通过细化锁粒度实现。一个大文件分为多个小文件，意味着将一个大锁分为多个小锁，这样一来，锁粒度细化，线程冲突可能性降低，系统的整体 I/O 能力得到提高。</p>
<h3 id="2-2-简化索引实现"><a href="#2-2-简化索引实现" class="headerlink" title="2.2 简化索引实现"></a>2.2 简化索引实现</h3><p>一般的日志存储系统有如下特点：</p>
<ul>
<li>每一条日志所占数据长度不一致（你无法事先确认用户试图写入 “Hello World” 还是 “Hi Spongecaptain”）；</li>
<li>日志顺序存储，例如在磁盘上编号 101 的日志顺序存储于编号 100 的日志之后；</li>
</ul>
<p>为了提高日志存储系统的查询效率，我们必然需要实现索引。</p>
<p>在不进行日志文件分区的情况下，即只有一个日志文件，那么如果要提供随机日志查询与范围查询的能力，那么索引系统必须为每一条日志设计一个 Tree 上的节点。但是如果日志非常多，那么索引 Tree 将拥有非常多的节点，存在查询效率降低的问题。</p>
<p>如果进行日志分区，大日志文件分为多个小日志文件进行存储，那么如果要提供随机日志查询与范围查询能力，那么我们可以为每一个小日志文件分别设计一个索引文件，由于每一个索引 Tree 的节点数不会特别多，因此我们总是能够确保较好的查询效率。</p>
<p>Kafka 的日志索引就基于此思想实现。</p>
<h3 id="2-3-分磁盘存储文件提高磁盘-I-O-效率"><a href="#2-3-分磁盘存储文件提高磁盘-I-O-效率" class="headerlink" title="2.3 分磁盘存储文件提高磁盘 I/O 效率"></a>2.3 分磁盘存储文件提高磁盘 I/O 效率</h3><p>文件分区的另一个含义是将不同文件存储于不同磁盘上，不过前提自然是你拥有多个磁盘与需要多个文件。正如前文所属，MySQL 通常推荐将事务日志文件（WAL）与数据文件（B+Tree）分别存储于本机上挂载的不同磁盘上。</p>
<p>分磁盘存储文件的优势主要有如下：</p>
<ol>
<li>实现并行磁盘 I/O；</li>
<li>不同文件的 I/O 模式特质不同（顺序 or 随机）；</li>
<li>更可靠的持久化保证；</li>
</ol>
<p><strong>1.并行磁盘 I/O</strong></p>
<p>多个磁盘具备属于各自的驱动，因此可以进行并行的磁盘 I/O（你可以想象多个磁盘的磁头在并行移动），比单磁盘的操作系统在磁盘 I/O 具备更好的性能。</p>
<p><strong>2.屏蔽不同磁盘 I/O 方式之间的干扰</strong></p>
<p>另一方面，不同文件的 I/O 模式特性不同。例如，MySQL 中的事务日志文件主要进行顺序 I/O 读写，而数据文件（B+Tree）主要进行随机 I/O 读写。如果随机 I/O 与顺序 I/O 共用一块磁盘，那么随机 I/O 会影响顺序 I/O 的磁盘调度，导致磁盘吞吐量下降。</p>
<p><strong>3.更可靠的持久化保证</strong></p>
<p>如果数据本身所在的磁盘损坏了，但是你有在另一个磁盘上存储着 <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/sql/relational-databases/backup-restore/tail-log-backups-sql-server">tail-of-the-log backup</a>，那么重新执行一遍写日志那么就能够得到完全一样的数据。这种情况下，持久化机制更可靠了。例如假设一个磁盘一年内发生损坏的概率为 2%，那么持久化的可靠性可以通过双磁盘提高至 1-2%*2% =99.96%。</p>
<h2 id="REFERENCE"><a href="#REFERENCE" class="headerlink" title="REFERENCE"></a>REFERENCE</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.cnkirito.moe/file-io-best-practise/">文件 IO 操作的一些最佳实践</a></li>
<li><a target="_blank" rel="noopener" href="https://dba.stackexchange.com/questions/15827/is-there-a-performance-benefit-to-placing-transaction-log-files-on-a-separate-dr">Is there a performance benefit to placing transaction log files on a separate drive?</a></li>
<li><a target="_blank" rel="noopener" href="https://www.brentozar.com/archive/2017/06/separating-data-log-files-make-server-reliable/">Does Separating Data and Log Files Make Your Server More Reliable?</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/default-index/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/default-index/page/15/">15</a><a class="extend next" rel="next" href="/default-index/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">sk-xinye</p>
  <div class="site-description" itemprop="description">愿所有努力都不被辜负</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">142</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sk-xinye</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
